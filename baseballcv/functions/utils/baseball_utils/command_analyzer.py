
import pandas as pd
import numpy as np
import os
import glob
from typing import List, Dict, Tuple, Optional

# Keep necessary utilities
from baseballcv.utilities import BaseballCVLogger, ProgressBar # Assuming ProgressBar exists

class CommandAnalyzer:
    """
    Analyzes pitcher command by comparing catcher's glove target proxy
    from GloveTracker CSVs with actual pitch locations from provided Statcast data.

    Reads tracking data generated by the GloveTracker class and integrates
    external pitch outcome data (e.g., Statcast DataFrame) to calculate command metrics.
    """

    def __init__(
        self,
        glove_tracking_dir: str, # Directory containing GloveTracker CSVs
        statcast_df: pd.DataFrame, # DataFrame with Statcast data for relevant pitches
        logger: Optional[BaseballCVLogger] = None,
        verbose: bool = True
    ):
        """
        Initialize the CommandAnalyzer.

        Args:
            glove_tracking_dir (str): Path to the directory containing GloveTracker CSV files.
            statcast_df (pd.DataFrame): DataFrame containing Statcast pitch data.
                                        Must include 'play_id', 'plate_x', 'plate_z'.
                                        Should ideally contain all pitches corresponding to the
                                        CSVs in glove_tracking_dir.
            logger (BaseballCVLogger, optional): Logger instance. If None, creates a default logger.
            verbose (bool): Whether to print verbose logs.
        """
        self.glove_tracking_dir = glove_tracking_dir
        self.logger = logger if logger else BaseballCVLogger.get_logger(self.__class__.__name__)
        self.verbose = verbose
        self.statcast_data = statcast_df # Store the provided DataFrame

        if not os.path.isdir(glove_tracking_dir):
             raise FileNotFoundError(f"Glove tracking directory not found: {glove_tracking_dir}")

        # Validate required Statcast columns
        required_cols = ['play_id', 'plate_x', 'plate_z'] # Minimum required
        if self.statcast_data is None or not all(col in self.statcast_data.columns for col in required_cols):
            missing = []
            if self.statcast_data is None:
                 missing = required_cols
            else:
                 missing = [col for col in required_cols if col not in self.statcast_data.columns]
            raise ValueError(f"Provided Statcast DataFrame is missing required columns: {missing}")

        # Ensure play_id is string for consistent merging/lookup
        self.statcast_data['play_id'] = self.statcast_data['play_id'].astype(str)

        self.logger.info(f"CommandAnalyzer initialized. Reading CSVs from: {glove_tracking_dir}")
        self.logger.info(f"Using provided Statcast data with {len(self.statcast_data)} rows.")


    def _extract_ids_from_filename(self, filename: str) -> Tuple[Optional[int], Optional[str]]:
        """Extracts game_pk and Statcast play_id from GloveTracker CSV filename."""
        basename = os.path.basename(filename)
        # Format: tracked_{game_pk}_{play_id}_tracking.csv (in root or subdirs)
        parts = basename.replace("tracked_", "").replace("_tracking.csv", "").split('_')

        if len(parts) == 2:
            game_pk_str, play_id = parts
            try:
                game_pk = int(game_pk_str)
                if len(play_id.split('-')) == 5: # Basic UUID format check
                    return game_pk, str(play_id) # Ensure play_id is string
            except ValueError:
                # Log warning but allow potential fallback
                self.logger.debug(f"Could not parse game_pk int from first part: {basename}")

        # Fallback for filenames directly like {game_pk}_{play_id}.csv (e.g., in subdirs)
        sub_parts = basename.replace(".csv", "").split('_')
        if len(sub_parts) == 2:
            game_pk_str, play_id = sub_parts
            try:
                game_pk = int(game_pk_str)
                if len(play_id.split('-')) == 5:
                    return game_pk, str(play_id)
            except ValueError:
                self.logger.debug(f"Could not parse game_pk int from fallback parts: {basename}")

        self.logger.warning(f"Could not extract valid game_pk and play_id from filename: {basename}")
        return None, None

    def _find_intent_frame(self, df: pd.DataFrame, velocity_threshold: float = 5.0) -> Optional[int]:
        """
        Identifies the 'intent frame' based on glove stability (low velocity).

        Placeholder implementation - needs refinement based on pitch timing.

        Args:
            df (pd.DataFrame): DataFrame for a single pitch.
            velocity_threshold (float): Velocity (inches/frame) below which the glove is stable.

        Returns:
            Optional[int]: The identified intent frame index, or None.
        """
        valid_glove_frames = df[
            df['glove_processed_x'].notna() &
            df['glove_processed_y'].notna() &
            (df['is_interpolated'] == False) # Use only actual detections for stability check
        ].copy()

        if len(valid_glove_frames) < 2:
            # self.logger.debug("Not enough non-interpolated glove frames (<2) to calculate velocity.")
            return None # Cannot determine stability

        valid_glove_frames = valid_glove_frames.sort_values(by='frame_idx').reset_index()
        valid_glove_frames['dt'] = valid_glove_frames['frame_idx'].diff().fillna(1.0)
        valid_glove_frames.loc[valid_glove_frames['dt'] <= 0, 'dt'] = 1.0 # Avoid zero or negative dt
        valid_glove_frames['dx'] = valid_glove_frames['glove_processed_x'].diff().fillna(0)
        valid_glove_frames['dy'] = valid_glove_frames['glove_processed_y'].diff().fillna(0)
        valid_glove_frames['velocity'] = np.sqrt(valid_glove_frames['dx']**2 + valid_glove_frames['dy']**2) / valid_glove_frames['dt']

        # Find the last frame where velocity was below threshold
        stable_frames = valid_glove_frames[valid_glove_frames['velocity'] < velocity_threshold]

        if not stable_frames.empty:
            # Return the *last* frame index that met the stability criteria
            intent_frame = int(stable_frames['frame_idx'].iloc[-1])
            # self.logger.debug(f"Identified potential intent frame: {intent_frame} (Velocity < {velocity_threshold})")
            return intent_frame
        else:
             # Fallback: If no frame is below threshold, find the frame with minimum velocity (excluding the first diff)
             if not valid_glove_frames.empty and 'velocity' in valid_glove_frames.columns and len(valid_glove_frames) > 1:
                 min_vel_frame_idx = valid_glove_frames['velocity'].iloc[1:].idxmin()
                 if pd.notna(min_vel_frame_idx):
                      min_vel_frame = int(valid_glove_frames.loc[min_vel_frame_idx, 'frame_idx'])
                      # self.logger.debug(f"Using fallback intent frame (min velocity): {min_vel_frame}")
                      return min_vel_frame
             self.logger.debug("Could not find a stable intent frame.")
             return None


    def calculate_command_metrics(
        self,
        csv_path: str
        ) -> Optional[Dict]:
        """
        Calculates command deviation for a single pitch from its tracking CSV,
        using the Statcast data provided during initialization.

        Args:
            csv_path (str): Path to the GloveTracker CSV file for one pitch.

        Returns:
            Optional[Dict]: Dictionary containing command metrics for the pitch, or None.
        """
        if not os.path.exists(csv_path):
            self.logger.error(f"CSV file not found: {csv_path}")
            return None

        game_pk, play_id = self._extract_ids_from_filename(csv_path)
        if not play_id or game_pk is None:
            self.logger.warning(f"Could not get IDs from {csv_path}. Skipping.")
            return None

        # Check if Statcast data is available at all (checked in init, but double-check)
        if self.statcast_data is None or self.statcast_data.empty:
             self.logger.error("Statcast DataFrame not provided or empty. Cannot calculate command.")
             return None # Cannot proceed without Statcast data

        # --- Look up this specific pitch in the Statcast DataFrame ---
        statcast_pitch = self.statcast_data[self.statcast_data['play_id'] == play_id]

        if statcast_pitch.empty:
            self.logger.warning(f"No Statcast data found for play_id {play_id} in provided DataFrame. Skipping.")
            return None # Cannot calculate deviation without Statcast match

        # Proceed only if Statcast data for this play exists
        try:
            track_df = pd.read_csv(csv_path)
        except Exception as e:
            self.logger.error(f"Failed to read tracking CSV {csv_path}: {e}")
            return None

        # --- Find Intent Frame ---
        intent_frame_idx = self._find_intent_frame(track_df, velocity_threshold=5.0) # Threshold needs tuning

        if intent_frame_idx is None:
            self.logger.warning(f"Could not determine intent frame for play_id {play_id} (Game {game_pk}). Skipping.")
            return None

        intent_frame_data_rows = track_df[track_df['frame_idx'] == intent_frame_idx]
        if intent_frame_data_rows.empty:
             self.logger.warning(f"Intent frame {intent_frame_idx} not found in data for play_id {play_id}. Skipping.")
             return None
        intent_frame_data = intent_frame_data_rows.iloc[0]

        # Use 'glove_processed_x/y' as target proxy (assumes these are filtered/stable)
        glove_target_x = intent_frame_data['glove_processed_x']
        glove_target_y = intent_frame_data['glove_processed_y']

        if pd.isna(glove_target_x) or pd.isna(glove_target_y):
             self.logger.warning(f"Glove target coords missing for intent frame {intent_frame_idx} in play_id {play_id}. Skipping.")
             return None

        # --- Get Actual Pitch Location (from looked-up Statcast data) ---
        if not all(col in statcast_pitch.columns for col in ['plate_x', 'plate_z']):
            self.logger.warning(f"Statcast location data (plate_x, plate_z) missing for play_id {play_id}. Skipping.")
            return None

        try:
            actual_pitch_x_ft = statcast_pitch['plate_x'].iloc[0]
            actual_pitch_z_ft = statcast_pitch['plate_z'].iloc[0]

            if pd.isna(actual_pitch_x_ft) or pd.isna(actual_pitch_z_ft):
                 raise ValueError("Statcast location is NaN")

            actual_pitch_x_inches = actual_pitch_x_ft * 12.0
            actual_pitch_z_inches = actual_pitch_z_ft * 12.0
        except (TypeError, ValueError, IndexError) as e:
             self.logger.warning(f"Invalid Statcast location data for play_id {play_id}: {e}. Skipping.")
             return None

        # --- Calculate Deviation ---
        dev_x = actual_pitch_x_inches - glove_target_x
        dev_y = actual_pitch_z_inches - glove_target_y
        deviation_inches = np.sqrt(dev_x**2 + dev_y**2)

        results = {
            "game_pk": game_pk,
            "play_id": play_id,
            "intent_frame": intent_frame_idx,
            "glove_target_x": glove_target_x,
            "glove_target_y": glove_target_y,
            "actual_pitch_x": actual_pitch_x_inches,
            "actual_pitch_z": actual_pitch_z_inches,
            "deviation_inches": deviation_inches,
            "deviation_vector_x": dev_x,
            "deviation_vector_y": dev_y
        }
        # Add pitcher ID and pitch type if available for easier aggregation later
        for col in ['pitcher', 'pitch_type']:
             if col in statcast_pitch.columns:
                  results[col] = statcast_pitch[col].iloc[0]

        return results

    def analyze_folder(self, output_csv: str = "command_analysis_results.csv") -> pd.DataFrame:
        """
        Analyzes all GloveTracker CSV files in the specified directory using
        the Statcast data provided during initialization.

        Args:
            output_csv (str): Path relative to glove_tracking_dir to save the results CSV file.

        Returns:
            pd.DataFrame: DataFrame containing command metrics for all processed pitches.
        """
        # Search in the root directory and one level deep
        csv_files = glob.glob(os.path.join(self.glove_tracking_dir, "tracked_*_tracking.csv")) + \
                    glob.glob(os.path.join(self.glove_tracking_dir, "*", "tracked_*_tracking.csv")) # Include subdirs like 'results'
        csv_files = list(set(csv_files)) # Remove duplicates

        if not csv_files:
            self.logger.error(f"No GloveTracker CSV files like 'tracked_*_tracking.csv' found in {self.glove_tracking_dir} or its subdirectories.")
            return pd.DataFrame()

        all_results = []
        self.logger.info(f"Found {len(csv_files)} tracking files to analyze.")

        # Use ProgressBar for iteration
        for csv_file in ProgressBar(iterable=csv_files, desc="Analyzing Pitch Command"):
             pitch_metrics = self.calculate_command_metrics(csv_file)
             # Append only if metrics were successfully calculated (not None and no error key)
             if pitch_metrics and 'error' not in pitch_metrics:
                 all_results.append(pitch_metrics)
             elif pitch_metrics and 'error' in pitch_metrics:
                 self.logger.warning(f"Skipped {pitch_metrics.get('play_id', os.path.basename(csv_file))} due to error: {pitch_metrics['error']}")
             elif pitch_metrics is None:
                 # Log skips where metrics calculation returned None (e.g., missing IDs, bad CSV)
                 self.logger.warning(f"Skipped {os.path.basename(csv_file)} during metric calculation.")


        if not all_results:
             self.logger.warning("No pitches could be successfully analyzed.")
             return pd.DataFrame()

        results_df = pd.DataFrame(all_results)

        # --- Merge additional Statcast data for context ---
        # (Pitcher/pitch_type potentially added in calculate_command_metrics)
        if self.statcast_data is not None and not self.statcast_data.empty:
            cols_to_merge = list(self.statcast_data.columns)
            # Define columns potentially added/calculated already
            cols_already_present = ['play_id', 'pitcher', 'pitch_type', 'plate_x', 'plate_z',
                                    'game_pk', 'intent_frame', 'glove_target_x', 'glove_target_y',
                                    'actual_pitch_x', 'actual_pitch_z', 'deviation_inches',
                                    'deviation_vector_x', 'deviation_vector_y']
            # Select Statcast cols not already in results_df
            cols_to_merge = [col for col in cols_to_merge if col not in results_df.columns and col not in cols_already_present]
            cols_to_merge.insert(0, 'play_id') # Ensure merge key is present

            if len(cols_to_merge) > 1: # If there's more than just the key to merge
                merge_statcast = self.statcast_data[cols_to_merge].drop_duplicates(subset=['play_id'])
                merge_statcast['play_id'] = merge_statcast['play_id'].astype(str)
                results_df['play_id'] = results_df['play_id'].astype(str)

                results_df = pd.merge(
                    results_df,
                    merge_statcast,
                    on='play_id',
                    how='left',
                    suffixes=('', '_statcast') # Suffix for safety, though we filtered overlaps
                )
                # Clean up any suffixed columns if they somehow appear
                results_df = results_df[[col for col in results_df.columns if not col.endswith('_statcast')]]


        # --- Save results ---
        output_path = os.path.join(self.glove_tracking_dir, output_csv)
        try:
            os.makedirs(os.path.dirname(output_path), exist_ok=True)
            results_df.to_csv(output_path, index=False)
            self.logger.info(f"Command analysis results saved to {output_path}")
        except Exception as e:
            self.logger.error(f"Failed to save results CSV to {output_path}: {e}")

        return results_df

    def calculate_aggregate_metrics(self, results_df: pd.DataFrame, group_by: List[str] = ['pitcher'], cmd_threshold_inches: float = 6.0) -> pd.DataFrame:
        """
        Calculates aggregate command metrics grouped by specified columns.

        Args:
            results_df (pd.DataFrame): DataFrame from analyze_folder().
            group_by (List[str]): List of columns to group by (e.g., ['pitcher'], ['pitcher', 'pitch_type']).
            cmd_threshold_inches (float): The threshold in inches to define a "commanded" pitch.

        Returns:
            pd.DataFrame: DataFrame with aggregate metrics (AvgDev, StdDevDev, Cmd%).
        """
        if results_df is None or results_df.empty:
            self.logger.error("Input DataFrame is empty or None.")
            return pd.DataFrame()
        if 'deviation_inches' not in results_df.columns:
            self.logger.error("Input DataFrame must contain 'deviation_inches' column.")
            return pd.DataFrame()

        # Ensure grouping columns exist after potential merge issues
        valid_group_by = [col for col in group_by if col in results_df.columns]
        if len(valid_group_by) != len(group_by):
             missing_groups = [col for col in group_by if col not in valid_group_by]
             self.logger.error(f"Grouping columns not found: {missing_groups}. Grouping by available: {valid_group_by}")
             if not valid_group_by: return pd.DataFrame()
             group_by = valid_group_by # Use only the valid columns

        results_df_filtered = results_df.dropna(subset=['deviation_inches'])
        if results_df_filtered.empty:
            self.logger.warning("No valid deviation data found for aggregation.")
            return pd.DataFrame()

        results_df_filtered = results_df_filtered.copy() # Avoid SettingWithCopyWarning
        results_df_filtered['is_commanded'] = results_df_filtered['deviation_inches'] <= cmd_threshold_inches

        if results_df_filtered[group_by].isnull().any().any():
            nan_cols = results_df_filtered[group_by].isnull().any()
            self.logger.warning(f"NaN values found in grouping columns: {nan_cols[nan_cols].index.tolist()}. Excluding these rows.")
            results_df_filtered = results_df_filtered.dropna(subset=group_by)

        if results_df_filtered.empty:
             self.logger.warning("DataFrame empty after dropping NaN group keys.")
             return pd.DataFrame()

        # Define aggregations
        agg_funcs = {
            'AvgDev_inches': pd.NamedAgg(column='deviation_inches', aggfunc='mean'),
            'StdDev_inches': pd.NamedAgg(column='deviation_inches', aggfunc='std'),
            'CmdPct': pd.NamedAgg(column='is_commanded', aggfunc=lambda x: x.mean() * 100 if not x.empty else 0),
            'Pitches': pd.NamedAgg(column='play_id', aggfunc='count')
        }

        agg_metrics = results_df_filtered.groupby(group_by, dropna=True).agg(**agg_funcs).reset_index() # dropna=True is default but explicit

        if 'StdDev_inches' in agg_metrics.columns:
            agg_metrics['StdDev_inches'] = agg_metrics['StdDev_inches'].fillna(0) # Fill NaN std dev for groups with 1 pitch

        agg_metrics.rename(columns={'CmdPct': f'Cmd%_<{cmd_threshold_inches}in'}, inplace=True)

        self.logger.info(f"Calculated aggregate metrics grouped by: {group_by}")
        return agg_metrics