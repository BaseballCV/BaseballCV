{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQjdUKvQigN2"
      },
      "source": [
        "# How to Infere & Extract Data from a Pre-Trained YOLO Detection Model - Glove Tracking\n",
        "---\n",
        "If you have any questions, please contact the authors of the repository."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m09A8n4djDwY"
      },
      "source": [
        "## Pre-work\n",
        "\n",
        "Let's make sure that we have access to GPU. We can use `nvidia-smi` command to do that. In case of any problems navigate to `Edit` -> `Notebook settings` -> `Hardware accelerator`, set it to `GPU`, and then click `Save`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_5hX88yficL7"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X8oLIkX2l2P0"
      },
      "source": [
        "## Clone BaseballCV Repo, set as Current Directory and Install Requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NcQ87h5Ib1Cw"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/dylandru/BaseballCV.git\n",
        "%cd BaseballCV\n",
        "!pip install -r requirements.txt\n",
        "from ultralytics import YOLO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dg29vEyLkTDA"
      },
      "source": [
        "## Download Example Image from Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xIKNGnN2kcTp"
      },
      "source": [
        "**NOTE:** If you want to run inference using your own file as input, simply upload image to Google Colab and update `SOURCE_IMAGE_PATH` with the path leading to your file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3i_vcbxRcfKX"
      },
      "outputs": [],
      "source": [
        "from scripts.load_tools import load_dataset\n",
        "\n",
        "load_dataset(\"/content/BaseballCV/datasets/yolo/baseball_rubber_home_glove.txt\") #can be any dataset within files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DmGB-YOLbbgY"
      },
      "outputs": [],
      "source": [
        "SOURCE_IMAGE_PATH = \"baseball_rubber_home_glove/baseball_rubber_home_glove/train/images/0000196.jpg\"\n",
        "print(\"Source Image Updated.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4dlfABN6m-LL"
      },
      "source": [
        "## Box Detection with Pre-Trained model (**Glove Detection Model**)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4UAJHgKOd008"
      },
      "source": [
        "**NOTE:** This can be used with any type of detection model, although the process may slightly differ for other types of YOLO models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hUuJUUbD4FE7"
      },
      "outputs": [],
      "source": [
        "from scripts.load_tools import load_model\n",
        "\n",
        "model_weights = load_model(model_alias='glove_tracking')\n",
        "model = YOLO(model_weights)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yAr31dx8qzS6"
      },
      "outputs": [],
      "source": [
        "results = model.predict(source=SOURCE_IMAGE_PATH, save=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hflXfkBt3N0k"
      },
      "source": [
        "**NOTE:** By default, the results of each subsequent inference sessions are saved in `/runs/detect/predict`, in directories named `exp`, `exp2`, `exp3`, ... You can override this behavior by using the `--name` parameter."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sAE1P1BxpHYL"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Image\n",
        "\n",
        "Image(filename=\"runs/detect/predict/0000196.jpg\", width=600)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_EW21kBg-YXo"
      },
      "source": [
        "## Process Box Detections"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9h3hO9r5gusV"
      },
      "source": [
        "**EXAMPLE:** Returning Box Predictions as Tensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dcx3P_-c-jU-"
      },
      "outputs": [],
      "source": [
        "for r in results: #access predictions from frame\n",
        "  for box in r.boxes: #access individual boxes from frame\n",
        "    print(box.xywh) #print x, y coordinate and width/height of box as tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0uAIoTkg2Yy"
      },
      "source": [
        "**EXAMPLE:** Since Tensors are not always the most ideal data format, you can convert the box predictions to a numpy array."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XaX60vzl-9ST"
      },
      "outputs": [],
      "source": [
        "import numpy\n",
        "\n",
        "for r in results: #access predictions from frame\n",
        "  for box in r.boxes.cpu().numpy(): #access individual boxes from frame, move to cpu memory, convert to numpy array from tensor\n",
        "    print(box.xywh) #print x, y coordinate and width/height of box as tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fwKrEyN_TEA"
      },
      "source": [
        "**EXAMPLE:** The output of the box prediction can be outputted in multiple formats, not just X, Y, W, H. Other aspects of the boxes can also be outputted."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A9JnnpBMjRbu"
      },
      "outputs": [],
      "source": [
        "for r in results:\n",
        "  for box in r.boxes.cpu().numpy():\n",
        "    print(f\"XYXY: {box.xyxy}\")\n",
        "    print(f\"XYWHN (Normalized XYWH): {box.xywh}\")\n",
        "    print(f\"XYXYN (Normalized XYXY): {box.xyxyn}\")\n",
        "    print(f\"Confidence: {box.conf}\")\n",
        "    print(f\"Track ID: {box.id}\")\n",
        "    print(f\"Class Value: {box.cls} \\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFHH_anf5kuG"
      },
      "source": [
        "## Utilizing OpenCV to Visualize Predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8VTZz4jnmvV"
      },
      "source": [
        "**EXAMPLE:** Visualize Rectangles Individually on Each Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IdS48w0Y_FtB"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "for box in r.boxes.cpu().numpy():\n",
        "    image = cv2.imread(SOURCE_IMAGE_PATH)\n",
        "    x1, y1, x2, y2 = box.xyxy[0]\n",
        "    cv2.rectangle(image, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n",
        "    cv2_imshow(image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4mLRkON_iY-"
      },
      "source": [
        "**EXAMPLE:** Each object was able to be detected across images with the numerical output. Utilizing the other classes and some reconfiguration, this can be done on a singular image with the class name and confidence of class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fu-suVgZnwT9"
      },
      "outputs": [],
      "source": [
        "image = cv2.imread(SOURCE_IMAGE_PATH)\n",
        "\n",
        "for box in r.boxes.cpu().numpy():\n",
        "    x1, y1, x2, y2 = box.xyxy[0]\n",
        "    cv2.rectangle(image, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2) #draw rectangle\n",
        "\n",
        "    class_id = int(box.cls.item())\n",
        "    class_name = model.names[class_id] #get class name based on ID\n",
        "    conf = float(box.conf.item())\n",
        "\n",
        "    label = f\"Class: {class_name}, Conf: {conf:.3f}\"\n",
        "    cv2.putText(image, label, (int(x1), int(y1)-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0,255,0), 2) #put class and confidence\n",
        "\n",
        "cv2_imshow(image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTzOz56Mq8_F"
      },
      "source": [
        "## Inference on Video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2a7KhTlTrIT6"
      },
      "outputs": [],
      "source": [
        "SOURCE_VIDEO_PATH = \"/content/BaseballCV/assets/hunter_harvey_splitter.avi\"\n",
        "print(\"Source Video Updated.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xghe2GoYrNuD"
      },
      "outputs": [],
      "source": [
        "results = model.predict(source=SOURCE_VIDEO_PATH, save=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8QvvPu49rPtj"
      },
      "outputs": [],
      "source": [
        "%cd /content/BaseballCV/runs/detect/predict\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JrWIDPWErSET"
      },
      "outputs": [],
      "source": [
        "import moviepy.editor\n",
        "\n",
        "# Load the video file\n",
        "video = moviepy.editor.VideoFileClip(filename=\"hunter_harvey_splitter.avi\")\n",
        "# Resize the video to a new resolution, e.g., (width, height)\n",
        "resized_video = video.resize((640, 360))  # Example: resizing to 640x360\n",
        "moviepy.editor.ipython_display(resized_video)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLQTd7Sq8i0W"
      },
      "source": [
        "##**CONGRATS!** You utilized the output of the Glove Detector model to recreate the prediction on the image!"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
