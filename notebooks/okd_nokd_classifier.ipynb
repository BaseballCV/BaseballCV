{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nn1S1uCNrxPB"
      },
      "source": [
        "# OKD-NOKD Dataset and Pose Detection Use-Case\n",
        "---\n",
        "### Exploring the classification of catcher positioning (one-knee down vs. both knees down) by utilizing the pose of the catcher for datapoints with a classification model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m09A8n4djDwY"
      },
      "source": [
        "## Pre-work\n",
        "\n",
        "Let's make sure that we have access to GPU. We can use `nvidia-smi` command to do that. In case of any problems navigate to `Edit` -> `Notebook settings` -> `Hardware accelerator`, set it to `GPU`, and then click `Save`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5hX88yficL7",
        "outputId": "a1a5e6a2-bcb4-46b4-cea6-2afa09e9b43e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Thu Oct 17 04:12:31 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   48C    P8              10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X8oLIkX2l2P0"
      },
      "source": [
        "## Clone BaseballCV Repo, set as Current Directory and Install Requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NcQ87h5Ib1Cw",
        "outputId": "f372570d-4940-42a8-9418-19652c500c0e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'BaseballCV'...\n",
            "remote: Enumerating objects: 781, done.\u001b[K\n",
            "remote: Counting objects: 100% (214/214), done.\u001b[K\n",
            "remote: Compressing objects: 100% (190/190), done.\u001b[K\n",
            "remote: Total 781 (delta 69), reused 68 (delta 20), pack-reused 567 (from 1)\u001b[K\n",
            "Receiving objects: 100% (781/781), 349.30 MiB | 35.37 MiB/s, done.\n",
            "Resolving deltas: 100% (297/297), done.\n",
            "/content/BaseballCV\n",
            "Collecting bs4==0.0.2 (from -r requirements.txt (line 1))\n",
            "  Downloading bs4-0.0.2-py2.py3-none-any.whl.metadata (411 bytes)\n",
            "Requirement already satisfied: cryptography==43.0.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (43.0.1)\n",
            "Requirement already satisfied: opencv-python==4.10.0.84 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (4.10.0.84)\n",
            "Collecting pip==24.0 (from -r requirements.txt (line 4))\n",
            "  Downloading pip-24.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting pybaseball==2.2.7 (from -r requirements.txt (line 5))\n",
            "  Downloading pybaseball-2.2.7-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting pytest==8.3.2 (from -r requirements.txt (line 6))\n",
            "  Downloading pytest-8.3.2-py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting ultralytics>=8.2.90 (from -r requirements.txt (line 7))\n",
            "  Downloading ultralytics-8.3.15-py3-none-any.whl.metadata (34 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from bs4==0.0.2->-r requirements.txt (line 1)) (4.12.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography==43.0.1->-r requirements.txt (line 2)) (1.17.1)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python==4.10.0.84->-r requirements.txt (line 3)) (1.26.4)\n",
            "Requirement already satisfied: pandas>=1.0.3 in /usr/local/lib/python3.10/dist-packages (from pybaseball==2.2.7->-r requirements.txt (line 5)) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.18.1 in /usr/local/lib/python3.10/dist-packages (from pybaseball==2.2.7->-r requirements.txt (line 5)) (2.32.3)\n",
            "Requirement already satisfied: lxml>=4.2.1 in /usr/local/lib/python3.10/dist-packages (from pybaseball==2.2.7->-r requirements.txt (line 5)) (4.9.4)\n",
            "Requirement already satisfied: pyarrow>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from pybaseball==2.2.7->-r requirements.txt (line 5)) (16.1.0)\n",
            "Collecting pygithub>=1.51 (from pybaseball==2.2.7->-r requirements.txt (line 5))\n",
            "  Downloading PyGithub-2.4.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: scipy>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from pybaseball==2.2.7->-r requirements.txt (line 5)) (1.13.1)\n",
            "Requirement already satisfied: matplotlib>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pybaseball==2.2.7->-r requirements.txt (line 5)) (3.7.1)\n",
            "Requirement already satisfied: tqdm>=4.50.0 in /usr/local/lib/python3.10/dist-packages (from pybaseball==2.2.7->-r requirements.txt (line 5)) (4.66.5)\n",
            "Requirement already satisfied: attrs>=20.3.0 in /usr/local/lib/python3.10/dist-packages (from pybaseball==2.2.7->-r requirements.txt (line 5)) (24.2.0)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest==8.3.2->-r requirements.txt (line 6)) (2.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pytest==8.3.2->-r requirements.txt (line 6)) (24.1)\n",
            "Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.10/dist-packages (from pytest==8.3.2->-r requirements.txt (line 6)) (1.5.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest==8.3.2->-r requirements.txt (line 6)) (1.2.2)\n",
            "Requirement already satisfied: tomli>=1 in /usr/local/lib/python3.10/dist-packages (from pytest==8.3.2->-r requirements.txt (line 6)) (2.0.2)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics>=8.2.90->-r requirements.txt (line 7)) (10.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics>=8.2.90->-r requirements.txt (line 7)) (6.0.2)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics>=8.2.90->-r requirements.txt (line 7)) (2.4.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics>=8.2.90->-r requirements.txt (line 7)) (0.19.1+cu121)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics>=8.2.90->-r requirements.txt (line 7)) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics>=8.2.90->-r requirements.txt (line 7)) (9.0.0)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics>=8.2.90->-r requirements.txt (line 7)) (0.13.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics>=8.2.90->-r requirements.txt (line 7))\n",
            "  Downloading ultralytics_thop-2.0.9-py3-none-any.whl.metadata (9.3 kB)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->bs4==0.0.2->-r requirements.txt (line 1)) (2.6)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography==43.0.1->-r requirements.txt (line 2)) (2.22)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->pybaseball==2.2.7->-r requirements.txt (line 5)) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->pybaseball==2.2.7->-r requirements.txt (line 5)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->pybaseball==2.2.7->-r requirements.txt (line 5)) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->pybaseball==2.2.7->-r requirements.txt (line 5)) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->pybaseball==2.2.7->-r requirements.txt (line 5)) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->pybaseball==2.2.7->-r requirements.txt (line 5)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.3->pybaseball==2.2.7->-r requirements.txt (line 5)) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.3->pybaseball==2.2.7->-r requirements.txt (line 5)) (2024.2)\n",
            "Collecting pynacl>=1.4.0 (from pygithub>=1.51->pybaseball==2.2.7->-r requirements.txt (line 5))\n",
            "  Downloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl.metadata (8.6 kB)\n",
            "Requirement already satisfied: pyjwt>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from pyjwt[crypto]>=2.4.0->pygithub>=1.51->pybaseball==2.2.7->-r requirements.txt (line 5)) (2.9.0)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from pygithub>=1.51->pybaseball==2.2.7->-r requirements.txt (line 5)) (4.12.2)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from pygithub>=1.51->pybaseball==2.2.7->-r requirements.txt (line 5)) (2.2.3)\n",
            "Requirement already satisfied: Deprecated in /usr/local/lib/python3.10/dist-packages (from pygithub>=1.51->pybaseball==2.2.7->-r requirements.txt (line 5)) (1.2.14)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.18.1->pybaseball==2.2.7->-r requirements.txt (line 5)) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.18.1->pybaseball==2.2.7->-r requirements.txt (line 5)) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.18.1->pybaseball==2.2.7->-r requirements.txt (line 5)) (2024.8.30)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics>=8.2.90->-r requirements.txt (line 7)) (3.16.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics>=8.2.90->-r requirements.txt (line 7)) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics>=8.2.90->-r requirements.txt (line 7)) (3.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics>=8.2.90->-r requirements.txt (line 7)) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics>=8.2.90->-r requirements.txt (line 7)) (2024.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=2.0.0->pybaseball==2.2.7->-r requirements.txt (line 5)) (1.16.0)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from Deprecated->pygithub>=1.51->pybaseball==2.2.7->-r requirements.txt (line 5)) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics>=8.2.90->-r requirements.txt (line 7)) (3.0.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics>=8.2.90->-r requirements.txt (line 7)) (1.3.0)\n",
            "Downloading bs4-0.0.2-py2.py3-none-any.whl (1.2 kB)\n",
            "Downloading pip-24.0-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pybaseball-2.2.7-py3-none-any.whl (426 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m426.1/426.1 kB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytest-8.3.2-py3-none-any.whl (341 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.8/341.8 kB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics-8.3.15-py3-none-any.whl (870 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m870.5/870.5 kB\u001b[0m \u001b[31m53.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading PyGithub-2.4.0-py3-none-any.whl (362 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m362.6/362.6 kB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.9-py3-none-any.whl (26 kB)\n",
            "Downloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (856 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m856.7/856.7 kB\u001b[0m \u001b[31m55.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pytest, pip, pynacl, bs4, ultralytics-thop, ultralytics, pygithub, pybaseball\n",
            "  Attempting uninstall: pytest\n",
            "    Found existing installation: pytest 7.4.4\n",
            "    Uninstalling pytest-7.4.4:\n",
            "      Successfully uninstalled pytest-7.4.4\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 24.1.2\n",
            "    Uninstalling pip-24.1.2:\n",
            "      Successfully uninstalled pip-24.1.2\n",
            "Successfully installed bs4-0.0.2 pip-24.0 pybaseball-2.2.7 pygithub-2.4.0 pynacl-1.5.0 pytest-8.3.2 ultralytics-8.3.15 ultralytics-thop-2.0.9\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/dylandru/BaseballCV.git\n",
        "%cd BaseballCV\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uuPwBhRjrxPH"
      },
      "source": [
        "\n",
        "## Data Prep from Pose Points for OKD/NOKD Classification\n",
        "\n",
        "- Import required libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6a11uCouRE1",
        "outputId": "6082719f-43bd-440a-cd25-4c913b25cf27"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import os\n",
        "import pandas as pd\n",
        "from ultralytics import YOLO\n",
        "from baseballcv.functions import LoadTools\n",
        "\n",
        "# Initialize LoadTools class\n",
        "load_tools = LoadTools()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQULbituuKCQ"
      },
      "source": [
        "- Load pose model and dataset OKD_NOKD\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xd2m5IlWuec7",
        "outputId": "9e2155a6-6cf2-420e-aeec-0a63293d3a59"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8l-pose.pt to 'yolov8l-pose.pt'...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 85.3M/85.3M [00:00<00:00, 113MB/s]\n",
            "Downloading OKD_NOKD: 100%|██████████| 113M/113M [00:02<00:00, 43.9MiB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset downloaded and extracted to OKD_NOKD\n"
          ]
        }
      ],
      "source": [
        "pose_model = YOLO(\"yolov8l-pose.pt\")\n",
        "\n",
        "load_tools.load_dataset(\"okd_nokd\")\n",
        "\n",
        "# input folder with OKD and NOKD classification folders\n",
        "input_folder = \"OKD_NOKD/data/\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q2e-QsBDuMXn"
      },
      "source": [
        "- Apply YOLO pose detection (using large v8 model) for keypoints\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aI-qRAl_uiYK",
        "outputId": "bc70c3b9-b8dd-40d3-b4bd-6dbf14da4377"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "0: 640x640 4 persons, 39.5ms\n",
            "Speed: 2.3ms preprocess, 39.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 10 persons, 37.1ms\n",
            "Speed: 2.3ms preprocess, 37.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 37.3ms\n",
            "Speed: 2.9ms preprocess, 37.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 39.1ms\n",
            "Speed: 2.6ms preprocess, 39.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 36.7ms\n",
            "Speed: 2.8ms preprocess, 36.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 38.1ms\n",
            "Speed: 2.3ms preprocess, 38.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 38.6ms\n",
            "Speed: 2.1ms preprocess, 38.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 37.1ms\n",
            "Speed: 2.8ms preprocess, 37.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 38.3ms\n",
            "Speed: 2.2ms preprocess, 38.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 38.9ms\n",
            "Speed: 2.2ms preprocess, 38.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 37.2ms\n",
            "Speed: 2.0ms preprocess, 37.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 37.4ms\n",
            "Speed: 2.2ms preprocess, 37.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 39.8ms\n",
            "Speed: 2.4ms preprocess, 39.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 37.1ms\n",
            "Speed: 2.2ms preprocess, 37.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 9 persons, 38.0ms\n",
            "Speed: 2.5ms preprocess, 38.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 39.4ms\n",
            "Speed: 2.1ms preprocess, 39.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 11 persons, 36.7ms\n",
            "Speed: 2.2ms preprocess, 36.7ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 37.6ms\n",
            "Speed: 2.2ms preprocess, 37.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 38.6ms\n",
            "Speed: 2.9ms preprocess, 38.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 8 persons, 36.9ms\n",
            "Speed: 2.3ms preprocess, 36.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 9 persons, 38.5ms\n",
            "Speed: 2.1ms preprocess, 38.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 persons, 38.0ms\n",
            "Speed: 3.0ms preprocess, 38.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 37.0ms\n",
            "Speed: 2.3ms preprocess, 37.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 38.5ms\n",
            "Speed: 2.1ms preprocess, 38.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 11 persons, 38.1ms\n",
            "Speed: 2.1ms preprocess, 38.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 persons, 37.1ms\n",
            "Speed: 2.6ms preprocess, 37.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 13 persons, 38.5ms\n",
            "Speed: 2.9ms preprocess, 38.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 37.6ms\n",
            "Speed: 2.4ms preprocess, 37.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 8 persons, 37.1ms\n",
            "Speed: 2.4ms preprocess, 37.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 39.2ms\n",
            "Speed: 2.9ms preprocess, 39.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 10 persons, 37.7ms\n",
            "Speed: 2.0ms preprocess, 37.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 37.7ms\n",
            "Speed: 2.1ms preprocess, 37.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 9 persons, 39.2ms\n",
            "Speed: 2.2ms preprocess, 39.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 10 persons, 37.4ms\n",
            "Speed: 2.0ms preprocess, 37.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 38.2ms\n",
            "Speed: 2.5ms preprocess, 38.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 39.7ms\n",
            "Speed: 2.4ms preprocess, 39.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 36.6ms\n",
            "Speed: 2.6ms preprocess, 36.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 persons, 37.8ms\n",
            "Speed: 3.0ms preprocess, 37.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 37.7ms\n",
            "Speed: 2.4ms preprocess, 37.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 37.0ms\n",
            "Speed: 2.4ms preprocess, 37.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 39.1ms\n",
            "Speed: 2.5ms preprocess, 39.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 10 persons, 37.1ms\n",
            "Speed: 2.4ms preprocess, 37.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 8 persons, 37.7ms\n",
            "Speed: 2.1ms preprocess, 37.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 39.1ms\n",
            "Speed: 2.5ms preprocess, 39.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 persons, 37.2ms\n",
            "Speed: 2.2ms preprocess, 37.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 38.1ms\n",
            "Speed: 2.4ms preprocess, 38.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 9 persons, 37.7ms\n",
            "Speed: 2.6ms preprocess, 37.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 9 persons, 37.7ms\n",
            "Speed: 2.4ms preprocess, 37.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 39.9ms\n",
            "Speed: 2.2ms preprocess, 39.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 38.2ms\n",
            "Speed: 1.9ms preprocess, 38.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 38.1ms\n",
            "Speed: 1.9ms preprocess, 38.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 9 persons, 39.6ms\n",
            "Speed: 2.4ms preprocess, 39.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 36.7ms\n",
            "Speed: 2.7ms preprocess, 36.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 persons, 38.1ms\n",
            "Speed: 2.5ms preprocess, 38.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 37.7ms\n",
            "Speed: 3.0ms preprocess, 37.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 13 persons, 37.1ms\n",
            "Speed: 3.0ms preprocess, 37.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 8 persons, 39.5ms\n",
            "Speed: 2.4ms preprocess, 39.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 37.1ms\n",
            "Speed: 2.7ms preprocess, 37.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 10 persons, 37.8ms\n",
            "Speed: 2.8ms preprocess, 37.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 38.1ms\n",
            "Speed: 3.1ms preprocess, 38.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 11 persons, 36.6ms\n",
            "Speed: 2.4ms preprocess, 36.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 persons, 38.4ms\n",
            "Speed: 3.0ms preprocess, 38.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 8 persons, 37.1ms\n",
            "Speed: 2.3ms preprocess, 37.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 37.1ms\n",
            "Speed: 2.7ms preprocess, 37.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 persons, 38.5ms\n",
            "Speed: 2.2ms preprocess, 38.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 37.4ms\n",
            "Speed: 2.5ms preprocess, 37.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 persons, 39.0ms\n",
            "Speed: 2.4ms preprocess, 39.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 37.8ms\n",
            "Speed: 2.5ms preprocess, 37.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 10 persons, 38.1ms\n",
            "Speed: 2.2ms preprocess, 38.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 8 persons, 39.4ms\n",
            "Speed: 2.1ms preprocess, 39.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 37.5ms\n",
            "Speed: 2.1ms preprocess, 37.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 38.1ms\n",
            "Speed: 2.2ms preprocess, 38.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 39.5ms\n",
            "Speed: 2.2ms preprocess, 39.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 37.5ms\n",
            "Speed: 2.3ms preprocess, 37.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 38.1ms\n",
            "Speed: 2.5ms preprocess, 38.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 39.8ms\n",
            "Speed: 2.3ms preprocess, 39.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 9 persons, 37.0ms\n",
            "Speed: 2.3ms preprocess, 37.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 37.8ms\n",
            "Speed: 2.3ms preprocess, 37.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 38.3ms\n",
            "Speed: 2.8ms preprocess, 38.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 37.2ms\n",
            "Speed: 2.7ms preprocess, 37.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 38.7ms\n",
            "Speed: 2.0ms preprocess, 38.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 38.9ms\n",
            "Speed: 2.2ms preprocess, 38.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 38.1ms\n",
            "Speed: 2.5ms preprocess, 38.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 39.6ms\n",
            "Speed: 2.4ms preprocess, 39.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 37.5ms\n",
            "Speed: 2.4ms preprocess, 37.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 37.8ms\n",
            "Speed: 2.4ms preprocess, 37.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 11 persons, 38.3ms\n",
            "Speed: 2.5ms preprocess, 38.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 36.9ms\n",
            "Speed: 2.4ms preprocess, 36.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 10 persons, 37.1ms\n",
            "Speed: 2.6ms preprocess, 37.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 37.7ms\n",
            "Speed: 2.2ms preprocess, 37.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 37.4ms\n",
            "Speed: 2.1ms preprocess, 37.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 39.0ms\n",
            "Speed: 2.3ms preprocess, 39.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 38.6ms\n",
            "Speed: 2.3ms preprocess, 38.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 37.7ms\n",
            "Speed: 2.1ms preprocess, 37.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 40.4ms\n",
            "Speed: 2.1ms preprocess, 40.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 8 persons, 37.7ms\n",
            "Speed: 2.3ms preprocess, 37.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 37.3ms\n",
            "Speed: 2.4ms preprocess, 37.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 10 persons, 39.9ms\n",
            "Speed: 2.6ms preprocess, 39.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 9 persons, 38.0ms\n",
            "Speed: 2.3ms preprocess, 38.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 38.1ms\n",
            "Speed: 2.2ms preprocess, 38.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 8 persons, 39.5ms\n",
            "Speed: 2.1ms preprocess, 39.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 9 persons, 36.9ms\n",
            "Speed: 2.4ms preprocess, 36.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 38.4ms\n",
            "Speed: 2.2ms preprocess, 38.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 10 persons, 38.8ms\n",
            "Speed: 2.9ms preprocess, 38.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 8 persons, 37.2ms\n",
            "Speed: 2.5ms preprocess, 37.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 12 persons, 38.5ms\n",
            "Speed: 2.4ms preprocess, 38.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 38.1ms\n",
            "Speed: 2.2ms preprocess, 38.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 37.0ms\n",
            "Speed: 2.2ms preprocess, 37.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 38.3ms\n",
            "Speed: 2.3ms preprocess, 38.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 38.3ms\n",
            "Speed: 2.4ms preprocess, 38.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 38.2ms\n",
            "Speed: 3.0ms preprocess, 38.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 10 persons, 39.5ms\n",
            "Speed: 2.0ms preprocess, 39.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 37.2ms\n",
            "Speed: 2.2ms preprocess, 37.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 10 persons, 38.4ms\n",
            "Speed: 2.0ms preprocess, 38.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 10 persons, 38.4ms\n",
            "Speed: 2.6ms preprocess, 38.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 37.8ms\n",
            "Speed: 2.1ms preprocess, 37.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 8 persons, 39.5ms\n",
            "Speed: 2.2ms preprocess, 39.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 37.7ms\n",
            "Speed: 2.0ms preprocess, 37.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 37.9ms\n",
            "Speed: 3.0ms preprocess, 37.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 40.0ms\n",
            "Speed: 2.3ms preprocess, 40.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 10 persons, 37.9ms\n",
            "Speed: 2.7ms preprocess, 37.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 13 persons, 38.5ms\n",
            "Speed: 2.1ms preprocess, 38.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 39.6ms\n",
            "Speed: 2.2ms preprocess, 39.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 13 persons, 37.4ms\n",
            "Speed: 2.1ms preprocess, 37.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 10 persons, 38.5ms\n",
            "Speed: 2.3ms preprocess, 38.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 39.5ms\n",
            "Speed: 2.7ms preprocess, 39.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 persons, 37.1ms\n",
            "Speed: 2.5ms preprocess, 37.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 38.6ms\n",
            "Speed: 2.5ms preprocess, 38.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 persons, 38.1ms\n",
            "Speed: 2.5ms preprocess, 38.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 9 persons, 38.1ms\n",
            "Speed: 2.5ms preprocess, 38.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 38.2ms\n",
            "Speed: 3.0ms preprocess, 38.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 14 persons, 37.5ms\n",
            "Speed: 2.5ms preprocess, 37.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 39.2ms\n",
            "Speed: 2.3ms preprocess, 39.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 13 persons, 37.5ms\n",
            "Speed: 2.1ms preprocess, 37.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 37.9ms\n",
            "Speed: 2.2ms preprocess, 37.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 39.9ms\n",
            "Speed: 2.7ms preprocess, 39.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 37.0ms\n",
            "Speed: 3.2ms preprocess, 37.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 16 persons, 38.5ms\n",
            "Speed: 2.0ms preprocess, 38.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 10 persons, 39.6ms\n",
            "Speed: 2.1ms preprocess, 39.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 8 persons, 37.9ms\n",
            "Speed: 2.2ms preprocess, 37.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 persons, 38.4ms\n",
            "Speed: 2.3ms preprocess, 38.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 13 persons, 39.3ms\n",
            "Speed: 2.1ms preprocess, 39.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 10 persons, 37.4ms\n",
            "Speed: 2.1ms preprocess, 37.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 38.5ms\n",
            "Speed: 2.6ms preprocess, 38.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 38.3ms\n",
            "Speed: 2.5ms preprocess, 38.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 37.6ms\n",
            "Speed: 2.0ms preprocess, 37.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 38.7ms\n",
            "Speed: 2.2ms preprocess, 38.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 38.9ms\n",
            "Speed: 2.4ms preprocess, 38.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 12 persons, 38.1ms\n",
            "Speed: 2.2ms preprocess, 38.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 39.9ms\n",
            "Speed: 2.0ms preprocess, 39.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 15 persons, 37.4ms\n",
            "Speed: 2.3ms preprocess, 37.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 37.7ms\n",
            "Speed: 2.3ms preprocess, 37.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 8 persons, 39.5ms\n",
            "Speed: 2.1ms preprocess, 39.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 37.4ms\n",
            "Speed: 2.1ms preprocess, 37.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 8 persons, 38.9ms\n",
            "Speed: 2.6ms preprocess, 38.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 39.1ms\n",
            "Speed: 2.3ms preprocess, 39.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 8 persons, 37.6ms\n",
            "Speed: 2.1ms preprocess, 37.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 39.0ms\n",
            "Speed: 2.3ms preprocess, 39.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 12 persons, 39.0ms\n",
            "Speed: 2.1ms preprocess, 39.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 8 persons, 38.1ms\n",
            "Speed: 2.2ms preprocess, 38.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 9 persons, 40.1ms\n",
            "Speed: 2.8ms preprocess, 40.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 9 persons, 38.1ms\n",
            "Speed: 2.3ms preprocess, 38.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 12 persons, 38.1ms\n",
            "Speed: 2.8ms preprocess, 38.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 10 persons, 39.9ms\n",
            "Speed: 2.1ms preprocess, 39.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 37.2ms\n",
            "Speed: 2.3ms preprocess, 37.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 38.5ms\n",
            "Speed: 2.5ms preprocess, 38.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 38.8ms\n",
            "Speed: 2.1ms preprocess, 38.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 persons, 37.2ms\n",
            "Speed: 2.9ms preprocess, 37.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 38.7ms\n",
            "Speed: 2.6ms preprocess, 38.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 persons, 38.3ms\n",
            "Speed: 2.4ms preprocess, 38.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 38.1ms\n",
            "Speed: 2.9ms preprocess, 38.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 persons, 39.1ms\n",
            "Speed: 2.4ms preprocess, 39.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 persons, 37.4ms\n",
            "Speed: 2.2ms preprocess, 37.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 10 persons, 38.9ms\n",
            "Speed: 2.2ms preprocess, 38.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 13 persons, 39.0ms\n",
            "Speed: 2.1ms preprocess, 39.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 38.4ms\n",
            "Speed: 2.6ms preprocess, 38.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 persons, 40.0ms\n",
            "Speed: 2.0ms preprocess, 40.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 9 persons, 38.5ms\n",
            "Speed: 2.4ms preprocess, 38.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 38.4ms\n",
            "Speed: 2.8ms preprocess, 38.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 40.2ms\n",
            "Speed: 2.1ms preprocess, 40.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 37.9ms\n",
            "Speed: 2.3ms preprocess, 37.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 38.1ms\n",
            "Speed: 2.2ms preprocess, 38.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 40.1ms\n",
            "Speed: 2.1ms preprocess, 40.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 38.3ms\n",
            "Speed: 2.2ms preprocess, 38.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 40.0ms\n",
            "Speed: 2.1ms preprocess, 40.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 37.5ms\n",
            "Speed: 2.4ms preprocess, 37.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 37.7ms\n",
            "Speed: 2.3ms preprocess, 37.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 39.9ms\n",
            "Speed: 2.2ms preprocess, 39.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 37.7ms\n",
            "Speed: 2.1ms preprocess, 37.7ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 37.8ms\n",
            "Speed: 2.4ms preprocess, 37.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 10 persons, 39.2ms\n",
            "Speed: 2.2ms preprocess, 39.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 37.4ms\n",
            "Speed: 2.2ms preprocess, 37.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 38.5ms\n",
            "Speed: 2.4ms preprocess, 38.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 38.4ms\n",
            "Speed: 3.0ms preprocess, 38.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 persons, 37.8ms\n",
            "Speed: 2.1ms preprocess, 37.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 38.9ms\n",
            "Speed: 2.1ms preprocess, 38.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 12 persons, 38.5ms\n",
            "Speed: 3.0ms preprocess, 38.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 37.8ms\n",
            "Speed: 2.0ms preprocess, 37.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 40.1ms\n",
            "Speed: 2.3ms preprocess, 40.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 9 persons, 37.9ms\n",
            "Speed: 2.7ms preprocess, 37.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 38.5ms\n",
            "Speed: 2.2ms preprocess, 38.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 40.1ms\n",
            "Speed: 2.1ms preprocess, 40.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 11 persons, 37.6ms\n",
            "Speed: 2.3ms preprocess, 37.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 9 persons, 39.0ms\n",
            "Speed: 2.1ms preprocess, 39.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 39.4ms\n",
            "Speed: 2.4ms preprocess, 39.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 8 persons, 37.4ms\n",
            "Speed: 3.0ms preprocess, 37.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 38.5ms\n",
            "Speed: 2.1ms preprocess, 38.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 11 persons, 38.9ms\n",
            "Speed: 2.0ms preprocess, 38.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 38.1ms\n",
            "Speed: 2.0ms preprocess, 38.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 39.7ms\n",
            "Speed: 2.4ms preprocess, 39.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 38.7ms\n",
            "Speed: 2.2ms preprocess, 38.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 10 persons, 38.5ms\n",
            "Speed: 2.2ms preprocess, 38.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 39.5ms\n",
            "Speed: 2.0ms preprocess, 39.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 37.4ms\n",
            "Speed: 2.2ms preprocess, 37.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 12 persons, 38.2ms\n",
            "Speed: 2.3ms preprocess, 38.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 39.5ms\n",
            "Speed: 2.3ms preprocess, 39.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 38.0ms\n",
            "Speed: 2.2ms preprocess, 38.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 14 persons, 39.8ms\n",
            "Speed: 2.2ms preprocess, 39.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 39.6ms\n",
            "Speed: 2.2ms preprocess, 39.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 38.4ms\n",
            "Speed: 2.3ms preprocess, 38.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 40.0ms\n",
            "Speed: 2.4ms preprocess, 40.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 38.1ms\n",
            "Speed: 2.1ms preprocess, 38.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 38.6ms\n",
            "Speed: 3.0ms preprocess, 38.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 38.9ms\n",
            "Speed: 2.4ms preprocess, 38.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 38.2ms\n",
            "Speed: 2.5ms preprocess, 38.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 persons, 39.3ms\n",
            "Speed: 2.2ms preprocess, 39.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 38.5ms\n",
            "Speed: 2.6ms preprocess, 38.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 38.1ms\n",
            "Speed: 2.0ms preprocess, 38.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 9 persons, 39.5ms\n",
            "Speed: 2.1ms preprocess, 39.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 37.4ms\n",
            "Speed: 2.0ms preprocess, 37.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 8 persons, 38.2ms\n",
            "Speed: 2.0ms preprocess, 38.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 39.0ms\n",
            "Speed: 2.9ms preprocess, 39.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 13 persons, 38.3ms\n",
            "Speed: 2.1ms preprocess, 38.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 40.2ms\n",
            "Speed: 2.1ms preprocess, 40.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 13 persons, 38.6ms\n",
            "Speed: 2.2ms preprocess, 38.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 10 persons, 38.4ms\n",
            "Speed: 2.3ms preprocess, 38.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 39.6ms\n",
            "Speed: 2.2ms preprocess, 39.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 37.3ms\n",
            "Speed: 2.3ms preprocess, 37.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 39.2ms\n",
            "Speed: 2.4ms preprocess, 39.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 39.1ms\n",
            "Speed: 1.9ms preprocess, 39.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 persons, 38.0ms\n",
            "Speed: 2.0ms preprocess, 38.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 8 persons, 39.9ms\n",
            "Speed: 3.0ms preprocess, 39.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 37.4ms\n",
            "Speed: 2.4ms preprocess, 37.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 38.5ms\n",
            "Speed: 2.2ms preprocess, 38.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 8 persons, 40.6ms\n",
            "Speed: 2.8ms preprocess, 40.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 13 persons, 38.2ms\n",
            "Speed: 2.2ms preprocess, 38.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 persons, 38.9ms\n",
            "Speed: 2.2ms preprocess, 38.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 12 persons, 39.9ms\n",
            "Speed: 2.1ms preprocess, 39.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 9 persons, 37.7ms\n",
            "Speed: 2.7ms preprocess, 37.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 38.9ms\n",
            "Speed: 2.1ms preprocess, 38.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 39.1ms\n",
            "Speed: 2.9ms preprocess, 39.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 38.3ms\n",
            "Speed: 2.3ms preprocess, 38.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 39.3ms\n",
            "Speed: 2.3ms preprocess, 39.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 40.2ms\n",
            "Speed: 2.4ms preprocess, 40.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 39.3ms\n",
            "Speed: 3.0ms preprocess, 39.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 11 persons, 37.8ms\n",
            "Speed: 2.1ms preprocess, 37.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 persons, 37.6ms\n",
            "Speed: 2.9ms preprocess, 37.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 9 persons, 40.0ms\n",
            "Speed: 2.5ms preprocess, 40.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 37.5ms\n",
            "Speed: 2.2ms preprocess, 37.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 38.9ms\n",
            "Speed: 2.5ms preprocess, 38.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 39.0ms\n",
            "Speed: 2.3ms preprocess, 39.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 8 persons, 38.2ms\n",
            "Speed: 2.2ms preprocess, 38.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 15 persons, 40.0ms\n",
            "Speed: 2.7ms preprocess, 40.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 38.1ms\n",
            "Speed: 2.2ms preprocess, 38.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 10 persons, 38.5ms\n",
            "Speed: 2.3ms preprocess, 38.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 9 persons, 40.1ms\n",
            "Speed: 2.1ms preprocess, 40.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 11 persons, 37.5ms\n",
            "Speed: 2.0ms preprocess, 37.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 39.4ms\n",
            "Speed: 2.2ms preprocess, 39.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 39.7ms\n",
            "Speed: 2.3ms preprocess, 39.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 9 persons, 37.8ms\n",
            "Speed: 2.0ms preprocess, 37.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 40.0ms\n",
            "Speed: 2.0ms preprocess, 40.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 10 persons, 39.6ms\n",
            "Speed: 2.6ms preprocess, 39.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 38.2ms\n",
            "Speed: 3.0ms preprocess, 38.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 40.0ms\n",
            "Speed: 2.4ms preprocess, 40.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 38.2ms\n",
            "Speed: 2.3ms preprocess, 38.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 persons, 39.1ms\n",
            "Speed: 3.2ms preprocess, 39.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 10 persons, 37.6ms\n",
            "Speed: 2.7ms preprocess, 37.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 38.6ms\n",
            "Speed: 2.8ms preprocess, 38.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 9 persons, 39.5ms\n",
            "Speed: 2.3ms preprocess, 39.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 38.9ms\n",
            "Speed: 2.2ms preprocess, 38.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 11 persons, 40.1ms\n",
            "Speed: 3.0ms preprocess, 40.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 8 persons, 37.0ms\n",
            "Speed: 2.8ms preprocess, 37.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 12 persons, 37.8ms\n",
            "Speed: 2.0ms preprocess, 37.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 39.1ms\n",
            "Speed: 2.3ms preprocess, 39.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 12 persons, 37.9ms\n",
            "Speed: 2.9ms preprocess, 37.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 40.4ms\n",
            "Speed: 2.4ms preprocess, 40.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 37.1ms\n",
            "Speed: 3.0ms preprocess, 37.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 persons, 39.1ms\n",
            "Speed: 2.6ms preprocess, 39.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 38.7ms\n",
            "Speed: 2.2ms preprocess, 38.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 37.8ms\n",
            "Speed: 2.6ms preprocess, 37.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 11 persons, 40.2ms\n",
            "Speed: 2.2ms preprocess, 40.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 9 persons, 38.7ms\n",
            "Speed: 2.1ms preprocess, 38.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 39.4ms\n",
            "Speed: 2.3ms preprocess, 39.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 9 persons, 38.2ms\n",
            "Speed: 2.9ms preprocess, 38.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 38.5ms\n",
            "Speed: 2.1ms preprocess, 38.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 9 persons, 39.8ms\n",
            "Speed: 2.5ms preprocess, 39.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 9 persons, 38.2ms\n",
            "Speed: 2.4ms preprocess, 38.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 persons, 39.3ms\n",
            "Speed: 2.7ms preprocess, 39.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 9 persons, 38.1ms\n",
            "Speed: 2.5ms preprocess, 38.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 13 persons, 41.1ms\n",
            "Speed: 2.4ms preprocess, 41.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 37.9ms\n",
            "Speed: 1.9ms preprocess, 37.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 persons, 39.5ms\n",
            "Speed: 2.5ms preprocess, 39.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 39.2ms\n",
            "Speed: 2.6ms preprocess, 39.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 38.6ms\n",
            "Speed: 2.7ms preprocess, 38.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 18 persons, 40.2ms\n",
            "Speed: 2.3ms preprocess, 40.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 37.8ms\n",
            "Speed: 3.2ms preprocess, 37.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 40.5ms\n",
            "Speed: 2.3ms preprocess, 40.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 38.2ms\n",
            "Speed: 2.4ms preprocess, 38.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 39.3ms\n",
            "Speed: 2.2ms preprocess, 39.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 9 persons, 39.3ms\n",
            "Speed: 2.3ms preprocess, 39.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 38.4ms\n",
            "Speed: 2.2ms preprocess, 38.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 persons, 41.7ms\n",
            "Speed: 1.9ms preprocess, 41.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 37.9ms\n",
            "Speed: 2.3ms preprocess, 37.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 8 persons, 38.7ms\n",
            "Speed: 3.0ms preprocess, 38.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 39.1ms\n",
            "Speed: 2.8ms preprocess, 39.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 15 persons, 38.6ms\n",
            "Speed: 2.3ms preprocess, 38.6ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 15 persons, 38.5ms\n",
            "Speed: 2.5ms preprocess, 38.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 37.9ms\n",
            "Speed: 2.8ms preprocess, 37.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 8 persons, 41.0ms\n",
            "Speed: 2.5ms preprocess, 41.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 persons, 37.2ms\n",
            "Speed: 2.4ms preprocess, 37.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 13 persons, 38.9ms\n",
            "Speed: 2.0ms preprocess, 38.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 39.5ms\n",
            "Speed: 2.0ms preprocess, 39.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 13 persons, 38.5ms\n",
            "Speed: 2.1ms preprocess, 38.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 15 persons, 41.1ms\n",
            "Speed: 2.3ms preprocess, 41.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 12 persons, 38.9ms\n",
            "Speed: 2.0ms preprocess, 38.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 38.9ms\n",
            "Speed: 2.6ms preprocess, 38.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 39.5ms\n",
            "Speed: 2.0ms preprocess, 39.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 11 persons, 38.0ms\n",
            "Speed: 2.2ms preprocess, 38.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 13 persons, 39.8ms\n",
            "Speed: 2.4ms preprocess, 39.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 10 persons, 38.6ms\n",
            "Speed: 2.7ms preprocess, 38.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 38.7ms\n",
            "Speed: 2.4ms preprocess, 38.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 39.9ms\n",
            "Speed: 2.0ms preprocess, 39.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 38.2ms\n",
            "Speed: 2.2ms preprocess, 38.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 39.0ms\n",
            "Speed: 2.6ms preprocess, 39.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 38.2ms\n",
            "Speed: 2.4ms preprocess, 38.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 38.2ms\n",
            "Speed: 2.8ms preprocess, 38.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 38.7ms\n",
            "Speed: 2.8ms preprocess, 38.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 38.5ms\n",
            "Speed: 2.3ms preprocess, 38.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 41.7ms\n",
            "Speed: 2.1ms preprocess, 41.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 38.0ms\n",
            "Speed: 2.6ms preprocess, 38.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 persons, 39.7ms\n",
            "Speed: 2.2ms preprocess, 39.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 persons, 39.0ms\n",
            "Speed: 2.8ms preprocess, 39.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 38.4ms\n",
            "Speed: 2.2ms preprocess, 38.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 11 persons, 41.5ms\n",
            "Speed: 2.0ms preprocess, 41.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 37.8ms\n",
            "Speed: 2.2ms preprocess, 37.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 39.2ms\n",
            "Speed: 2.0ms preprocess, 39.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 40.2ms\n",
            "Speed: 2.8ms preprocess, 40.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 38.9ms\n",
            "Speed: 2.3ms preprocess, 38.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 16 persons, 39.8ms\n",
            "Speed: 2.4ms preprocess, 39.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 37.6ms\n",
            "Speed: 2.4ms preprocess, 37.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 38.5ms\n",
            "Speed: 2.5ms preprocess, 38.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 8 persons, 40.0ms\n",
            "Speed: 2.5ms preprocess, 40.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 38.4ms\n",
            "Speed: 2.4ms preprocess, 38.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 40.8ms\n",
            "Speed: 2.4ms preprocess, 40.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 38.9ms\n",
            "Speed: 2.3ms preprocess, 38.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 10 persons, 38.9ms\n",
            "Speed: 2.3ms preprocess, 38.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 39.8ms\n",
            "Speed: 2.7ms preprocess, 39.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 38.3ms\n",
            "Speed: 2.6ms preprocess, 38.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 persons, 40.2ms\n",
            "Speed: 2.1ms preprocess, 40.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 17 persons, 38.3ms\n",
            "Speed: 2.2ms preprocess, 38.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 41.2ms\n",
            "Speed: 2.1ms preprocess, 41.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 38.5ms\n",
            "Speed: 2.4ms preprocess, 38.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 38.9ms\n",
            "Speed: 2.2ms preprocess, 38.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 38.8ms\n",
            "Speed: 2.4ms preprocess, 38.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 10 persons, 38.4ms\n",
            "Speed: 2.3ms preprocess, 38.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 11 persons, 41.0ms\n",
            "Speed: 2.0ms preprocess, 41.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 37.9ms\n",
            "Speed: 2.8ms preprocess, 37.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 39.6ms\n",
            "Speed: 2.1ms preprocess, 39.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 38.6ms\n",
            "Speed: 3.0ms preprocess, 38.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 38.4ms\n",
            "Speed: 2.5ms preprocess, 38.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 39.8ms\n",
            "Speed: 2.7ms preprocess, 39.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 10 persons, 38.2ms\n",
            "Speed: 2.1ms preprocess, 38.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 8 persons, 41.2ms\n",
            "Speed: 2.2ms preprocess, 41.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 11 persons, 37.8ms\n",
            "Speed: 2.3ms preprocess, 37.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 38.2ms\n",
            "Speed: 2.4ms preprocess, 38.2ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 8 persons, 39.6ms\n",
            "Speed: 2.4ms preprocess, 39.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 38.4ms\n",
            "Speed: 2.2ms preprocess, 38.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 8 persons, 40.3ms\n",
            "Speed: 3.1ms preprocess, 40.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 8 persons, 37.6ms\n",
            "Speed: 2.3ms preprocess, 37.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 9 persons, 39.4ms\n",
            "Speed: 2.3ms preprocess, 39.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 39.9ms\n",
            "Speed: 2.3ms preprocess, 39.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 38.4ms\n",
            "Speed: 2.4ms preprocess, 38.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 40.5ms\n",
            "Speed: 2.4ms preprocess, 40.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 38.5ms\n",
            "Speed: 2.2ms preprocess, 38.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 40.3ms\n",
            "Speed: 2.1ms preprocess, 40.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 39.2ms\n",
            "Speed: 2.3ms preprocess, 39.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 38.9ms\n",
            "Speed: 2.1ms preprocess, 38.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 9 persons, 41.4ms\n",
            "Speed: 1.9ms preprocess, 41.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 37.6ms\n",
            "Speed: 2.6ms preprocess, 37.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 10 persons, 38.9ms\n",
            "Speed: 3.0ms preprocess, 38.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 12 persons, 39.3ms\n",
            "Speed: 2.6ms preprocess, 39.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 39.0ms\n",
            "Speed: 2.4ms preprocess, 39.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 41.2ms\n",
            "Speed: 2.0ms preprocess, 41.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 37.9ms\n",
            "Speed: 2.6ms preprocess, 37.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 39.0ms\n",
            "Speed: 2.3ms preprocess, 39.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 38.4ms\n",
            "Speed: 3.2ms preprocess, 38.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 39.1ms\n",
            "Speed: 2.4ms preprocess, 39.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 9 persons, 40.0ms\n",
            "Speed: 2.0ms preprocess, 40.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 38.6ms\n",
            "Speed: 2.2ms preprocess, 38.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 40.8ms\n",
            "Speed: 2.1ms preprocess, 40.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 37.8ms\n",
            "Speed: 2.3ms preprocess, 37.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 12 persons, 39.0ms\n",
            "Speed: 2.8ms preprocess, 39.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 38.9ms\n",
            "Speed: 2.3ms preprocess, 38.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 14 persons, 39.1ms\n",
            "Speed: 2.2ms preprocess, 39.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 41.4ms\n",
            "Speed: 2.4ms preprocess, 41.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 38.0ms\n",
            "Speed: 2.3ms preprocess, 38.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 11 persons, 39.3ms\n",
            "Speed: 2.1ms preprocess, 39.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 40.4ms\n",
            "Speed: 1.9ms preprocess, 40.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 10 persons, 38.7ms\n",
            "Speed: 2.0ms preprocess, 38.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 41.2ms\n",
            "Speed: 2.7ms preprocess, 41.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 10 persons, 38.5ms\n",
            "Speed: 2.2ms preprocess, 38.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 9 persons, 39.3ms\n",
            "Speed: 2.3ms preprocess, 39.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 40.5ms\n",
            "Speed: 2.3ms preprocess, 40.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 39.1ms\n",
            "Speed: 1.9ms preprocess, 39.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 persons, 40.3ms\n",
            "Speed: 2.4ms preprocess, 40.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 10 persons, 37.8ms\n",
            "Speed: 2.2ms preprocess, 37.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 39.0ms\n",
            "Speed: 2.1ms preprocess, 39.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 10 persons, 39.6ms\n",
            "Speed: 2.2ms preprocess, 39.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 38.4ms\n",
            "Speed: 2.9ms preprocess, 38.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 8 persons, 41.0ms\n",
            "Speed: 2.7ms preprocess, 41.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 persons, 38.5ms\n",
            "Speed: 2.3ms preprocess, 38.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 persons, 41.7ms\n",
            "Speed: 2.1ms preprocess, 41.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 10 persons, 37.9ms\n",
            "Speed: 3.0ms preprocess, 37.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 39.9ms\n",
            "Speed: 2.9ms preprocess, 39.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 13 persons, 39.2ms\n",
            "Speed: 2.2ms preprocess, 39.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 38.9ms\n",
            "Speed: 2.3ms preprocess, 38.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 8 persons, 40.5ms\n",
            "Speed: 2.2ms preprocess, 40.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 38.3ms\n",
            "Speed: 2.0ms preprocess, 38.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 8 persons, 40.2ms\n",
            "Speed: 2.2ms preprocess, 40.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 9 persons, 40.5ms\n",
            "Speed: 2.1ms preprocess, 40.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 39.3ms\n",
            "Speed: 2.0ms preprocess, 39.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 persons, 40.9ms\n",
            "Speed: 2.0ms preprocess, 40.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 12 persons, 38.5ms\n",
            "Speed: 2.2ms preprocess, 38.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 40.7ms\n",
            "Speed: 2.4ms preprocess, 40.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 38.9ms\n",
            "Speed: 2.2ms preprocess, 38.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 11 persons, 39.1ms\n",
            "Speed: 2.1ms preprocess, 39.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 39.7ms\n",
            "Speed: 2.0ms preprocess, 39.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 38.8ms\n",
            "Speed: 2.5ms preprocess, 38.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 41.0ms\n",
            "Speed: 2.0ms preprocess, 41.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 38.1ms\n",
            "Speed: 1.9ms preprocess, 38.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 10 persons, 39.7ms\n",
            "Speed: 2.0ms preprocess, 39.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 persons, 39.6ms\n",
            "Speed: 2.4ms preprocess, 39.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 9 persons, 38.9ms\n",
            "Speed: 2.3ms preprocess, 38.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 14 persons, 41.4ms\n",
            "Speed: 2.2ms preprocess, 41.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 38.5ms\n",
            "Speed: 2.1ms preprocess, 38.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 39.5ms\n",
            "Speed: 2.4ms preprocess, 39.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 11 persons, 40.0ms\n",
            "Speed: 2.4ms preprocess, 40.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 38.8ms\n",
            "Speed: 2.7ms preprocess, 38.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 40.9ms\n",
            "Speed: 2.2ms preprocess, 40.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 10 persons, 38.3ms\n",
            "Speed: 2.1ms preprocess, 38.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 13 persons, 39.5ms\n",
            "Speed: 2.3ms preprocess, 39.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 39.3ms\n",
            "Speed: 1.9ms preprocess, 39.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 38.6ms\n",
            "Speed: 2.4ms preprocess, 38.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 41.6ms\n",
            "Speed: 2.3ms preprocess, 41.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 persons, 38.2ms\n",
            "Speed: 2.2ms preprocess, 38.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 40.9ms\n",
            "Speed: 2.3ms preprocess, 40.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 10 persons, 38.4ms\n",
            "Speed: 2.6ms preprocess, 38.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 8 persons, 39.4ms\n",
            "Speed: 3.0ms preprocess, 39.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 10 persons, 39.0ms\n",
            "Speed: 2.3ms preprocess, 39.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 38.8ms\n",
            "Speed: 2.5ms preprocess, 38.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 9 persons, 40.9ms\n",
            "Speed: 2.2ms preprocess, 40.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 38.8ms\n",
            "Speed: 2.0ms preprocess, 38.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 41.4ms\n",
            "Speed: 2.4ms preprocess, 41.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 38.4ms\n",
            "Speed: 2.3ms preprocess, 38.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 40.3ms\n",
            "Speed: 2.1ms preprocess, 40.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 39.1ms\n",
            "Speed: 2.1ms preprocess, 39.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 39.2ms\n",
            "Speed: 2.2ms preprocess, 39.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 11 persons, 40.4ms\n",
            "Speed: 2.3ms preprocess, 40.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 38.5ms\n",
            "Speed: 2.1ms preprocess, 38.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 41.2ms\n",
            "Speed: 2.3ms preprocess, 41.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 38.5ms\n",
            "Speed: 2.3ms preprocess, 38.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 39.1ms\n",
            "Speed: 2.8ms preprocess, 39.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 40.5ms\n",
            "Speed: 2.2ms preprocess, 40.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 39.0ms\n",
            "Speed: 2.8ms preprocess, 39.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 13 persons, 41.5ms\n",
            "Speed: 3.1ms preprocess, 41.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 38.5ms\n",
            "Speed: 2.1ms preprocess, 38.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 40.4ms\n",
            "Speed: 2.0ms preprocess, 40.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 39.5ms\n",
            "Speed: 2.6ms preprocess, 39.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 39.3ms\n",
            "Speed: 2.3ms preprocess, 39.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 8 persons, 40.2ms\n",
            "Speed: 2.4ms preprocess, 40.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 10 persons, 38.5ms\n",
            "Speed: 3.4ms preprocess, 38.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 8 persons, 40.9ms\n",
            "Speed: 2.8ms preprocess, 40.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 39.1ms\n",
            "Speed: 2.2ms preprocess, 39.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 9 persons, 41.8ms\n",
            "Speed: 1.9ms preprocess, 41.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 38.5ms\n",
            "Speed: 2.3ms preprocess, 38.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 38.9ms\n",
            "Speed: 2.7ms preprocess, 38.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 persons, 40.5ms\n",
            "Speed: 2.1ms preprocess, 40.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 39.0ms\n",
            "Speed: 2.0ms preprocess, 39.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 40.5ms\n",
            "Speed: 2.1ms preprocess, 40.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 38.9ms\n",
            "Speed: 2.1ms preprocess, 38.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 41.1ms\n",
            "Speed: 2.1ms preprocess, 41.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 12 persons, 37.9ms\n",
            "Speed: 3.0ms preprocess, 37.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 persons, 39.2ms\n",
            "Speed: 2.3ms preprocess, 39.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 39.6ms\n",
            "Speed: 2.0ms preprocess, 39.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 39.1ms\n",
            "Speed: 2.1ms preprocess, 39.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 42.1ms\n",
            "Speed: 2.2ms preprocess, 42.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 38.4ms\n",
            "Speed: 2.3ms preprocess, 38.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 12 persons, 38.9ms\n",
            "Speed: 3.1ms preprocess, 38.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 persons, 39.7ms\n",
            "Speed: 2.6ms preprocess, 39.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 8 persons, 39.1ms\n",
            "Speed: 2.0ms preprocess, 39.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 40.2ms\n",
            "Speed: 3.0ms preprocess, 40.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 9 persons, 39.2ms\n",
            "Speed: 2.4ms preprocess, 39.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 41.1ms\n",
            "Speed: 2.1ms preprocess, 41.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 11 persons, 38.8ms\n",
            "Speed: 2.2ms preprocess, 38.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 40.5ms\n",
            "Speed: 2.2ms preprocess, 40.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 39.8ms\n",
            "Speed: 2.3ms preprocess, 39.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 39.7ms\n",
            "Speed: 2.4ms preprocess, 39.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 40.4ms\n",
            "Speed: 2.8ms preprocess, 40.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 39.5ms\n",
            "Speed: 2.4ms preprocess, 39.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 10 persons, 41.5ms\n",
            "Speed: 2.3ms preprocess, 41.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 15 persons, 39.0ms\n",
            "Speed: 2.7ms preprocess, 39.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 40.3ms\n",
            "Speed: 2.8ms preprocess, 40.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 persons, 38.2ms\n",
            "Speed: 3.0ms preprocess, 38.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 12 persons, 40.7ms\n",
            "Speed: 3.1ms preprocess, 40.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 11 persons, 39.5ms\n",
            "Speed: 2.5ms preprocess, 39.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 40.9ms\n",
            "Speed: 2.1ms preprocess, 40.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 9 persons, 39.0ms\n",
            "Speed: 2.2ms preprocess, 39.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 persons, 39.8ms\n",
            "Speed: 2.3ms preprocess, 39.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 39.2ms\n",
            "Speed: 2.4ms preprocess, 39.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 8 persons, 39.0ms\n",
            "Speed: 2.4ms preprocess, 39.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 12 persons, 39.4ms\n",
            "Speed: 2.4ms preprocess, 39.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 39.1ms\n",
            "Speed: 2.2ms preprocess, 39.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 41.2ms\n",
            "Speed: 2.3ms preprocess, 41.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 38.4ms\n",
            "Speed: 2.8ms preprocess, 38.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 41.7ms\n",
            "Speed: 2.1ms preprocess, 41.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 37.9ms\n",
            "Speed: 2.2ms preprocess, 37.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 40.4ms\n",
            "Speed: 2.7ms preprocess, 40.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 39.2ms\n",
            "Speed: 2.2ms preprocess, 39.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 persons, 39.0ms\n",
            "Speed: 2.6ms preprocess, 39.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 persons, 40.3ms\n",
            "Speed: 2.0ms preprocess, 40.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 39.5ms\n",
            "Speed: 2.3ms preprocess, 39.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 9 persons, 41.1ms\n",
            "Speed: 2.5ms preprocess, 41.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 38.5ms\n",
            "Speed: 2.3ms preprocess, 38.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 40.5ms\n",
            "Speed: 2.2ms preprocess, 40.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 39.0ms\n",
            "Speed: 2.2ms preprocess, 39.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 40.9ms\n",
            "Speed: 2.6ms preprocess, 40.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 38.4ms\n",
            "Speed: 3.0ms preprocess, 38.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 9 persons, 40.3ms\n",
            "Speed: 2.5ms preprocess, 40.3ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 10 persons, 38.1ms\n",
            "Speed: 3.1ms preprocess, 38.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 persons, 39.8ms\n",
            "Speed: 2.6ms preprocess, 39.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 39.2ms\n",
            "Speed: 2.7ms preprocess, 39.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 10 persons, 39.4ms\n",
            "Speed: 2.9ms preprocess, 39.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 39.4ms\n",
            "Speed: 2.3ms preprocess, 39.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 39.5ms\n",
            "Speed: 2.3ms preprocess, 39.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 40.5ms\n",
            "Speed: 2.8ms preprocess, 40.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 38.8ms\n",
            "Speed: 3.1ms preprocess, 38.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 9 persons, 41.2ms\n",
            "Speed: 2.2ms preprocess, 41.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 8 persons, 38.5ms\n",
            "Speed: 2.1ms preprocess, 38.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 14 persons, 40.2ms\n",
            "Speed: 2.6ms preprocess, 40.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 39.3ms\n",
            "Speed: 2.3ms preprocess, 39.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 39.6ms\n",
            "Speed: 1.9ms preprocess, 39.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 39.8ms\n",
            "Speed: 2.3ms preprocess, 39.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 39.6ms\n",
            "Speed: 2.2ms preprocess, 39.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 41.7ms\n",
            "Speed: 2.1ms preprocess, 41.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 39.2ms\n",
            "Speed: 2.3ms preprocess, 39.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 41.8ms\n",
            "Speed: 2.1ms preprocess, 41.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 39.1ms\n",
            "Speed: 2.2ms preprocess, 39.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 persons, 39.2ms\n",
            "Speed: 2.5ms preprocess, 39.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 40.4ms\n",
            "Speed: 2.3ms preprocess, 40.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 9 persons, 38.8ms\n",
            "Speed: 2.2ms preprocess, 38.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 40.2ms\n",
            "Speed: 2.5ms preprocess, 40.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 38.3ms\n",
            "Speed: 2.2ms preprocess, 38.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 41.7ms\n",
            "Speed: 2.4ms preprocess, 41.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 12 persons, 38.8ms\n",
            "Speed: 3.1ms preprocess, 38.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 40.8ms\n",
            "Speed: 3.1ms preprocess, 40.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 11 persons, 38.1ms\n",
            "Speed: 3.1ms preprocess, 38.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 40.8ms\n",
            "Speed: 2.5ms preprocess, 40.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 9 persons, 38.3ms\n",
            "Speed: 2.3ms preprocess, 38.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 40.1ms\n",
            "Speed: 2.3ms preprocess, 40.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 40.0ms\n",
            "Speed: 2.9ms preprocess, 40.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 10 persons, 39.6ms\n",
            "Speed: 2.1ms preprocess, 39.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 13 persons, 41.1ms\n",
            "Speed: 2.0ms preprocess, 41.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 persons, 39.7ms\n",
            "Speed: 2.3ms preprocess, 39.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 41.0ms\n",
            "Speed: 2.4ms preprocess, 41.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 39.2ms\n",
            "Speed: 2.5ms preprocess, 39.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 41.7ms\n",
            "Speed: 2.0ms preprocess, 41.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 12 persons, 38.8ms\n",
            "Speed: 2.3ms preprocess, 38.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 persons, 41.2ms\n",
            "Speed: 2.5ms preprocess, 41.2ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 38.5ms\n",
            "Speed: 2.8ms preprocess, 38.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 40.6ms\n",
            "Speed: 2.3ms preprocess, 40.6ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 39.2ms\n",
            "Speed: 2.2ms preprocess, 39.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 8 persons, 41.4ms\n",
            "Speed: 2.8ms preprocess, 41.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 39.4ms\n",
            "Speed: 2.4ms preprocess, 39.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 42.4ms\n",
            "Speed: 2.9ms preprocess, 42.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 39.3ms\n",
            "Speed: 2.6ms preprocess, 39.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 40.9ms\n",
            "Speed: 2.9ms preprocess, 40.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 persons, 38.5ms\n",
            "Speed: 2.2ms preprocess, 38.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 10 persons, 41.8ms\n",
            "Speed: 2.4ms preprocess, 41.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 38.7ms\n",
            "Speed: 2.1ms preprocess, 38.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 41.3ms\n",
            "Speed: 2.0ms preprocess, 41.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 38.6ms\n",
            "Speed: 2.6ms preprocess, 38.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 39.3ms\n",
            "Speed: 2.3ms preprocess, 39.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 40.5ms\n",
            "Speed: 2.3ms preprocess, 40.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 11 persons, 39.2ms\n",
            "Speed: 3.0ms preprocess, 39.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 41.6ms\n",
            "Speed: 2.6ms preprocess, 41.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 39.2ms\n",
            "Speed: 2.7ms preprocess, 39.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 42.2ms\n",
            "Speed: 2.2ms preprocess, 42.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 38.8ms\n",
            "Speed: 2.4ms preprocess, 38.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 40.9ms\n",
            "Speed: 2.3ms preprocess, 40.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 38.6ms\n",
            "Speed: 2.3ms preprocess, 38.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 17 persons, 39.6ms\n",
            "Speed: 2.1ms preprocess, 39.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 10 persons, 40.2ms\n",
            "Speed: 2.1ms preprocess, 40.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 39.5ms\n",
            "Speed: 2.2ms preprocess, 39.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 40.2ms\n",
            "Speed: 2.6ms preprocess, 40.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 9 persons, 39.3ms\n",
            "Speed: 2.3ms preprocess, 39.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 40.1ms\n",
            "Speed: 2.7ms preprocess, 40.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 39.8ms\n",
            "Speed: 2.3ms preprocess, 39.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 41.7ms\n",
            "Speed: 2.4ms preprocess, 41.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 39.7ms\n",
            "Speed: 2.2ms preprocess, 39.7ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 40.6ms\n",
            "Speed: 2.3ms preprocess, 40.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 39.2ms\n",
            "Speed: 2.0ms preprocess, 39.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 40.1ms\n",
            "Speed: 2.0ms preprocess, 40.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 10 persons, 39.7ms\n",
            "Speed: 2.0ms preprocess, 39.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 39.6ms\n",
            "Speed: 2.5ms preprocess, 39.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 40.0ms\n",
            "Speed: 2.3ms preprocess, 40.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 39.6ms\n",
            "Speed: 2.2ms preprocess, 39.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 41.8ms\n",
            "Speed: 2.1ms preprocess, 41.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 39.7ms\n",
            "Speed: 2.4ms preprocess, 39.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 8 persons, 41.3ms\n",
            "Speed: 2.5ms preprocess, 41.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 13 persons, 38.9ms\n",
            "Speed: 2.4ms preprocess, 38.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 12 persons, 41.6ms\n",
            "Speed: 2.7ms preprocess, 41.6ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 38.8ms\n",
            "Speed: 2.5ms preprocess, 38.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 40.7ms\n",
            "Speed: 2.1ms preprocess, 40.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 10 persons, 38.4ms\n",
            "Speed: 2.3ms preprocess, 38.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 40.1ms\n",
            "Speed: 2.8ms preprocess, 40.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 39.8ms\n",
            "Speed: 2.5ms preprocess, 39.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 39.6ms\n",
            "Speed: 2.5ms preprocess, 39.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 40.4ms\n",
            "Speed: 2.2ms preprocess, 40.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 persons, 38.8ms\n",
            "Speed: 2.6ms preprocess, 38.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 41.1ms\n",
            "Speed: 2.9ms preprocess, 41.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 39.0ms\n",
            "Speed: 2.0ms preprocess, 39.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 41.7ms\n",
            "Speed: 2.6ms preprocess, 41.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 39.0ms\n",
            "Speed: 2.3ms preprocess, 39.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 15 persons, 40.0ms\n",
            "Speed: 1.9ms preprocess, 40.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 39.3ms\n",
            "Speed: 3.0ms preprocess, 39.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 persons, 40.1ms\n",
            "Speed: 2.2ms preprocess, 40.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 40.7ms\n",
            "Speed: 2.2ms preprocess, 40.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 39.6ms\n",
            "Speed: 2.4ms preprocess, 39.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 persons, 41.6ms\n",
            "Speed: 2.4ms preprocess, 41.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 39.0ms\n",
            "Speed: 3.1ms preprocess, 39.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 41.7ms\n",
            "Speed: 2.3ms preprocess, 41.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 39.3ms\n",
            "Speed: 2.5ms preprocess, 39.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 persons, 41.7ms\n",
            "Speed: 2.0ms preprocess, 41.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 39.2ms\n",
            "Speed: 2.4ms preprocess, 39.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 41.5ms\n",
            "Speed: 2.3ms preprocess, 41.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 38.5ms\n",
            "Speed: 2.3ms preprocess, 38.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 41.4ms\n",
            "Speed: 2.2ms preprocess, 41.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 39.2ms\n",
            "Speed: 2.3ms preprocess, 39.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 40.4ms\n",
            "Speed: 2.1ms preprocess, 40.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 39.9ms\n",
            "Speed: 2.9ms preprocess, 39.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 39.6ms\n",
            "Speed: 2.5ms preprocess, 39.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 10 persons, 40.4ms\n",
            "Speed: 2.9ms preprocess, 40.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 39.0ms\n",
            "Speed: 2.1ms preprocess, 39.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 41.7ms\n",
            "Speed: 2.2ms preprocess, 41.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 39.6ms\n",
            "Speed: 2.1ms preprocess, 39.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 persons, 40.0ms\n",
            "Speed: 2.2ms preprocess, 40.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 8 persons, 38.6ms\n",
            "Speed: 2.4ms preprocess, 38.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 12 persons, 39.3ms\n",
            "Speed: 2.7ms preprocess, 39.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 persons, 39.9ms\n",
            "Speed: 2.6ms preprocess, 39.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 39.6ms\n",
            "Speed: 2.3ms preprocess, 39.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 11 persons, 41.2ms\n",
            "Speed: 2.9ms preprocess, 41.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 39.3ms\n",
            "Speed: 2.1ms preprocess, 39.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 41.2ms\n",
            "Speed: 2.9ms preprocess, 41.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 39.4ms\n",
            "Speed: 2.4ms preprocess, 39.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 40.3ms\n",
            "Speed: 2.6ms preprocess, 40.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 39.7ms\n",
            "Speed: 2.2ms preprocess, 39.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 39.8ms\n",
            "Speed: 2.3ms preprocess, 39.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 40.7ms\n",
            "Speed: 2.0ms preprocess, 40.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 39.6ms\n",
            "Speed: 2.1ms preprocess, 39.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 41.0ms\n",
            "Speed: 2.1ms preprocess, 41.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 10 persons, 39.2ms\n",
            "Speed: 2.7ms preprocess, 39.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 41.7ms\n",
            "Speed: 2.1ms preprocess, 41.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 39.2ms\n",
            "Speed: 1.9ms preprocess, 39.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 15 persons, 41.4ms\n",
            "Speed: 2.2ms preprocess, 41.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 39.3ms\n",
            "Speed: 2.3ms preprocess, 39.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 9 persons, 39.7ms\n",
            "Speed: 2.2ms preprocess, 39.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 40.1ms\n",
            "Speed: 3.0ms preprocess, 40.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 persons, 39.6ms\n",
            "Speed: 2.1ms preprocess, 39.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 9 persons, 40.0ms\n",
            "Speed: 2.1ms preprocess, 40.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 39.1ms\n",
            "Speed: 1.9ms preprocess, 39.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 persons, 41.2ms\n",
            "Speed: 2.5ms preprocess, 41.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 39.3ms\n",
            "Speed: 2.3ms preprocess, 39.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 13 persons, 41.7ms\n",
            "Speed: 2.6ms preprocess, 41.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 39.5ms\n",
            "Speed: 2.1ms preprocess, 39.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 41.7ms\n",
            "Speed: 2.9ms preprocess, 41.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 39.2ms\n",
            "Speed: 2.2ms preprocess, 39.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 14 persons, 41.3ms\n",
            "Speed: 2.7ms preprocess, 41.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 39.2ms\n",
            "Speed: 2.4ms preprocess, 39.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 39.8ms\n",
            "Speed: 3.0ms preprocess, 39.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 40.0ms\n",
            "Speed: 2.2ms preprocess, 40.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 9 persons, 39.6ms\n",
            "Speed: 2.1ms preprocess, 39.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 41.1ms\n",
            "Speed: 2.6ms preprocess, 41.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 39.6ms\n",
            "Speed: 2.5ms preprocess, 39.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 41.6ms\n",
            "Speed: 2.2ms preprocess, 41.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 38.7ms\n",
            "Speed: 1.9ms preprocess, 38.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 41.2ms\n",
            "Speed: 2.4ms preprocess, 41.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 10 persons, 39.3ms\n",
            "Speed: 2.5ms preprocess, 39.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 39.8ms\n",
            "Speed: 2.1ms preprocess, 39.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 39.3ms\n",
            "Speed: 3.0ms preprocess, 39.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 39.9ms\n",
            "Speed: 2.4ms preprocess, 39.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 40.7ms\n",
            "Speed: 2.5ms preprocess, 40.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 39.6ms\n",
            "Speed: 2.4ms preprocess, 39.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 41.7ms\n",
            "Speed: 2.6ms preprocess, 41.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 9 persons, 39.7ms\n",
            "Speed: 2.4ms preprocess, 39.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 41.8ms\n",
            "Speed: 2.0ms preprocess, 41.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 8 persons, 39.4ms\n",
            "Speed: 2.0ms preprocess, 39.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 40.5ms\n",
            "Speed: 2.7ms preprocess, 40.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 39.7ms\n",
            "Speed: 2.0ms preprocess, 39.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 39.6ms\n",
            "Speed: 2.3ms preprocess, 39.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 40.7ms\n",
            "Speed: 2.3ms preprocess, 40.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 39.6ms\n",
            "Speed: 2.2ms preprocess, 39.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 41.9ms\n",
            "Speed: 2.4ms preprocess, 41.9ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 39.5ms\n",
            "Speed: 2.8ms preprocess, 39.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 8 persons, 41.1ms\n",
            "Speed: 2.7ms preprocess, 41.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 8 persons, 39.1ms\n",
            "Speed: 2.3ms preprocess, 39.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 8 persons, 41.8ms\n",
            "Speed: 2.2ms preprocess, 41.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 39.3ms\n",
            "Speed: 2.4ms preprocess, 39.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 12 persons, 40.9ms\n",
            "Speed: 2.6ms preprocess, 40.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 38.6ms\n",
            "Speed: 2.2ms preprocess, 38.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 10 persons, 39.9ms\n",
            "Speed: 3.0ms preprocess, 39.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 39.9ms\n",
            "Speed: 2.7ms preprocess, 39.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 9 persons, 39.7ms\n",
            "Speed: 2.2ms preprocess, 39.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 40.5ms\n",
            "Speed: 2.3ms preprocess, 40.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 14 persons, 39.6ms\n",
            "Speed: 2.7ms preprocess, 39.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 40.6ms\n",
            "Speed: 2.1ms preprocess, 40.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 persons, 39.1ms\n",
            "Speed: 2.3ms preprocess, 39.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 41.8ms\n",
            "Speed: 2.4ms preprocess, 41.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 38.5ms\n",
            "Speed: 2.3ms preprocess, 38.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 40.5ms\n",
            "Speed: 2.1ms preprocess, 40.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 39.8ms\n",
            "Speed: 2.0ms preprocess, 39.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 39.7ms\n",
            "Speed: 2.5ms preprocess, 39.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 11 persons, 40.6ms\n",
            "Speed: 2.3ms preprocess, 40.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 39.9ms\n",
            "Speed: 2.9ms preprocess, 39.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 41.0ms\n",
            "Speed: 2.4ms preprocess, 41.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 9 persons, 39.2ms\n",
            "Speed: 2.6ms preprocess, 39.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 8 persons, 41.8ms\n",
            "Speed: 2.2ms preprocess, 41.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 39.9ms\n",
            "Speed: 2.2ms preprocess, 39.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 41.7ms\n",
            "Speed: 2.4ms preprocess, 41.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 8 persons, 39.4ms\n",
            "Speed: 2.9ms preprocess, 39.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 11 persons, 41.2ms\n",
            "Speed: 2.3ms preprocess, 41.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 persons, 38.4ms\n",
            "Speed: 2.3ms preprocess, 38.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 8 persons, 40.1ms\n",
            "Speed: 2.4ms preprocess, 40.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 39.1ms\n",
            "Speed: 2.2ms preprocess, 39.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 12 persons, 39.6ms\n",
            "Speed: 2.6ms preprocess, 39.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 38.3ms\n",
            "Speed: 2.2ms preprocess, 38.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 39.1ms\n",
            "Speed: 2.4ms preprocess, 39.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 persons, 40.0ms\n",
            "Speed: 3.0ms preprocess, 40.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 39.6ms\n",
            "Speed: 2.3ms preprocess, 39.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 11 persons, 40.2ms\n",
            "Speed: 2.5ms preprocess, 40.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 38.8ms\n",
            "Speed: 2.0ms preprocess, 38.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 10 persons, 41.5ms\n",
            "Speed: 2.6ms preprocess, 41.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 38.8ms\n",
            "Speed: 2.8ms preprocess, 38.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 41.5ms\n",
            "Speed: 3.0ms preprocess, 41.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 12 persons, 38.5ms\n",
            "Speed: 2.3ms preprocess, 38.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 40.2ms\n",
            "Speed: 2.6ms preprocess, 40.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 38.4ms\n",
            "Speed: 3.0ms preprocess, 38.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 8 persons, 40.0ms\n",
            "Speed: 2.6ms preprocess, 40.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 9 persons, 40.8ms\n",
            "Speed: 2.0ms preprocess, 40.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 40.4ms\n",
            "Speed: 2.8ms preprocess, 40.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 38.9ms\n",
            "Speed: 2.5ms preprocess, 38.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 39.3ms\n",
            "Speed: 2.5ms preprocess, 39.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 40.1ms\n",
            "Speed: 2.4ms preprocess, 40.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 11 persons, 39.4ms\n",
            "Speed: 2.7ms preprocess, 39.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 39.7ms\n",
            "Speed: 2.4ms preprocess, 39.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 39.2ms\n",
            "Speed: 2.4ms preprocess, 39.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 9 persons, 40.7ms\n",
            "Speed: 2.9ms preprocess, 40.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 39.2ms\n",
            "Speed: 1.9ms preprocess, 39.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 40.5ms\n",
            "Speed: 2.5ms preprocess, 40.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 38.8ms\n",
            "Speed: 3.0ms preprocess, 38.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 41.3ms\n",
            "Speed: 2.3ms preprocess, 41.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 38.9ms\n",
            "Speed: 2.4ms preprocess, 38.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 persons, 41.6ms\n",
            "Speed: 2.1ms preprocess, 41.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 39.1ms\n",
            "Speed: 3.0ms preprocess, 39.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 40.7ms\n",
            "Speed: 2.2ms preprocess, 40.7ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 15 persons, 39.6ms\n",
            "Speed: 2.5ms preprocess, 39.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 9 persons, 40.8ms\n",
            "Speed: 2.4ms preprocess, 40.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 11 persons, 38.0ms\n",
            "Speed: 2.0ms preprocess, 38.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 8 persons, 39.6ms\n",
            "Speed: 2.4ms preprocess, 39.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 40.6ms\n",
            "Speed: 2.2ms preprocess, 40.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 40.4ms\n",
            "Speed: 2.5ms preprocess, 40.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 40.0ms\n",
            "Speed: 2.3ms preprocess, 40.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 39.6ms\n",
            "Speed: 2.5ms preprocess, 39.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 40.4ms\n",
            "Speed: 2.1ms preprocess, 40.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 10 persons, 39.2ms\n",
            "Speed: 2.3ms preprocess, 39.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 41.5ms\n",
            "Speed: 3.0ms preprocess, 41.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 9 persons, 38.8ms\n",
            "Speed: 2.4ms preprocess, 38.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 9 persons, 40.5ms\n",
            "Speed: 2.9ms preprocess, 40.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 38.7ms\n",
            "Speed: 2.3ms preprocess, 38.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 39.3ms\n",
            "Speed: 2.3ms preprocess, 39.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 39.4ms\n",
            "Speed: 2.9ms preprocess, 39.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 11 persons, 39.1ms\n",
            "Speed: 2.4ms preprocess, 39.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 41.2ms\n",
            "Speed: 2.9ms preprocess, 41.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 39.3ms\n",
            "Speed: 3.0ms preprocess, 39.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 persons, 40.4ms\n",
            "Speed: 3.0ms preprocess, 40.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 38.9ms\n",
            "Speed: 2.9ms preprocess, 38.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 41.5ms\n",
            "Speed: 2.3ms preprocess, 41.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 38.5ms\n",
            "Speed: 2.5ms preprocess, 38.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 40.3ms\n",
            "Speed: 3.0ms preprocess, 40.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 38.7ms\n",
            "Speed: 2.4ms preprocess, 38.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 39.5ms\n",
            "Speed: 2.1ms preprocess, 39.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 39.3ms\n",
            "Speed: 3.0ms preprocess, 39.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 10 persons, 39.6ms\n",
            "Speed: 2.5ms preprocess, 39.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 39.9ms\n",
            "Speed: 2.2ms preprocess, 39.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 39.2ms\n",
            "Speed: 2.4ms preprocess, 39.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 41.8ms\n",
            "Speed: 2.7ms preprocess, 41.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 39.1ms\n",
            "Speed: 2.1ms preprocess, 39.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 40.8ms\n",
            "Speed: 2.5ms preprocess, 40.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 9 persons, 39.1ms\n",
            "Speed: 2.1ms preprocess, 39.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 40.0ms\n",
            "Speed: 2.0ms preprocess, 40.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 9 persons, 39.3ms\n",
            "Speed: 2.0ms preprocess, 39.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 39.2ms\n",
            "Speed: 2.4ms preprocess, 39.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 41.6ms\n",
            "Speed: 2.2ms preprocess, 41.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 39.4ms\n",
            "Speed: 2.2ms preprocess, 39.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 41.6ms\n",
            "Speed: 2.3ms preprocess, 41.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 39.2ms\n",
            "Speed: 2.6ms preprocess, 39.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 41.7ms\n",
            "Speed: 2.2ms preprocess, 41.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 38.7ms\n",
            "Speed: 2.9ms preprocess, 38.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 40.1ms\n",
            "Speed: 2.3ms preprocess, 40.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 10 persons, 38.6ms\n",
            "Speed: 2.3ms preprocess, 38.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 38.8ms\n",
            "Speed: 3.2ms preprocess, 38.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 11 persons, 39.3ms\n",
            "Speed: 2.6ms preprocess, 39.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 9 persons, 39.1ms\n",
            "Speed: 2.3ms preprocess, 39.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 10 persons, 39.7ms\n",
            "Speed: 2.2ms preprocess, 39.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 9 persons, 38.5ms\n",
            "Speed: 2.5ms preprocess, 38.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 11 persons, 40.5ms\n",
            "Speed: 1.9ms preprocess, 40.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 8 persons, 39.1ms\n",
            "Speed: 2.3ms preprocess, 39.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 41.3ms\n",
            "Speed: 2.2ms preprocess, 41.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 persons, 39.1ms\n",
            "Speed: 2.0ms preprocess, 39.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 39.5ms\n",
            "Speed: 2.9ms preprocess, 39.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 40.4ms\n",
            "Speed: 2.1ms preprocess, 40.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 39.3ms\n",
            "Speed: 2.6ms preprocess, 39.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 41.0ms\n",
            "Speed: 2.4ms preprocess, 41.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 39.2ms\n",
            "Speed: 2.4ms preprocess, 39.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 41.7ms\n",
            "Speed: 2.1ms preprocess, 41.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 persons, 39.5ms\n",
            "Speed: 2.4ms preprocess, 39.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 40.8ms\n",
            "Speed: 3.0ms preprocess, 40.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 38.1ms\n",
            "Speed: 2.1ms preprocess, 38.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 39.8ms\n",
            "Speed: 2.2ms preprocess, 39.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 40.4ms\n",
            "Speed: 2.4ms preprocess, 40.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 38.6ms\n",
            "Speed: 2.4ms preprocess, 38.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 persons, 39.3ms\n",
            "Speed: 3.1ms preprocess, 39.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 38.7ms\n",
            "Speed: 2.6ms preprocess, 38.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 40.9ms\n",
            "Speed: 3.4ms preprocess, 40.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 38.8ms\n",
            "Speed: 2.5ms preprocess, 38.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 14 persons, 40.9ms\n",
            "Speed: 2.4ms preprocess, 40.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 38.9ms\n",
            "Speed: 2.6ms preprocess, 38.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 41.0ms\n",
            "Speed: 3.0ms preprocess, 41.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 9 persons, 38.5ms\n",
            "Speed: 2.2ms preprocess, 38.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 persons, 39.5ms\n",
            "Speed: 2.2ms preprocess, 39.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 9 persons, 39.7ms\n",
            "Speed: 2.3ms preprocess, 39.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 39.3ms\n",
            "Speed: 2.5ms preprocess, 39.3ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 12 persons, 39.9ms\n",
            "Speed: 2.4ms preprocess, 39.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 39.2ms\n",
            "Speed: 2.3ms preprocess, 39.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 9 persons, 41.1ms\n",
            "Speed: 3.0ms preprocess, 41.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 39.2ms\n",
            "Speed: 2.1ms preprocess, 39.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 41.3ms\n",
            "Speed: 2.1ms preprocess, 41.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 9 persons, 38.4ms\n",
            "Speed: 2.5ms preprocess, 38.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 11 persons, 39.3ms\n",
            "Speed: 2.2ms preprocess, 39.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 12 persons, 39.9ms\n",
            "Speed: 2.4ms preprocess, 39.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 38.6ms\n",
            "Speed: 2.4ms preprocess, 38.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 8 persons, 40.7ms\n",
            "Speed: 2.4ms preprocess, 40.7ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 10 persons, 38.9ms\n",
            "Speed: 2.5ms preprocess, 38.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 10 persons, 40.0ms\n",
            "Speed: 3.0ms preprocess, 40.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 14 persons, 38.3ms\n",
            "Speed: 2.2ms preprocess, 38.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 39.6ms\n",
            "Speed: 2.2ms preprocess, 39.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 40.3ms\n",
            "Speed: 2.1ms preprocess, 40.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 15 persons, 39.0ms\n",
            "Speed: 2.3ms preprocess, 39.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 40.4ms\n",
            "Speed: 2.8ms preprocess, 40.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 8 persons, 38.8ms\n",
            "Speed: 2.2ms preprocess, 38.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 persons, 40.9ms\n",
            "Speed: 2.6ms preprocess, 40.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 11 persons, 38.7ms\n",
            "Speed: 2.0ms preprocess, 38.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 9 persons, 39.5ms\n",
            "Speed: 2.2ms preprocess, 39.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 39.9ms\n",
            "Speed: 2.0ms preprocess, 39.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 9 persons, 39.2ms\n",
            "Speed: 2.8ms preprocess, 39.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 41.5ms\n",
            "Speed: 2.2ms preprocess, 41.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 38.7ms\n",
            "Speed: 2.3ms preprocess, 38.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 8 persons, 41.3ms\n",
            "Speed: 2.1ms preprocess, 41.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 39.1ms\n",
            "Speed: 2.2ms preprocess, 39.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 10 persons, 40.1ms\n",
            "Speed: 2.2ms preprocess, 40.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 persons, 40.8ms\n",
            "Speed: 2.4ms preprocess, 40.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 39.2ms\n",
            "Speed: 2.5ms preprocess, 39.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 41.5ms\n",
            "Speed: 2.3ms preprocess, 41.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 38.4ms\n",
            "Speed: 2.7ms preprocess, 38.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 41.0ms\n",
            "Speed: 2.4ms preprocess, 41.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 39.0ms\n",
            "Speed: 2.2ms preprocess, 39.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 persons, 39.5ms\n",
            "Speed: 2.1ms preprocess, 39.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 40.1ms\n",
            "Speed: 2.1ms preprocess, 40.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 38.7ms\n",
            "Speed: 2.4ms preprocess, 38.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 41.5ms\n",
            "Speed: 2.1ms preprocess, 41.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 persons, 38.5ms\n",
            "Speed: 2.0ms preprocess, 38.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 40.7ms\n",
            "Speed: 2.3ms preprocess, 40.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 38.8ms\n",
            "Speed: 2.2ms preprocess, 38.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 8 persons, 38.6ms\n",
            "Speed: 2.4ms preprocess, 38.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 12 persons, 39.7ms\n",
            "Speed: 2.2ms preprocess, 39.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 11 persons, 38.5ms\n",
            "Speed: 3.1ms preprocess, 38.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 persons, 41.4ms\n",
            "Speed: 2.4ms preprocess, 41.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 9 persons, 38.4ms\n",
            "Speed: 2.2ms preprocess, 38.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 persons, 40.5ms\n",
            "Speed: 2.2ms preprocess, 40.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 9 persons, 39.9ms\n",
            "Speed: 2.2ms preprocess, 39.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 14 persons, 39.3ms\n",
            "Speed: 2.4ms preprocess, 39.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 40.7ms\n",
            "Speed: 2.5ms preprocess, 40.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 39.2ms\n",
            "Speed: 2.2ms preprocess, 39.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 41.5ms\n",
            "Speed: 2.8ms preprocess, 41.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 38.2ms\n",
            "Speed: 2.3ms preprocess, 38.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 12 persons, 39.8ms\n",
            "Speed: 2.2ms preprocess, 39.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 8 persons, 39.6ms\n",
            "Speed: 2.2ms preprocess, 39.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 persons, 39.0ms\n",
            "Speed: 2.2ms preprocess, 39.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 40.5ms\n",
            "Speed: 2.4ms preprocess, 40.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 38.9ms\n",
            "Speed: 2.5ms preprocess, 38.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 41.6ms\n",
            "Speed: 2.3ms preprocess, 41.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 10 persons, 38.2ms\n",
            "Speed: 2.1ms preprocess, 38.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 39.8ms\n",
            "Speed: 2.2ms preprocess, 39.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 39.5ms\n",
            "Speed: 2.7ms preprocess, 39.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 persons, 38.6ms\n",
            "Speed: 2.1ms preprocess, 38.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 40.0ms\n",
            "Speed: 2.4ms preprocess, 40.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 38.8ms\n",
            "Speed: 2.2ms preprocess, 38.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 9 persons, 41.3ms\n",
            "Speed: 2.6ms preprocess, 41.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 11 persons, 38.1ms\n",
            "Speed: 2.5ms preprocess, 38.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 39.0ms\n",
            "Speed: 2.6ms preprocess, 39.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 39.8ms\n",
            "Speed: 3.0ms preprocess, 39.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 8 persons, 38.5ms\n",
            "Speed: 3.0ms preprocess, 38.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 40.5ms\n",
            "Speed: 2.1ms preprocess, 40.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 12 persons, 38.6ms\n",
            "Speed: 2.3ms preprocess, 38.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 41.6ms\n",
            "Speed: 2.5ms preprocess, 41.6ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 8 persons, 37.9ms\n",
            "Speed: 2.2ms preprocess, 37.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 11 persons, 40.5ms\n",
            "Speed: 3.2ms preprocess, 40.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 9 persons, 38.5ms\n",
            "Speed: 2.1ms preprocess, 38.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 40.6ms\n",
            "Speed: 2.2ms preprocess, 40.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 39.5ms\n",
            "Speed: 2.4ms preprocess, 39.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 12 persons, 39.3ms\n",
            "Speed: 2.3ms preprocess, 39.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 40.6ms\n",
            "Speed: 2.2ms preprocess, 40.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 39.6ms\n",
            "Speed: 2.1ms preprocess, 39.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 40.5ms\n",
            "Speed: 3.1ms preprocess, 40.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 9 persons, 38.9ms\n",
            "Speed: 2.3ms preprocess, 38.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 40.0ms\n",
            "Speed: 2.4ms preprocess, 40.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 39.2ms\n",
            "Speed: 2.2ms preprocess, 39.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 39.2ms\n",
            "Speed: 1.9ms preprocess, 39.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 persons, 40.5ms\n",
            "Speed: 2.3ms preprocess, 40.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 8 persons, 38.5ms\n",
            "Speed: 2.8ms preprocess, 38.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 40.2ms\n",
            "Speed: 2.3ms preprocess, 40.2ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 38.3ms\n",
            "Speed: 3.2ms preprocess, 38.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 39.8ms\n",
            "Speed: 2.3ms preprocess, 39.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 39.1ms\n",
            "Speed: 2.4ms preprocess, 39.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 39.0ms\n",
            "Speed: 2.9ms preprocess, 39.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 39.8ms\n",
            "Speed: 2.4ms preprocess, 39.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 8 persons, 38.8ms\n",
            "Speed: 2.7ms preprocess, 38.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 41.5ms\n",
            "Speed: 2.4ms preprocess, 41.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 37.9ms\n",
            "Speed: 2.1ms preprocess, 37.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 39.7ms\n",
            "Speed: 2.4ms preprocess, 39.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 9 persons, 39.9ms\n",
            "Speed: 2.8ms preprocess, 39.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 38.7ms\n",
            "Speed: 2.8ms preprocess, 38.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 41.5ms\n",
            "Speed: 2.2ms preprocess, 41.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 38.2ms\n",
            "Speed: 2.7ms preprocess, 38.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 40.1ms\n",
            "Speed: 2.3ms preprocess, 40.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 39.2ms\n",
            "Speed: 2.0ms preprocess, 39.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 39.0ms\n",
            "Speed: 2.4ms preprocess, 39.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 39.9ms\n",
            "Speed: 2.2ms preprocess, 39.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 37.7ms\n",
            "Speed: 2.3ms preprocess, 37.7ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 40.2ms\n",
            "Speed: 2.1ms preprocess, 40.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 39.1ms\n",
            "Speed: 2.3ms preprocess, 39.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 persons, 39.1ms\n",
            "Speed: 2.6ms preprocess, 39.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 38.6ms\n",
            "Speed: 2.4ms preprocess, 38.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 persons, 38.6ms\n",
            "Speed: 2.3ms preprocess, 38.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 39.8ms\n",
            "Speed: 2.2ms preprocess, 39.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 persons, 38.7ms\n",
            "Speed: 2.9ms preprocess, 38.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 41.4ms\n",
            "Speed: 2.1ms preprocess, 41.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 38.0ms\n",
            "Speed: 2.0ms preprocess, 38.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 40.5ms\n",
            "Speed: 2.4ms preprocess, 40.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 39.6ms\n",
            "Speed: 2.2ms preprocess, 39.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 38.9ms\n",
            "Speed: 3.0ms preprocess, 38.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 9 persons, 39.8ms\n",
            "Speed: 2.3ms preprocess, 39.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 38.4ms\n",
            "Speed: 2.3ms preprocess, 38.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 40.9ms\n",
            "Speed: 2.4ms preprocess, 40.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 38.7ms\n",
            "Speed: 2.2ms preprocess, 38.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 39.4ms\n",
            "Speed: 2.7ms preprocess, 39.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 39.1ms\n",
            "Speed: 3.0ms preprocess, 39.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 13 persons, 38.5ms\n",
            "Speed: 2.6ms preprocess, 38.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 16 persons, 39.4ms\n",
            "Speed: 3.1ms preprocess, 39.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 11 persons, 38.9ms\n",
            "Speed: 2.5ms preprocess, 38.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 40.4ms\n",
            "Speed: 2.2ms preprocess, 40.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 10 persons, 37.9ms\n",
            "Speed: 2.4ms preprocess, 37.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 11 persons, 38.6ms\n",
            "Speed: 3.3ms preprocess, 38.6ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 9 persons, 37.5ms\n",
            "Speed: 3.0ms preprocess, 37.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 9 persons, 39.0ms\n",
            "Speed: 2.3ms preprocess, 39.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 39.4ms\n",
            "Speed: 3.0ms preprocess, 39.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 38.8ms\n",
            "Speed: 2.1ms preprocess, 38.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 40.5ms\n",
            "Speed: 2.3ms preprocess, 40.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 9 persons, 38.9ms\n",
            "Speed: 2.4ms preprocess, 38.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 40.5ms\n",
            "Speed: 2.4ms preprocess, 40.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 9 persons, 38.0ms\n",
            "Speed: 2.3ms preprocess, 38.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 10 persons, 38.9ms\n",
            "Speed: 2.9ms preprocess, 38.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 persons, 39.2ms\n",
            "Speed: 2.5ms preprocess, 39.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 8 persons, 38.5ms\n",
            "Speed: 2.6ms preprocess, 38.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 40.5ms\n",
            "Speed: 2.5ms preprocess, 40.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 38.0ms\n",
            "Speed: 3.0ms preprocess, 38.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 40.6ms\n",
            "Speed: 2.6ms preprocess, 40.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 38.4ms\n",
            "Speed: 2.5ms preprocess, 38.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 persons, 38.5ms\n",
            "Speed: 2.3ms preprocess, 38.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 9 persons, 39.7ms\n",
            "Speed: 2.3ms preprocess, 39.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 10 persons, 38.6ms\n",
            "Speed: 2.8ms preprocess, 38.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 40.0ms\n",
            "Speed: 2.8ms preprocess, 40.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 persons, 38.5ms\n",
            "Speed: 2.7ms preprocess, 38.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 39.9ms\n",
            "Speed: 2.3ms preprocess, 39.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 38.3ms\n",
            "Speed: 3.3ms preprocess, 38.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 39.7ms\n",
            "Speed: 2.7ms preprocess, 39.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 38.2ms\n",
            "Speed: 3.0ms preprocess, 38.2ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 39.9ms\n",
            "Speed: 2.8ms preprocess, 39.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 8 persons, 38.3ms\n",
            "Speed: 2.2ms preprocess, 38.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 persons, 39.5ms\n",
            "Speed: 2.2ms preprocess, 39.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 39.3ms\n",
            "Speed: 2.1ms preprocess, 39.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 38.5ms\n",
            "Speed: 2.1ms preprocess, 38.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 40.5ms\n",
            "Speed: 2.4ms preprocess, 40.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 14 persons, 38.3ms\n",
            "Speed: 2.3ms preprocess, 38.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 persons, 39.5ms\n",
            "Speed: 2.4ms preprocess, 39.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 9 persons, 39.7ms\n",
            "Speed: 2.1ms preprocess, 39.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 38.5ms\n",
            "Speed: 2.3ms preprocess, 38.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 10 persons, 41.1ms\n",
            "Speed: 2.3ms preprocess, 41.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 38.3ms\n",
            "Speed: 2.5ms preprocess, 38.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 40.8ms\n",
            "Speed: 2.8ms preprocess, 40.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 38.7ms\n",
            "Speed: 2.4ms preprocess, 38.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 39.0ms\n",
            "Speed: 2.2ms preprocess, 39.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 8 persons, 39.4ms\n",
            "Speed: 2.6ms preprocess, 39.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 persons, 38.5ms\n",
            "Speed: 2.7ms preprocess, 38.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 39.8ms\n",
            "Speed: 3.2ms preprocess, 39.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 persons, 38.0ms\n",
            "Speed: 2.4ms preprocess, 38.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 40.4ms\n",
            "Speed: 2.9ms preprocess, 40.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 12 persons, 38.1ms\n",
            "Speed: 2.4ms preprocess, 38.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 8 persons, 39.7ms\n",
            "Speed: 2.2ms preprocess, 39.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 38.5ms\n",
            "Speed: 2.4ms preprocess, 38.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 38.5ms\n",
            "Speed: 2.1ms preprocess, 38.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 persons, 40.3ms\n",
            "Speed: 2.5ms preprocess, 40.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 38.8ms\n",
            "Speed: 2.2ms preprocess, 38.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 persons, 40.8ms\n",
            "Speed: 2.2ms preprocess, 40.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 13 persons, 38.9ms\n",
            "Speed: 2.2ms preprocess, 38.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 39.2ms\n",
            "Speed: 2.1ms preprocess, 39.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 8 persons, 40.4ms\n",
            "Speed: 1.9ms preprocess, 40.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 persons, 37.9ms\n",
            "Speed: 2.0ms preprocess, 37.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 39.7ms\n",
            "Speed: 2.2ms preprocess, 39.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 8 persons, 39.0ms\n",
            "Speed: 1.9ms preprocess, 39.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 38.5ms\n",
            "Speed: 3.0ms preprocess, 38.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 10 persons, 40.1ms\n",
            "Speed: 2.1ms preprocess, 40.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 8 persons, 38.4ms\n",
            "Speed: 2.3ms preprocess, 38.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 41.0ms\n",
            "Speed: 2.1ms preprocess, 41.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 38.2ms\n",
            "Speed: 2.3ms preprocess, 38.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 40.3ms\n",
            "Speed: 2.2ms preprocess, 40.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 39.5ms\n",
            "Speed: 2.4ms preprocess, 39.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 38.2ms\n",
            "Speed: 2.6ms preprocess, 38.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 13 persons, 39.5ms\n",
            "Speed: 2.3ms preprocess, 39.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 38.1ms\n",
            "Speed: 2.3ms preprocess, 38.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 41.2ms\n",
            "Speed: 2.4ms preprocess, 41.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 39.6ms\n",
            "Speed: 2.4ms preprocess, 39.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 38.5ms\n",
            "Speed: 2.5ms preprocess, 38.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 40.4ms\n",
            "Speed: 2.4ms preprocess, 40.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 38.1ms\n",
            "Speed: 2.3ms preprocess, 38.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 10 persons, 39.3ms\n",
            "Speed: 2.2ms preprocess, 39.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 39.7ms\n",
            "Speed: 2.3ms preprocess, 39.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 38.6ms\n",
            "Speed: 2.3ms preprocess, 38.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 9 persons, 40.7ms\n",
            "Speed: 2.3ms preprocess, 40.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 37.2ms\n",
            "Speed: 3.0ms preprocess, 37.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 38.9ms\n",
            "Speed: 2.1ms preprocess, 38.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 persons, 38.8ms\n",
            "Speed: 2.9ms preprocess, 38.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 12 persons, 38.1ms\n",
            "Speed: 2.1ms preprocess, 38.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 41.3ms\n",
            "Speed: 2.3ms preprocess, 41.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 11 persons, 37.9ms\n",
            "Speed: 2.1ms preprocess, 37.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 39.0ms\n",
            "Speed: 2.3ms preprocess, 39.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 persons, 40.3ms\n",
            "Speed: 2.2ms preprocess, 40.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 9 persons, 38.5ms\n",
            "Speed: 2.4ms preprocess, 38.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 8 persons, 40.5ms\n",
            "Speed: 2.3ms preprocess, 40.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 38.0ms\n",
            "Speed: 2.7ms preprocess, 38.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 8 persons, 39.3ms\n",
            "Speed: 2.1ms preprocess, 39.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 39.5ms\n",
            "Speed: 2.2ms preprocess, 39.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 38.5ms\n",
            "Speed: 2.5ms preprocess, 38.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 40.7ms\n",
            "Speed: 2.3ms preprocess, 40.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 9 persons, 38.6ms\n",
            "Speed: 2.2ms preprocess, 38.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 39.3ms\n",
            "Speed: 2.0ms preprocess, 39.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 39.4ms\n",
            "Speed: 2.3ms preprocess, 39.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 38.1ms\n",
            "Speed: 2.2ms preprocess, 38.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 41.2ms\n",
            "Speed: 2.2ms preprocess, 41.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 39.0ms\n",
            "Speed: 2.2ms preprocess, 39.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 11 persons, 38.6ms\n",
            "Speed: 3.0ms preprocess, 38.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 39.4ms\n",
            "Speed: 2.4ms preprocess, 39.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 8 persons, 37.9ms\n",
            "Speed: 2.4ms preprocess, 37.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 persons, 40.7ms\n",
            "Speed: 2.4ms preprocess, 40.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 persons, 37.6ms\n",
            "Speed: 2.5ms preprocess, 37.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 39.3ms\n",
            "Speed: 2.5ms preprocess, 39.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 39.1ms\n",
            "Speed: 2.3ms preprocess, 39.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 38.9ms\n",
            "Speed: 2.3ms preprocess, 38.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 8 persons, 39.8ms\n",
            "Speed: 2.8ms preprocess, 39.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 38.1ms\n",
            "Speed: 2.4ms preprocess, 38.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 40.1ms\n",
            "Speed: 3.1ms preprocess, 40.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 37.4ms\n",
            "Speed: 2.0ms preprocess, 37.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 38.8ms\n",
            "Speed: 2.7ms preprocess, 38.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 40.3ms\n",
            "Speed: 2.2ms preprocess, 40.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 10 persons, 38.8ms\n",
            "Speed: 2.0ms preprocess, 38.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 40.7ms\n",
            "Speed: 2.2ms preprocess, 40.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 37.6ms\n",
            "Speed: 2.2ms preprocess, 37.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 persons, 38.9ms\n",
            "Speed: 2.3ms preprocess, 38.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 40.5ms\n",
            "Speed: 2.2ms preprocess, 40.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 38.6ms\n",
            "Speed: 2.4ms preprocess, 38.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 41.5ms\n",
            "Speed: 2.7ms preprocess, 41.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 37.9ms\n",
            "Speed: 2.3ms preprocess, 37.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 9 persons, 38.6ms\n",
            "Speed: 3.1ms preprocess, 38.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 persons, 39.0ms\n",
            "Speed: 2.5ms preprocess, 39.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 38.2ms\n",
            "Speed: 2.5ms preprocess, 38.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 40.8ms\n",
            "Speed: 2.4ms preprocess, 40.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 37.8ms\n",
            "Speed: 3.0ms preprocess, 37.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 39.3ms\n",
            "Speed: 2.3ms preprocess, 39.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 38.4ms\n",
            "Speed: 2.7ms preprocess, 38.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 11 persons, 38.1ms\n",
            "Speed: 2.3ms preprocess, 38.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 12 persons, 40.4ms\n",
            "Speed: 2.5ms preprocess, 40.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 37.4ms\n",
            "Speed: 2.6ms preprocess, 37.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 38.7ms\n",
            "Speed: 3.2ms preprocess, 38.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 persons, 38.9ms\n",
            "Speed: 2.1ms preprocess, 38.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 persons, 38.8ms\n",
            "Speed: 2.2ms preprocess, 38.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 39.7ms\n",
            "Speed: 2.4ms preprocess, 39.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 37.7ms\n",
            "Speed: 2.4ms preprocess, 37.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 10 persons, 38.9ms\n",
            "Speed: 2.5ms preprocess, 38.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 38.9ms\n",
            "Speed: 2.4ms preprocess, 38.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 persons, 37.8ms\n",
            "Speed: 2.6ms preprocess, 37.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 11 persons, 40.7ms\n",
            "Speed: 2.5ms preprocess, 40.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 37.4ms\n",
            "Speed: 3.0ms preprocess, 37.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 39.0ms\n",
            "Speed: 2.1ms preprocess, 39.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 38.4ms\n",
            "Speed: 2.8ms preprocess, 38.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 38.4ms\n",
            "Speed: 2.3ms preprocess, 38.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 40.2ms\n",
            "Speed: 3.0ms preprocess, 40.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 37.5ms\n",
            "Speed: 2.9ms preprocess, 37.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 39.3ms\n",
            "Speed: 2.1ms preprocess, 39.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 persons, 39.2ms\n",
            "Speed: 2.2ms preprocess, 39.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 38.1ms\n",
            "Speed: 2.3ms preprocess, 38.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 40.4ms\n",
            "Speed: 2.3ms preprocess, 40.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 11 persons, 37.9ms\n",
            "Speed: 2.1ms preprocess, 37.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 persons, 38.9ms\n",
            "Speed: 2.1ms preprocess, 38.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 39.0ms\n",
            "Speed: 2.5ms preprocess, 39.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 37.8ms\n",
            "Speed: 2.0ms preprocess, 37.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 10 persons, 39.3ms\n",
            "Speed: 1.9ms preprocess, 39.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 10 persons, 38.8ms\n",
            "Speed: 2.5ms preprocess, 38.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 39.1ms\n",
            "Speed: 2.3ms preprocess, 39.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 40.1ms\n",
            "Speed: 2.5ms preprocess, 40.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 38.0ms\n",
            "Speed: 2.6ms preprocess, 38.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 11 persons, 40.7ms\n",
            "Speed: 2.2ms preprocess, 40.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 8 persons, 38.6ms\n",
            "Speed: 2.0ms preprocess, 38.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 38.9ms\n",
            "Speed: 2.9ms preprocess, 38.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 8 persons, 39.6ms\n",
            "Speed: 2.1ms preprocess, 39.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 37.9ms\n",
            "Speed: 2.3ms preprocess, 37.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 39.1ms\n",
            "Speed: 2.4ms preprocess, 39.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 38.6ms\n",
            "Speed: 2.5ms preprocess, 38.6ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 38.9ms\n",
            "Speed: 2.5ms preprocess, 38.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 39.0ms\n",
            "Speed: 2.3ms preprocess, 39.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 37.8ms\n",
            "Speed: 2.3ms preprocess, 37.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 9 persons, 39.6ms\n",
            "Speed: 2.2ms preprocess, 39.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 39.0ms\n",
            "Speed: 2.3ms preprocess, 39.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 38.4ms\n",
            "Speed: 2.3ms preprocess, 38.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 persons, 40.1ms\n",
            "Speed: 2.1ms preprocess, 40.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 persons, 37.4ms\n",
            "Speed: 2.2ms preprocess, 37.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 persons, 38.9ms\n",
            "Speed: 1.9ms preprocess, 38.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 39.9ms\n",
            "Speed: 2.2ms preprocess, 39.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 11 persons, 37.7ms\n",
            "Speed: 3.0ms preprocess, 37.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 40.1ms\n",
            "Speed: 2.4ms preprocess, 40.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 39.2ms\n",
            "Speed: 2.1ms preprocess, 39.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 11 persons, 38.5ms\n",
            "Speed: 2.5ms preprocess, 38.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 9 persons, 40.4ms\n",
            "Speed: 2.5ms preprocess, 40.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 38.0ms\n",
            "Speed: 2.3ms preprocess, 38.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 12 persons, 39.0ms\n",
            "Speed: 3.0ms preprocess, 39.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 8 persons, 38.9ms\n",
            "Speed: 2.5ms preprocess, 38.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 38.3ms\n",
            "Speed: 2.1ms preprocess, 38.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 40.5ms\n",
            "Speed: 2.4ms preprocess, 40.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 38.2ms\n",
            "Speed: 2.6ms preprocess, 38.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 39.6ms\n",
            "Speed: 2.4ms preprocess, 39.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 9 persons, 37.8ms\n",
            "Speed: 2.4ms preprocess, 37.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 15 persons, 38.0ms\n",
            "Speed: 2.2ms preprocess, 38.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 40.4ms\n",
            "Speed: 2.4ms preprocess, 40.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 11 persons, 37.1ms\n",
            "Speed: 2.0ms preprocess, 37.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 38.2ms\n",
            "Speed: 1.9ms preprocess, 38.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 12 persons, 39.4ms\n",
            "Speed: 2.8ms preprocess, 39.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 11 persons, 37.8ms\n",
            "Speed: 2.3ms preprocess, 37.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 persons, 39.4ms\n",
            "Speed: 2.2ms preprocess, 39.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 10 persons, 39.7ms\n",
            "Speed: 2.0ms preprocess, 39.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 persons, 38.7ms\n",
            "Speed: 2.3ms preprocess, 38.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 40.4ms\n",
            "Speed: 2.2ms preprocess, 40.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 10 persons, 38.0ms\n",
            "Speed: 2.2ms preprocess, 38.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 38.7ms\n",
            "Speed: 2.5ms preprocess, 38.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 9 persons, 40.0ms\n",
            "Speed: 2.0ms preprocess, 40.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 38.0ms\n",
            "Speed: 2.5ms preprocess, 38.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 11 persons, 40.0ms\n",
            "Speed: 3.0ms preprocess, 40.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 38.4ms\n",
            "Speed: 2.1ms preprocess, 38.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 38.6ms\n",
            "Speed: 2.5ms preprocess, 38.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 39.8ms\n",
            "Speed: 2.4ms preprocess, 39.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 38.9ms\n",
            "Speed: 2.2ms preprocess, 38.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 8 persons, 40.1ms\n",
            "Speed: 2.3ms preprocess, 40.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 37.7ms\n",
            "Speed: 1.9ms preprocess, 37.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 38.6ms\n",
            "Speed: 2.4ms preprocess, 38.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 39.0ms\n",
            "Speed: 2.0ms preprocess, 39.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 37.9ms\n",
            "Speed: 2.7ms preprocess, 37.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 39.6ms\n",
            "Speed: 2.5ms preprocess, 39.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 38.5ms\n",
            "Speed: 2.8ms preprocess, 38.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 9 persons, 38.7ms\n",
            "Speed: 2.0ms preprocess, 38.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 40.7ms\n",
            "Speed: 2.2ms preprocess, 40.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 persons, 38.0ms\n",
            "Speed: 2.6ms preprocess, 38.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 persons, 38.6ms\n",
            "Speed: 2.9ms preprocess, 38.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 9 persons, 39.0ms\n",
            "Speed: 2.3ms preprocess, 39.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 38.1ms\n",
            "Speed: 2.1ms preprocess, 38.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 39.6ms\n",
            "Speed: 2.3ms preprocess, 39.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 39.1ms\n",
            "Speed: 2.1ms preprocess, 39.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 38.4ms\n",
            "Speed: 2.3ms preprocess, 38.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 40.3ms\n",
            "Speed: 2.2ms preprocess, 40.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 37.8ms\n",
            "Speed: 2.8ms preprocess, 37.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 39.3ms\n",
            "Speed: 2.0ms preprocess, 39.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 persons, 39.2ms\n",
            "Speed: 2.1ms preprocess, 39.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 8 persons, 38.9ms\n",
            "Speed: 2.4ms preprocess, 38.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 11 persons, 39.5ms\n",
            "Speed: 2.0ms preprocess, 39.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 9 persons, 37.8ms\n",
            "Speed: 2.2ms preprocess, 37.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 12 persons, 38.9ms\n",
            "Speed: 2.0ms preprocess, 38.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 38.9ms\n",
            "Speed: 2.2ms preprocess, 38.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 13 persons, 38.1ms\n",
            "Speed: 2.6ms preprocess, 38.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 10 persons, 39.9ms\n",
            "Speed: 3.1ms preprocess, 39.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 37.5ms\n",
            "Speed: 2.8ms preprocess, 37.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 11 persons, 39.1ms\n",
            "Speed: 2.8ms preprocess, 39.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 8 persons, 39.0ms\n",
            "Speed: 2.5ms preprocess, 39.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 38.5ms\n",
            "Speed: 2.0ms preprocess, 38.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 39.5ms\n",
            "Speed: 3.0ms preprocess, 39.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 37.9ms\n",
            "Speed: 2.2ms preprocess, 37.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 12 persons, 39.4ms\n",
            "Speed: 2.1ms preprocess, 39.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 39.0ms\n",
            "Speed: 3.0ms preprocess, 39.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 10 persons, 38.2ms\n",
            "Speed: 2.1ms preprocess, 38.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 persons, 39.8ms\n",
            "Speed: 2.5ms preprocess, 39.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 38.3ms\n",
            "Speed: 2.2ms preprocess, 38.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 9 persons, 39.2ms\n",
            "Speed: 3.0ms preprocess, 39.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 9 persons, 38.8ms\n",
            "Speed: 2.5ms preprocess, 38.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 37.8ms\n",
            "Speed: 3.2ms preprocess, 37.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 9 persons, 39.0ms\n",
            "Speed: 2.4ms preprocess, 39.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 38.7ms\n",
            "Speed: 2.2ms preprocess, 38.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 40.3ms\n",
            "Speed: 2.8ms preprocess, 40.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 37.6ms\n",
            "Speed: 2.4ms preprocess, 37.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 9 persons, 39.9ms\n",
            "Speed: 2.7ms preprocess, 39.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 37.5ms\n",
            "Speed: 2.5ms preprocess, 37.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 38.6ms\n",
            "Speed: 2.2ms preprocess, 38.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 38.9ms\n",
            "Speed: 2.2ms preprocess, 38.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 37.8ms\n",
            "Speed: 2.3ms preprocess, 37.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 9 persons, 40.3ms\n",
            "Speed: 2.8ms preprocess, 40.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 37.5ms\n",
            "Speed: 2.0ms preprocess, 37.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 10 persons, 38.6ms\n",
            "Speed: 3.1ms preprocess, 38.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 11 persons, 38.0ms\n",
            "Speed: 2.5ms preprocess, 38.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 38.6ms\n",
            "Speed: 2.5ms preprocess, 38.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 9 persons, 39.6ms\n",
            "Speed: 2.1ms preprocess, 39.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 37.6ms\n",
            "Speed: 3.0ms preprocess, 37.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 8 persons, 40.2ms\n",
            "Speed: 2.2ms preprocess, 40.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 38.3ms\n",
            "Speed: 2.3ms preprocess, 38.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 38.6ms\n",
            "Speed: 2.0ms preprocess, 38.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 39.0ms\n",
            "Speed: 2.4ms preprocess, 39.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 persons, 37.5ms\n",
            "Speed: 2.3ms preprocess, 37.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 10 persons, 40.0ms\n",
            "Speed: 2.0ms preprocess, 40.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 38.0ms\n",
            "Speed: 3.0ms preprocess, 38.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 38.2ms\n",
            "Speed: 2.8ms preprocess, 38.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 9 persons, 38.9ms\n",
            "Speed: 2.2ms preprocess, 38.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 8 persons, 38.1ms\n",
            "Speed: 2.3ms preprocess, 38.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 40.2ms\n",
            "Speed: 2.7ms preprocess, 40.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 14 persons, 37.9ms\n",
            "Speed: 2.6ms preprocess, 37.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 38.5ms\n",
            "Speed: 3.1ms preprocess, 38.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 37.9ms\n",
            "Speed: 2.1ms preprocess, 37.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 38.5ms\n",
            "Speed: 2.0ms preprocess, 38.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 40.2ms\n",
            "Speed: 2.2ms preprocess, 40.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 37.8ms\n",
            "Speed: 2.3ms preprocess, 37.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 39.5ms\n",
            "Speed: 2.1ms preprocess, 39.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 13 persons, 39.1ms\n",
            "Speed: 2.6ms preprocess, 39.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 12 persons, 38.5ms\n",
            "Speed: 3.0ms preprocess, 38.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 13 persons, 39.5ms\n",
            "Speed: 2.1ms preprocess, 39.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 37.8ms\n",
            "Speed: 2.8ms preprocess, 37.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 persons, 39.3ms\n",
            "Speed: 2.4ms preprocess, 39.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 38.3ms\n",
            "Speed: 3.0ms preprocess, 38.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 37.5ms\n",
            "Speed: 3.0ms preprocess, 37.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 40.5ms\n",
            "Speed: 2.5ms preprocess, 40.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 38.0ms\n",
            "Speed: 2.4ms preprocess, 38.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 38.7ms\n",
            "Speed: 2.6ms preprocess, 38.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 39.1ms\n",
            "Speed: 2.3ms preprocess, 39.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 9 persons, 38.4ms\n",
            "Speed: 2.9ms preprocess, 38.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 41.2ms\n",
            "Speed: 2.8ms preprocess, 41.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 37.9ms\n",
            "Speed: 2.4ms preprocess, 37.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 39.0ms\n",
            "Speed: 2.2ms preprocess, 39.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 9 persons, 39.4ms\n",
            "Speed: 2.4ms preprocess, 39.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 37.8ms\n",
            "Speed: 2.0ms preprocess, 37.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 9 persons, 39.3ms\n",
            "Speed: 2.3ms preprocess, 39.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 39.1ms\n",
            "Speed: 2.2ms preprocess, 39.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 8 persons, 38.0ms\n",
            "Speed: 2.6ms preprocess, 38.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 8 persons, 40.1ms\n",
            "Speed: 1.9ms preprocess, 40.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 37.1ms\n",
            "Speed: 2.0ms preprocess, 37.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 38.4ms\n",
            "Speed: 2.2ms preprocess, 38.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 40.8ms\n",
            "Speed: 2.3ms preprocess, 40.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 12 persons, 38.0ms\n",
            "Speed: 2.4ms preprocess, 38.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 38.9ms\n",
            "Speed: 2.4ms preprocess, 38.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 39.0ms\n",
            "Speed: 2.6ms preprocess, 39.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 38.4ms\n",
            "Speed: 2.4ms preprocess, 38.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 8 persons, 39.9ms\n",
            "Speed: 2.7ms preprocess, 39.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 38.1ms\n",
            "Speed: 2.7ms preprocess, 38.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 10 persons, 40.0ms\n",
            "Speed: 2.4ms preprocess, 40.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 11 persons, 37.9ms\n",
            "Speed: 2.5ms preprocess, 37.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 38.6ms\n",
            "Speed: 2.0ms preprocess, 38.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 persons, 39.6ms\n",
            "Speed: 2.2ms preprocess, 39.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 11 persons, 37.8ms\n",
            "Speed: 2.7ms preprocess, 37.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 39.2ms\n",
            "Speed: 2.2ms preprocess, 39.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 39.0ms\n",
            "Speed: 2.2ms preprocess, 39.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 38.4ms\n",
            "Speed: 2.0ms preprocess, 38.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 8 persons, 39.7ms\n",
            "Speed: 2.2ms preprocess, 39.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 39.1ms\n",
            "Speed: 2.3ms preprocess, 39.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 38.6ms\n",
            "Speed: 2.8ms preprocess, 38.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 39.5ms\n",
            "Speed: 2.2ms preprocess, 39.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 38.1ms\n",
            "Speed: 2.9ms preprocess, 38.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 40.0ms\n",
            "Speed: 2.7ms preprocess, 40.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 37.9ms\n",
            "Speed: 2.2ms preprocess, 37.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 9 persons, 38.5ms\n",
            "Speed: 2.3ms preprocess, 38.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 8 persons, 39.6ms\n",
            "Speed: 2.2ms preprocess, 39.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 37.9ms\n",
            "Speed: 2.2ms preprocess, 37.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 39.9ms\n",
            "Speed: 2.4ms preprocess, 39.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 38.1ms\n",
            "Speed: 2.4ms preprocess, 38.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 persons, 38.2ms\n",
            "Speed: 3.0ms preprocess, 38.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 39.4ms\n",
            "Speed: 2.5ms preprocess, 39.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 38.0ms\n",
            "Speed: 2.2ms preprocess, 38.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 39.1ms\n",
            "Speed: 3.0ms preprocess, 39.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 38.9ms\n",
            "Speed: 2.2ms preprocess, 38.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 11 persons, 38.1ms\n",
            "Speed: 2.1ms preprocess, 38.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 9 persons, 40.4ms\n",
            "Speed: 2.4ms preprocess, 40.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 37.2ms\n",
            "Speed: 2.5ms preprocess, 37.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 11 persons, 38.4ms\n",
            "Speed: 2.5ms preprocess, 38.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 39.8ms\n",
            "Speed: 2.3ms preprocess, 39.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 12 persons, 37.9ms\n",
            "Speed: 2.2ms preprocess, 37.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 10 persons, 39.5ms\n",
            "Speed: 2.4ms preprocess, 39.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 39.5ms\n",
            "Speed: 2.3ms preprocess, 39.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 10 persons, 37.8ms\n",
            "Speed: 2.2ms preprocess, 37.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 39.5ms\n",
            "Speed: 2.3ms preprocess, 39.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 37.4ms\n",
            "Speed: 2.1ms preprocess, 37.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 38.9ms\n",
            "Speed: 2.2ms preprocess, 38.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 39.5ms\n",
            "Speed: 2.4ms preprocess, 39.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 38.1ms\n",
            "Speed: 2.5ms preprocess, 38.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 14 persons, 40.0ms\n",
            "Speed: 2.5ms preprocess, 40.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 37.4ms\n",
            "Speed: 3.0ms preprocess, 37.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 38.2ms\n",
            "Speed: 2.5ms preprocess, 38.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 39.5ms\n",
            "Speed: 2.3ms preprocess, 39.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 37.4ms\n",
            "Speed: 2.1ms preprocess, 37.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 39.3ms\n",
            "Speed: 2.4ms preprocess, 39.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 39.5ms\n",
            "Speed: 2.0ms preprocess, 39.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 37.8ms\n",
            "Speed: 2.6ms preprocess, 37.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 10 persons, 40.1ms\n",
            "Speed: 2.6ms preprocess, 40.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 38.1ms\n",
            "Speed: 2.1ms preprocess, 38.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 38.6ms\n",
            "Speed: 2.0ms preprocess, 38.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 9 persons, 39.0ms\n",
            "Speed: 2.1ms preprocess, 39.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 38.1ms\n",
            "Speed: 2.2ms preprocess, 38.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 8 persons, 39.5ms\n",
            "Speed: 2.3ms preprocess, 39.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 persons, 37.9ms\n",
            "Speed: 2.6ms preprocess, 37.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 persons, 38.0ms\n",
            "Speed: 2.3ms preprocess, 38.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 40.8ms\n",
            "Speed: 2.2ms preprocess, 40.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 37.7ms\n",
            "Speed: 3.1ms preprocess, 37.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 38.7ms\n",
            "Speed: 2.0ms preprocess, 38.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 38.1ms\n",
            "Speed: 2.4ms preprocess, 38.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 9 persons, 37.2ms\n",
            "Speed: 2.6ms preprocess, 37.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 11 persons, 39.4ms\n",
            "Speed: 2.2ms preprocess, 39.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 8 persons, 37.5ms\n",
            "Speed: 2.0ms preprocess, 37.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 38.7ms\n",
            "Speed: 2.3ms preprocess, 38.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 10 persons, 39.0ms\n",
            "Speed: 2.3ms preprocess, 39.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 38.4ms\n",
            "Speed: 2.2ms preprocess, 38.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 10 persons, 40.4ms\n",
            "Speed: 2.2ms preprocess, 40.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 persons, 37.4ms\n",
            "Speed: 2.9ms preprocess, 37.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 9 persons, 38.6ms\n",
            "Speed: 2.1ms preprocess, 38.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 38.9ms\n",
            "Speed: 3.2ms preprocess, 38.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 13 persons, 37.7ms\n",
            "Speed: 2.1ms preprocess, 37.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 9 persons, 39.6ms\n",
            "Speed: 2.3ms preprocess, 39.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 38.9ms\n",
            "Speed: 2.2ms preprocess, 38.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 8 persons, 38.4ms\n",
            "Speed: 2.2ms preprocess, 38.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 39.9ms\n",
            "Speed: 2.2ms preprocess, 39.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 37.3ms\n",
            "Speed: 1.9ms preprocess, 37.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 38.2ms\n",
            "Speed: 2.3ms preprocess, 38.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 39.3ms\n",
            "Speed: 2.7ms preprocess, 39.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 37.9ms\n",
            "Speed: 2.2ms preprocess, 37.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 39.3ms\n",
            "Speed: 2.5ms preprocess, 39.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 10 persons, 39.0ms\n",
            "Speed: 2.5ms preprocess, 39.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 9 persons, 38.4ms\n",
            "Speed: 2.1ms preprocess, 38.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 9 persons, 40.1ms\n",
            "Speed: 2.8ms preprocess, 40.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 37.0ms\n",
            "Speed: 2.0ms preprocess, 37.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 38.6ms\n",
            "Speed: 2.4ms preprocess, 38.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 39.5ms\n",
            "Speed: 2.3ms preprocess, 39.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 38.1ms\n",
            "Speed: 2.4ms preprocess, 38.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 39.7ms\n",
            "Speed: 2.3ms preprocess, 39.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 39.0ms\n",
            "Speed: 2.8ms preprocess, 39.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 9 persons, 38.4ms\n",
            "Speed: 2.3ms preprocess, 38.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 39.9ms\n",
            "Speed: 2.6ms preprocess, 39.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 37.4ms\n",
            "Speed: 2.3ms preprocess, 37.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 38.9ms\n",
            "Speed: 2.1ms preprocess, 38.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 39.5ms\n",
            "Speed: 2.0ms preprocess, 39.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 37.8ms\n",
            "Speed: 2.1ms preprocess, 37.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 8 persons, 38.6ms\n",
            "Speed: 2.4ms preprocess, 38.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 8 persons, 38.9ms\n",
            "Speed: 3.2ms preprocess, 38.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 38.1ms\n",
            "Speed: 2.4ms preprocess, 38.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 40.3ms\n",
            "Speed: 2.4ms preprocess, 40.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 persons, 37.5ms\n",
            "Speed: 2.0ms preprocess, 37.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 38.6ms\n",
            "Speed: 2.4ms preprocess, 38.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 10 persons, 39.3ms\n",
            "Speed: 2.2ms preprocess, 39.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 37.4ms\n",
            "Speed: 2.3ms preprocess, 37.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 8 persons, 38.9ms\n",
            "Speed: 2.9ms preprocess, 38.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 38.2ms\n",
            "Speed: 2.3ms preprocess, 38.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 38.5ms\n",
            "Speed: 2.4ms preprocess, 38.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 38.8ms\n",
            "Speed: 2.6ms preprocess, 38.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 9 persons, 37.8ms\n",
            "Speed: 3.0ms preprocess, 37.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 39.9ms\n",
            "Speed: 2.8ms preprocess, 39.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 persons, 37.9ms\n",
            "Speed: 2.3ms preprocess, 37.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 38.6ms\n",
            "Speed: 2.5ms preprocess, 38.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 39.0ms\n",
            "Speed: 2.4ms preprocess, 39.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 10 persons, 38.2ms\n",
            "Speed: 2.6ms preprocess, 38.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 9 persons, 40.1ms\n",
            "Speed: 2.7ms preprocess, 40.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 12 persons, 38.9ms\n",
            "Speed: 3.0ms preprocess, 38.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 38.1ms\n",
            "Speed: 2.5ms preprocess, 38.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 39.5ms\n",
            "Speed: 2.3ms preprocess, 39.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 37.4ms\n",
            "Speed: 2.5ms preprocess, 37.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 8 persons, 38.6ms\n",
            "Speed: 2.3ms preprocess, 38.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 39.0ms\n",
            "Speed: 2.2ms preprocess, 39.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 37.6ms\n",
            "Speed: 2.2ms preprocess, 37.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 38.6ms\n",
            "Speed: 2.4ms preprocess, 38.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 8 persons, 38.0ms\n",
            "Speed: 2.7ms preprocess, 38.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 38.0ms\n",
            "Speed: 2.4ms preprocess, 38.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 40.0ms\n",
            "Speed: 2.2ms preprocess, 40.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 37.3ms\n",
            "Speed: 3.1ms preprocess, 37.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 38.3ms\n",
            "Speed: 2.2ms preprocess, 38.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 38.9ms\n",
            "Speed: 2.9ms preprocess, 38.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 38.1ms\n",
            "Speed: 2.2ms preprocess, 38.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 39.5ms\n",
            "Speed: 2.3ms preprocess, 39.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 39.3ms\n",
            "Speed: 2.3ms preprocess, 39.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 9 persons, 38.0ms\n",
            "Speed: 2.1ms preprocess, 38.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 40.0ms\n",
            "Speed: 1.9ms preprocess, 40.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 persons, 37.6ms\n",
            "Speed: 2.7ms preprocess, 37.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 39.0ms\n",
            "Speed: 2.2ms preprocess, 39.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 39.8ms\n",
            "Speed: 2.6ms preprocess, 39.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 38.4ms\n",
            "Speed: 2.5ms preprocess, 38.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 persons, 39.5ms\n",
            "Speed: 2.3ms preprocess, 39.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 9 persons, 37.3ms\n",
            "Speed: 2.9ms preprocess, 37.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 38.6ms\n",
            "Speed: 2.7ms preprocess, 38.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 persons, 39.4ms\n",
            "Speed: 2.8ms preprocess, 39.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 37.8ms\n",
            "Speed: 2.4ms preprocess, 37.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 10 persons, 39.0ms\n",
            "Speed: 3.2ms preprocess, 39.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 10 persons, 37.4ms\n",
            "Speed: 2.2ms preprocess, 37.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 9 persons, 38.4ms\n",
            "Speed: 2.5ms preprocess, 38.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 39.5ms\n",
            "Speed: 2.4ms preprocess, 39.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 37.6ms\n",
            "Speed: 2.7ms preprocess, 37.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 12 persons, 38.3ms\n",
            "Speed: 2.6ms preprocess, 38.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 persons, 39.2ms\n",
            "Speed: 2.2ms preprocess, 39.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 10 persons, 37.8ms\n",
            "Speed: 2.5ms preprocess, 37.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 13 persons, 40.1ms\n",
            "Speed: 2.6ms preprocess, 40.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 39.0ms\n",
            "Speed: 2.3ms preprocess, 39.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 15 persons, 38.2ms\n",
            "Speed: 2.7ms preprocess, 38.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 39.9ms\n",
            "Speed: 2.0ms preprocess, 39.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 37.8ms\n",
            "Speed: 2.1ms preprocess, 37.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 38.3ms\n",
            "Speed: 2.9ms preprocess, 38.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 39.3ms\n",
            "Speed: 2.0ms preprocess, 39.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 11 persons, 37.8ms\n",
            "Speed: 2.5ms preprocess, 37.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 10 persons, 38.9ms\n",
            "Speed: 2.1ms preprocess, 38.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 13 persons, 37.2ms\n",
            "Speed: 3.0ms preprocess, 37.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 38.6ms\n",
            "Speed: 3.0ms preprocess, 38.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 39.0ms\n",
            "Speed: 2.5ms preprocess, 39.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 38.1ms\n",
            "Speed: 2.4ms preprocess, 38.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 40.1ms\n",
            "Speed: 2.3ms preprocess, 40.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 38.3ms\n",
            "Speed: 2.3ms preprocess, 38.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 38.5ms\n",
            "Speed: 2.3ms preprocess, 38.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 38.5ms\n",
            "Speed: 2.1ms preprocess, 38.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 37.8ms\n",
            "Speed: 3.1ms preprocess, 37.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 8 persons, 39.9ms\n",
            "Speed: 2.2ms preprocess, 39.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 37.4ms\n",
            "Speed: 2.3ms preprocess, 37.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 38.0ms\n",
            "Speed: 1.9ms preprocess, 38.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 9 persons, 40.3ms\n",
            "Speed: 2.1ms preprocess, 40.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 37.1ms\n",
            "Speed: 2.0ms preprocess, 37.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 38.2ms\n",
            "Speed: 2.6ms preprocess, 38.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 39.5ms\n",
            "Speed: 2.3ms preprocess, 39.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 8 persons, 38.1ms\n",
            "Speed: 2.1ms preprocess, 38.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 40.1ms\n",
            "Speed: 2.3ms preprocess, 40.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 37.9ms\n",
            "Speed: 2.5ms preprocess, 37.9ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 38.2ms\n",
            "Speed: 2.7ms preprocess, 38.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 39.0ms\n",
            "Speed: 3.0ms preprocess, 39.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 37.9ms\n",
            "Speed: 3.0ms preprocess, 37.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 11 persons, 40.3ms\n",
            "Speed: 2.7ms preprocess, 40.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 persons, 37.3ms\n",
            "Speed: 2.7ms preprocess, 37.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 38.3ms\n",
            "Speed: 3.0ms preprocess, 38.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 8 persons, 38.0ms\n",
            "Speed: 2.4ms preprocess, 38.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 persons, 38.1ms\n",
            "Speed: 2.7ms preprocess, 38.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 persons, 39.8ms\n",
            "Speed: 2.7ms preprocess, 39.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 persons, 37.6ms\n",
            "Speed: 2.3ms preprocess, 37.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 13 persons, 40.2ms\n",
            "Speed: 2.5ms preprocess, 40.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 37.4ms\n",
            "Speed: 3.1ms preprocess, 37.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 39.7ms\n",
            "Speed: 2.3ms preprocess, 39.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 persons, 38.4ms\n",
            "Speed: 2.9ms preprocess, 38.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 38.4ms\n",
            "Speed: 2.0ms preprocess, 38.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 40.0ms\n",
            "Speed: 2.3ms preprocess, 40.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 37.5ms\n",
            "Speed: 2.3ms preprocess, 37.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 39.0ms\n",
            "Speed: 3.0ms preprocess, 39.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 11 persons, 38.8ms\n",
            "Speed: 2.2ms preprocess, 38.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 37.9ms\n",
            "Speed: 2.3ms preprocess, 37.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 40.7ms\n",
            "Speed: 2.3ms preprocess, 40.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 37.5ms\n",
            "Speed: 2.4ms preprocess, 37.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 38.2ms\n",
            "Speed: 2.3ms preprocess, 38.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 13 persons, 39.6ms\n",
            "Speed: 2.1ms preprocess, 39.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 37.2ms\n",
            "Speed: 2.2ms preprocess, 37.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 38.2ms\n",
            "Speed: 2.7ms preprocess, 38.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 38.9ms\n",
            "Speed: 3.0ms preprocess, 38.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 10 persons, 37.9ms\n",
            "Speed: 2.8ms preprocess, 37.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 persons, 40.3ms\n",
            "Speed: 2.3ms preprocess, 40.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 37.4ms\n",
            "Speed: 2.7ms preprocess, 37.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 38.6ms\n",
            "Speed: 2.2ms preprocess, 38.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 39.0ms\n",
            "Speed: 2.3ms preprocess, 39.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 10 persons, 38.1ms\n",
            "Speed: 1.9ms preprocess, 38.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 39.5ms\n",
            "Speed: 2.9ms preprocess, 39.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 10 persons, 37.8ms\n",
            "Speed: 1.9ms preprocess, 37.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 38.3ms\n",
            "Speed: 2.5ms preprocess, 38.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 39.5ms\n",
            "Speed: 1.9ms preprocess, 39.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 37.9ms\n",
            "Speed: 2.2ms preprocess, 37.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 38.6ms\n",
            "Speed: 2.2ms preprocess, 38.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 38.7ms\n",
            "Speed: 2.2ms preprocess, 38.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 37.1ms\n",
            "Speed: 2.2ms preprocess, 37.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 8 persons, 38.6ms\n",
            "Speed: 2.4ms preprocess, 38.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 39.7ms\n",
            "Speed: 2.3ms preprocess, 39.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 37.9ms\n",
            "Speed: 2.3ms preprocess, 37.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 persons, 40.0ms\n",
            "Speed: 3.1ms preprocess, 40.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 38.3ms\n",
            "Speed: 2.6ms preprocess, 38.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 38.5ms\n",
            "Speed: 2.3ms preprocess, 38.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 8 persons, 40.1ms\n",
            "Speed: 2.3ms preprocess, 40.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 38.0ms\n",
            "Speed: 2.5ms preprocess, 38.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 39.3ms\n",
            "Speed: 2.2ms preprocess, 39.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 38.0ms\n",
            "Speed: 2.4ms preprocess, 38.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 38.0ms\n",
            "Speed: 2.3ms preprocess, 38.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 8 persons, 40.8ms\n",
            "Speed: 2.2ms preprocess, 40.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 8 persons, 37.7ms\n",
            "Speed: 2.1ms preprocess, 37.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 8 persons, 38.1ms\n",
            "Speed: 2.6ms preprocess, 38.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 9 persons, 39.5ms\n",
            "Speed: 2.0ms preprocess, 39.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 38.0ms\n",
            "Speed: 2.4ms preprocess, 38.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 9 persons, 39.0ms\n",
            "Speed: 2.4ms preprocess, 39.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 persons, 39.0ms\n",
            "Speed: 2.3ms preprocess, 39.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 38.7ms\n",
            "Speed: 2.3ms preprocess, 38.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 40.2ms\n",
            "Speed: 2.9ms preprocess, 40.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 37.1ms\n",
            "Speed: 3.0ms preprocess, 37.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 38.6ms\n",
            "Speed: 2.6ms preprocess, 38.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 10 persons, 39.0ms\n",
            "Speed: 2.3ms preprocess, 39.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 persons, 38.1ms\n",
            "Speed: 2.4ms preprocess, 38.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 40.4ms\n",
            "Speed: 2.0ms preprocess, 40.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 38.0ms\n",
            "Speed: 2.4ms preprocess, 38.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 38.6ms\n",
            "Speed: 2.4ms preprocess, 38.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 8 persons, 39.4ms\n",
            "Speed: 2.3ms preprocess, 39.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 37.1ms\n",
            "Speed: 2.3ms preprocess, 37.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 persons, 38.2ms\n",
            "Speed: 2.9ms preprocess, 38.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 39.1ms\n",
            "Speed: 2.6ms preprocess, 39.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 37.6ms\n",
            "Speed: 2.8ms preprocess, 37.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 8 persons, 40.5ms\n",
            "Speed: 2.1ms preprocess, 40.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 37.6ms\n",
            "Speed: 2.1ms preprocess, 37.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 38.5ms\n",
            "Speed: 2.2ms preprocess, 38.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 39.3ms\n",
            "Speed: 2.0ms preprocess, 39.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 persons, 37.9ms\n",
            "Speed: 2.3ms preprocess, 37.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 10 persons, 39.7ms\n",
            "Speed: 2.0ms preprocess, 39.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 38.6ms\n",
            "Speed: 2.5ms preprocess, 38.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 38.5ms\n",
            "Speed: 2.6ms preprocess, 38.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 39.6ms\n",
            "Speed: 2.0ms preprocess, 39.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 38.0ms\n",
            "Speed: 2.0ms preprocess, 38.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 38.1ms\n",
            "Speed: 2.1ms preprocess, 38.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 8 persons, 39.6ms\n",
            "Speed: 2.2ms preprocess, 39.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 37.7ms\n",
            "Speed: 2.2ms preprocess, 37.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 38.2ms\n",
            "Speed: 2.3ms preprocess, 38.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 39.3ms\n",
            "Speed: 2.4ms preprocess, 39.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 38.0ms\n",
            "Speed: 2.1ms preprocess, 38.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 39.5ms\n",
            "Speed: 2.9ms preprocess, 39.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 8 persons, 37.2ms\n",
            "Speed: 2.4ms preprocess, 37.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 38.5ms\n",
            "Speed: 2.4ms preprocess, 38.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 38.5ms\n",
            "Speed: 2.3ms preprocess, 38.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 38.1ms\n",
            "Speed: 2.4ms preprocess, 38.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 persons, 40.7ms\n",
            "Speed: 2.3ms preprocess, 40.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 10 persons, 37.1ms\n",
            "Speed: 2.3ms preprocess, 37.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 38.1ms\n",
            "Speed: 2.3ms preprocess, 38.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 persons, 39.3ms\n",
            "Speed: 2.4ms preprocess, 39.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 38.0ms\n",
            "Speed: 2.3ms preprocess, 38.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 12 persons, 38.9ms\n",
            "Speed: 2.2ms preprocess, 38.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 12 persons, 38.3ms\n",
            "Speed: 2.5ms preprocess, 38.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 38.3ms\n",
            "Speed: 2.3ms preprocess, 38.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 39.6ms\n",
            "Speed: 2.2ms preprocess, 39.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 8 persons, 37.4ms\n",
            "Speed: 2.6ms preprocess, 37.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 38.5ms\n",
            "Speed: 2.2ms preprocess, 38.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 39.5ms\n",
            "Speed: 2.1ms preprocess, 39.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 10 persons, 37.4ms\n",
            "Speed: 2.4ms preprocess, 37.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 10 persons, 38.2ms\n",
            "Speed: 2.3ms preprocess, 38.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 39.4ms\n",
            "Speed: 2.2ms preprocess, 39.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 persons, 37.9ms\n",
            "Speed: 2.8ms preprocess, 37.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 38.9ms\n",
            "Speed: 2.1ms preprocess, 38.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 38.3ms\n",
            "Speed: 2.5ms preprocess, 38.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 38.0ms\n",
            "Speed: 3.1ms preprocess, 38.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 39.5ms\n",
            "Speed: 2.0ms preprocess, 39.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 10 persons, 37.8ms\n",
            "Speed: 2.4ms preprocess, 37.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 39.9ms\n",
            "Speed: 2.8ms preprocess, 39.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 37.9ms\n",
            "Speed: 2.3ms preprocess, 37.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 8 persons, 38.1ms\n",
            "Speed: 2.4ms preprocess, 38.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 39.3ms\n",
            "Speed: 2.2ms preprocess, 39.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 37.6ms\n",
            "Speed: 2.0ms preprocess, 37.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 8 persons, 38.9ms\n",
            "Speed: 2.2ms preprocess, 38.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 38.9ms\n",
            "Speed: 2.3ms preprocess, 38.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 15 persons, 38.1ms\n",
            "Speed: 3.0ms preprocess, 38.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 13 persons, 40.7ms\n",
            "Speed: 2.0ms preprocess, 40.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 37.9ms\n",
            "Speed: 2.2ms preprocess, 37.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 persons, 38.0ms\n",
            "Speed: 2.9ms preprocess, 38.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 40.3ms\n",
            "Speed: 2.1ms preprocess, 40.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 12 persons, 37.2ms\n",
            "Speed: 2.3ms preprocess, 37.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 38.2ms\n",
            "Speed: 2.4ms preprocess, 38.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 39.0ms\n",
            "Speed: 2.2ms preprocess, 39.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 38.0ms\n",
            "Speed: 2.6ms preprocess, 38.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 38.9ms\n",
            "Speed: 2.3ms preprocess, 38.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 38.6ms\n",
            "Speed: 2.2ms preprocess, 38.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 11 persons, 38.6ms\n",
            "Speed: 2.4ms preprocess, 38.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 8 persons, 39.1ms\n",
            "Speed: 2.5ms preprocess, 39.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 persons, 37.8ms\n",
            "Speed: 3.2ms preprocess, 37.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 39.6ms\n",
            "Speed: 3.1ms preprocess, 39.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 37.2ms\n",
            "Speed: 2.4ms preprocess, 37.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 38.2ms\n",
            "Speed: 3.0ms preprocess, 38.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 39.4ms\n",
            "Speed: 2.5ms preprocess, 39.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 38.1ms\n",
            "Speed: 2.5ms preprocess, 38.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 10 persons, 39.6ms\n",
            "Speed: 2.2ms preprocess, 39.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 38.5ms\n",
            "Speed: 3.1ms preprocess, 38.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 11 persons, 38.1ms\n",
            "Speed: 3.0ms preprocess, 38.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 39.7ms\n",
            "Speed: 2.6ms preprocess, 39.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 37.4ms\n",
            "Speed: 2.3ms preprocess, 37.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 38.6ms\n",
            "Speed: 2.7ms preprocess, 38.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 38.7ms\n",
            "Speed: 2.5ms preprocess, 38.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 8 persons, 37.7ms\n",
            "Speed: 2.3ms preprocess, 37.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 38.2ms\n",
            "Speed: 3.0ms preprocess, 38.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 38.9ms\n",
            "Speed: 2.1ms preprocess, 38.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 38.3ms\n",
            "Speed: 2.2ms preprocess, 38.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 40.3ms\n",
            "Speed: 2.1ms preprocess, 40.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 13 persons, 36.8ms\n",
            "Speed: 2.6ms preprocess, 36.8ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 37.7ms\n",
            "Speed: 2.5ms preprocess, 37.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 38.6ms\n",
            "Speed: 2.7ms preprocess, 38.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 37.9ms\n",
            "Speed: 2.1ms preprocess, 37.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 9 persons, 39.4ms\n",
            "Speed: 2.6ms preprocess, 39.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 39.0ms\n",
            "Speed: 2.0ms preprocess, 39.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 9 persons, 38.2ms\n",
            "Speed: 2.4ms preprocess, 38.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 40.1ms\n",
            "Speed: 2.3ms preprocess, 40.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 persons, 39.0ms\n",
            "Speed: 2.2ms preprocess, 39.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 11 persons, 38.5ms\n",
            "Speed: 2.2ms preprocess, 38.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 39.6ms\n",
            "Speed: 2.1ms preprocess, 39.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 8 persons, 37.9ms\n",
            "Speed: 2.3ms preprocess, 37.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 9 persons, 38.8ms\n",
            "Speed: 1.9ms preprocess, 38.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 persons, 39.2ms\n",
            "Speed: 2.3ms preprocess, 39.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 9 persons, 37.2ms\n",
            "Speed: 2.2ms preprocess, 37.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 38.9ms\n",
            "Speed: 2.5ms preprocess, 38.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 39.2ms\n",
            "Speed: 2.3ms preprocess, 39.2ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 11 persons, 37.8ms\n",
            "Speed: 2.3ms preprocess, 37.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 10 persons, 38.9ms\n",
            "Speed: 2.4ms preprocess, 38.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 38.2ms\n",
            "Speed: 3.1ms preprocess, 38.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 persons, 37.5ms\n",
            "Speed: 2.2ms preprocess, 37.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 40.1ms\n",
            "Speed: 2.7ms preprocess, 40.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 37.7ms\n",
            "Speed: 2.4ms preprocess, 37.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 38.5ms\n",
            "Speed: 2.1ms preprocess, 38.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 39.0ms\n",
            "Speed: 2.9ms preprocess, 39.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 38.6ms\n",
            "Speed: 2.5ms preprocess, 38.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 40.3ms\n",
            "Speed: 2.1ms preprocess, 40.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 8 persons, 37.7ms\n",
            "Speed: 2.3ms preprocess, 37.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 38.5ms\n",
            "Speed: 2.0ms preprocess, 38.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 39.6ms\n",
            "Speed: 2.2ms preprocess, 39.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 8 persons, 37.8ms\n",
            "Speed: 2.9ms preprocess, 37.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 39.7ms\n",
            "Speed: 2.4ms preprocess, 39.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 39.1ms\n",
            "Speed: 2.2ms preprocess, 39.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 4 persons, 38.0ms\n",
            "Speed: 2.9ms preprocess, 38.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 5 persons, 40.1ms\n",
            "Speed: 2.1ms preprocess, 40.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 37.1ms\n",
            "Speed: 2.4ms preprocess, 37.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 13 persons, 38.5ms\n",
            "Speed: 2.1ms preprocess, 38.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 14 persons, 38.6ms\n",
            "Speed: 2.1ms preprocess, 38.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 6 persons, 38.0ms\n",
            "Speed: 2.5ms preprocess, 38.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 9 persons, 39.3ms\n",
            "Speed: 2.3ms preprocess, 39.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 12 persons, 39.1ms\n",
            "Speed: 2.2ms preprocess, 39.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 3 persons, 38.5ms\n",
            "Speed: 2.6ms preprocess, 38.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 9 persons, 39.6ms\n",
            "Speed: 2.8ms preprocess, 39.6ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 7 persons, 37.3ms\n",
            "Speed: 2.6ms preprocess, 37.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Create empty pose data list\n",
        "pose_data = []\n",
        "\n",
        "# columns for df\n",
        "columns = ['filename', 'OKD', 'NOKD']\n",
        "for i in range(17):  # Assuming 17 keypoints\n",
        "    columns.extend([f'pose_x_{i}', f'pose_y_{i}'])\n",
        "\n",
        "# Process each subfolder\n",
        "for subfolder in ['OKD', 'NOKD']:\n",
        "    subfolder_path = os.path.join(input_folder, subfolder)\n",
        "\n",
        "    for filename in os.listdir(subfolder_path):\n",
        "        if filename.lower().endswith(('.jpg', '.jpeg')):\n",
        "            input_path = os.path.join(subfolder_path, filename)\n",
        "\n",
        "            img = cv2.imread(input_path)\n",
        "            if img is None:\n",
        "                print(f\"{input_path} failed to load.\")\n",
        "                continue\n",
        "\n",
        "            # run pose with 10% confidence min threshold\n",
        "            pose_results = pose_model(img, device='cuda', verbose=True, conf=0.1)[0]\n",
        "            pose_points = pose_results.keypoints[0].xyn[0].cpu().numpy().tolist()\n",
        "            pose_points = [(float(x), float(y)) for x, y in pose_points]\n",
        "\n",
        "            # Determine OKD or NOKD based on classification folder\n",
        "            okd = 1 if subfolder == 'OKD' else 0\n",
        "            nokd = 1 - okd\n",
        "\n",
        "            row = [filename, okd, nokd]\n",
        "\n",
        "            for i in range(17):\n",
        "                if i < len(pose_points):\n",
        "                    row.extend(pose_points[i])\n",
        "                else:\n",
        "                    row.extend([None, None])  # None if missing\n",
        "\n",
        "            pose_data.append(row)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Z8r48eruNy_"
      },
      "source": [
        "- Create dataframe for analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "hdkksjO7rxPI",
        "outputId": "ae38f330-cbf3-426a-cc80-aad56d78ab07"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Rows: 2816 | Columns: 37\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-50e9b192-0574-44c6-983d-072b4db83822\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>OKD</th>\n",
              "      <th>NOKD</th>\n",
              "      <th>pose_x_0</th>\n",
              "      <th>pose_y_0</th>\n",
              "      <th>pose_x_1</th>\n",
              "      <th>pose_y_1</th>\n",
              "      <th>pose_x_2</th>\n",
              "      <th>pose_y_2</th>\n",
              "      <th>pose_x_3</th>\n",
              "      <th>...</th>\n",
              "      <th>pose_x_12</th>\n",
              "      <th>pose_y_12</th>\n",
              "      <th>pose_x_13</th>\n",
              "      <th>pose_y_13</th>\n",
              "      <th>pose_x_14</th>\n",
              "      <th>pose_y_14</th>\n",
              "      <th>pose_x_15</th>\n",
              "      <th>pose_y_15</th>\n",
              "      <th>pose_x_16</th>\n",
              "      <th>pose_y_16</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>000081.jpg</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.117915</td>\n",
              "      <td>0.113611</td>\n",
              "      <td>0.127501</td>\n",
              "      <td>0.099366</td>\n",
              "      <td>0.101761</td>\n",
              "      <td>0.098568</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.072171</td>\n",
              "      <td>0.403215</td>\n",
              "      <td>0.186927</td>\n",
              "      <td>0.543835</td>\n",
              "      <td>0.085750</td>\n",
              "      <td>0.579695</td>\n",
              "      <td>0.119016</td>\n",
              "      <td>0.708583</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.713879</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>002852.jpg</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.466619</td>\n",
              "      <td>0.331017</td>\n",
              "      <td>0.483839</td>\n",
              "      <td>0.317607</td>\n",
              "      <td>0.445003</td>\n",
              "      <td>0.315951</td>\n",
              "      <td>0.509351</td>\n",
              "      <td>...</td>\n",
              "      <td>0.436511</td>\n",
              "      <td>0.622762</td>\n",
              "      <td>0.687442</td>\n",
              "      <td>0.678112</td>\n",
              "      <td>0.304950</td>\n",
              "      <td>0.538863</td>\n",
              "      <td>0.630653</td>\n",
              "      <td>0.726693</td>\n",
              "      <td>0.345687</td>\n",
              "      <td>0.714473</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>005277.jpg</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.489538</td>\n",
              "      <td>0.323467</td>\n",
              "      <td>0.509563</td>\n",
              "      <td>0.309117</td>\n",
              "      <td>0.468071</td>\n",
              "      <td>0.307666</td>\n",
              "      <td>0.539809</td>\n",
              "      <td>...</td>\n",
              "      <td>0.441234</td>\n",
              "      <td>0.616522</td>\n",
              "      <td>0.709722</td>\n",
              "      <td>0.678872</td>\n",
              "      <td>0.312557</td>\n",
              "      <td>0.562543</td>\n",
              "      <td>0.556522</td>\n",
              "      <td>0.732833</td>\n",
              "      <td>0.411327</td>\n",
              "      <td>0.715870</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>004041.jpg</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.209192</td>\n",
              "      <td>0.071663</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.196286</td>\n",
              "      <td>0.060132</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.181014</td>\n",
              "      <td>0.367919</td>\n",
              "      <td>0.235090</td>\n",
              "      <td>0.548650</td>\n",
              "      <td>0.166215</td>\n",
              "      <td>0.572018</td>\n",
              "      <td>0.194912</td>\n",
              "      <td>0.710301</td>\n",
              "      <td>0.102112</td>\n",
              "      <td>0.743998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>000697.jpg</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.497751</td>\n",
              "      <td>0.359748</td>\n",
              "      <td>0.511930</td>\n",
              "      <td>0.346465</td>\n",
              "      <td>0.481172</td>\n",
              "      <td>0.347219</td>\n",
              "      <td>0.535631</td>\n",
              "      <td>...</td>\n",
              "      <td>0.462590</td>\n",
              "      <td>0.588794</td>\n",
              "      <td>0.613503</td>\n",
              "      <td>0.655703</td>\n",
              "      <td>0.367108</td>\n",
              "      <td>0.532407</td>\n",
              "      <td>0.617004</td>\n",
              "      <td>0.677573</td>\n",
              "      <td>0.429643</td>\n",
              "      <td>0.672072</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 37 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-50e9b192-0574-44c6-983d-072b4db83822')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-50e9b192-0574-44c6-983d-072b4db83822 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-50e9b192-0574-44c6-983d-072b4db83822');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d9b32987-5708-44cc-b84c-c671ed9febcd\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d9b32987-5708-44cc-b84c-c671ed9febcd')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d9b32987-5708-44cc-b84c-c671ed9febcd button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "     filename  OKD  NOKD  pose_x_0  pose_y_0  pose_x_1  pose_y_1  pose_x_2  \\\n",
              "0  000081.jpg    1     0  0.117915  0.113611  0.127501  0.099366  0.101761   \n",
              "1  002852.jpg    1     0  0.466619  0.331017  0.483839  0.317607  0.445003   \n",
              "2  005277.jpg    1     0  0.489538  0.323467  0.509563  0.309117  0.468071   \n",
              "3  004041.jpg    1     0  0.209192  0.071663  0.000000  0.000000  0.196286   \n",
              "4  000697.jpg    1     0  0.497751  0.359748  0.511930  0.346465  0.481172   \n",
              "\n",
              "   pose_y_2  pose_x_3  ...  pose_x_12  pose_y_12  pose_x_13  pose_y_13  \\\n",
              "0  0.098568  0.000000  ...   0.072171   0.403215   0.186927   0.543835   \n",
              "1  0.315951  0.509351  ...   0.436511   0.622762   0.687442   0.678112   \n",
              "2  0.307666  0.539809  ...   0.441234   0.616522   0.709722   0.678872   \n",
              "3  0.060132  0.000000  ...   0.181014   0.367919   0.235090   0.548650   \n",
              "4  0.347219  0.535631  ...   0.462590   0.588794   0.613503   0.655703   \n",
              "\n",
              "   pose_x_14  pose_y_14  pose_x_15  pose_y_15  pose_x_16  pose_y_16  \n",
              "0   0.085750   0.579695   0.119016   0.708583   0.000000   0.713879  \n",
              "1   0.304950   0.538863   0.630653   0.726693   0.345687   0.714473  \n",
              "2   0.312557   0.562543   0.556522   0.732833   0.411327   0.715870  \n",
              "3   0.166215   0.572018   0.194912   0.710301   0.102112   0.743998  \n",
              "4   0.367108   0.532407   0.617004   0.677573   0.429643   0.672072  \n",
              "\n",
              "[5 rows x 37 columns]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "df = pd.DataFrame(pose_data, columns=columns)\n",
        "print(f\"Rows: {df.shape[0]} | Columns: {df.shape[1]}\")\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4ckedL5rxPK"
      },
      "source": [
        "### Fill NaN values with 0, print value counts for OKD (should be even-split with 1408 of each class)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "yKnAHyWxrxPK",
        "outputId": "f0f391d1-a5ba-4cf4-f185-dfe9b7c9536c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>OKD</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1408</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1408</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ],
            "text/plain": [
              "OKD\n",
              "0      1408\n",
              "1      1408\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.fillna(0, inplace=True)\n",
        "df[['OKD']].value_counts()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvjcuuk7rxPK"
      },
      "source": [
        "## Train AutoML Classification Instance\n",
        "\n",
        "### Explore different types of sci-kit learn models to find the best model for this specific use-case\n",
        "\n",
        "- Install and Import libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wXube5UWy6XU",
        "outputId": "72c9b45b-19ec-4f9e-ea8d-c328ad2af9c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting flaml\n",
            "  Downloading FLAML-2.3.1-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: NumPy>=1.17 in /usr/local/lib/python3.10/dist-packages (from flaml) (1.26.4)\n",
            "Downloading FLAML-2.3.1-py3-none-any.whl (313 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.3/313.3 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: flaml\n",
            "Successfully installed flaml-2.3.1\n"
          ]
        }
      ],
      "source": [
        "!pip install flaml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9rZIaxXGvMAy",
        "outputId": "a7a9d1c0-0bc4-45bc-ff36-1870e28c4ad7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
            "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\n",
            "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "This will raise in a future version.\n",
            "\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from flaml import AutoML\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.exceptions import ConvergenceWarning\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import warnings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8eCdM_ZqvD4C"
      },
      "source": [
        "- Create an 80/20 train/test split based on feature points and target OKD\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "-HCsZ6Z2vOaS"
      },
      "outputs": [],
      "source": [
        "warnings.filterwarnings('ignore', category=ConvergenceWarning) #ignore warnings about iterations of non-converging models\n",
        "\n",
        "features = df.drop(columns=['filename', 'OKD', 'NOKD']) #keypoint data\n",
        "target = df['OKD'] #train to predict OKD\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=22, stratify=target, shuffle=True) #80/20 train/test split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOdYh0c0vFuR"
      },
      "source": [
        "- Train AutoML classifier for 6 minutes optimizing for accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K6P6Fa0qvT5S",
        "outputId": "53eea89b-ef98-4384-8539-aba8a33cf215"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[flaml.automl.logger: 10-17 04:18:37] {1728} INFO - task = classification\n",
            "[flaml.automl.logger: 10-17 04:18:37] {1739} INFO - Evaluation method: cv\n",
            "[flaml.automl.logger: 10-17 04:18:37] {1838} INFO - Minimizing error metric: 1-accuracy\n",
            "[flaml.automl.logger: 10-17 04:18:37] {1955} INFO - List of ML learners in AutoML Run: ['lgbm', 'rf', 'xgboost', 'extra_tree', 'xgb_limitdepth', 'sgd', 'lrl1']\n",
            "[flaml.automl.logger: 10-17 04:18:37] {2258} INFO - iteration 0, current learner lgbm\n",
            "[flaml.automl.logger: 10-17 04:18:37] {2393} INFO - Estimated sufficient time budget=1185s. Estimated necessary time budget=27s.\n",
            "[flaml.automl.logger: 10-17 04:18:37] {2442} INFO -  at 0.2s,\testimator lgbm's best error=0.3104,\tbest estimator lgbm's best error=0.3104\n",
            "[flaml.automl.logger: 10-17 04:18:37] {2258} INFO - iteration 1, current learner lgbm\n",
            "[flaml.automl.logger: 10-17 04:18:37] {2442} INFO -  at 0.2s,\testimator lgbm's best error=0.3104,\tbest estimator lgbm's best error=0.3104\n",
            "[flaml.automl.logger: 10-17 04:18:37] {2258} INFO - iteration 2, current learner lgbm\n",
            "[flaml.automl.logger: 10-17 04:18:37] {2442} INFO -  at 0.3s,\testimator lgbm's best error=0.2922,\tbest estimator lgbm's best error=0.2922\n",
            "[flaml.automl.logger: 10-17 04:18:37] {2258} INFO - iteration 3, current learner sgd\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:flaml.tune.searcher.blendsearch:No low-cost partial config given to the search algorithm. For cost-frugal search, consider providing low-cost values for cost-related hps via 'low_cost_partial_config'. More info can be found at https://microsoft.github.io/FLAML/docs/FAQ#about-low_cost_partial_config-in-tune\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[flaml.automl.logger: 10-17 04:18:37] {2442} INFO -  at 0.4s,\testimator sgd's best error=0.4667,\tbest estimator lgbm's best error=0.2922\n",
            "[flaml.automl.logger: 10-17 04:18:37] {2258} INFO - iteration 4, current learner lgbm\n",
            "[flaml.automl.logger: 10-17 04:18:37] {2442} INFO -  at 0.6s,\testimator lgbm's best error=0.2669,\tbest estimator lgbm's best error=0.2669\n",
            "[flaml.automl.logger: 10-17 04:18:37] {2258} INFO - iteration 5, current learner lgbm\n",
            "[flaml.automl.logger: 10-17 04:18:37] {2442} INFO -  at 0.7s,\testimator lgbm's best error=0.2669,\tbest estimator lgbm's best error=0.2669\n",
            "[flaml.automl.logger: 10-17 04:18:37] {2258} INFO - iteration 6, current learner lgbm\n",
            "[flaml.automl.logger: 10-17 04:18:37] {2442} INFO -  at 0.8s,\testimator lgbm's best error=0.2651,\tbest estimator lgbm's best error=0.2651\n",
            "[flaml.automl.logger: 10-17 04:18:37] {2258} INFO - iteration 7, current learner lgbm\n",
            "[flaml.automl.logger: 10-17 04:18:37] {2442} INFO -  at 0.8s,\testimator lgbm's best error=0.2651,\tbest estimator lgbm's best error=0.2651\n",
            "[flaml.automl.logger: 10-17 04:18:38] {2258} INFO - iteration 8, current learner lgbm\n",
            "[flaml.automl.logger: 10-17 04:18:38] {2442} INFO -  at 0.9s,\testimator lgbm's best error=0.2651,\tbest estimator lgbm's best error=0.2651\n",
            "[flaml.automl.logger: 10-17 04:18:38] {2258} INFO - iteration 9, current learner lgbm\n",
            "[flaml.automl.logger: 10-17 04:18:38] {2442} INFO -  at 1.0s,\testimator lgbm's best error=0.2429,\tbest estimator lgbm's best error=0.2429\n",
            "[flaml.automl.logger: 10-17 04:18:38] {2258} INFO - iteration 10, current learner sgd\n",
            "[flaml.automl.logger: 10-17 04:18:38] {2442} INFO -  at 1.2s,\testimator sgd's best error=0.4378,\tbest estimator lgbm's best error=0.2429\n",
            "[flaml.automl.logger: 10-17 04:18:38] {2258} INFO - iteration 11, current learner xgboost\n",
            "[flaml.automl.logger: 10-17 04:18:38] {2442} INFO -  at 1.5s,\testimator xgboost's best error=0.3126,\tbest estimator lgbm's best error=0.2429\n",
            "[flaml.automl.logger: 10-17 04:18:38] {2258} INFO - iteration 12, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:18:38] {2442} INFO -  at 1.6s,\testimator extra_tree's best error=0.3828,\tbest estimator lgbm's best error=0.2429\n",
            "[flaml.automl.logger: 10-17 04:18:38] {2258} INFO - iteration 13, current learner xgboost\n",
            "[flaml.automl.logger: 10-17 04:18:38] {2442} INFO -  at 1.8s,\testimator xgboost's best error=0.3126,\tbest estimator lgbm's best error=0.2429\n",
            "[flaml.automl.logger: 10-17 04:18:38] {2258} INFO - iteration 14, current learner xgboost\n",
            "[flaml.automl.logger: 10-17 04:18:39] {2442} INFO -  at 2.0s,\testimator xgboost's best error=0.2926,\tbest estimator lgbm's best error=0.2429\n",
            "[flaml.automl.logger: 10-17 04:18:39] {2258} INFO - iteration 15, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:18:39] {2442} INFO -  at 2.2s,\testimator extra_tree's best error=0.3659,\tbest estimator lgbm's best error=0.2429\n",
            "[flaml.automl.logger: 10-17 04:18:39] {2258} INFO - iteration 16, current learner rf\n",
            "[flaml.automl.logger: 10-17 04:18:39] {2442} INFO -  at 2.4s,\testimator rf's best error=0.3370,\tbest estimator lgbm's best error=0.2429\n",
            "[flaml.automl.logger: 10-17 04:18:39] {2258} INFO - iteration 17, current learner lgbm\n",
            "[flaml.automl.logger: 10-17 04:18:39] {2442} INFO -  at 2.4s,\testimator lgbm's best error=0.2429,\tbest estimator lgbm's best error=0.2429\n",
            "[flaml.automl.logger: 10-17 04:18:39] {2258} INFO - iteration 18, current learner xgboost\n",
            "[flaml.automl.logger: 10-17 04:18:39] {2442} INFO -  at 2.6s,\testimator xgboost's best error=0.2775,\tbest estimator lgbm's best error=0.2429\n",
            "[flaml.automl.logger: 10-17 04:18:39] {2258} INFO - iteration 19, current learner lgbm\n",
            "[flaml.automl.logger: 10-17 04:18:40] {2442} INFO -  at 3.3s,\testimator lgbm's best error=0.2251,\tbest estimator lgbm's best error=0.2251\n",
            "[flaml.automl.logger: 10-17 04:18:40] {2258} INFO - iteration 20, current learner rf\n",
            "[flaml.automl.logger: 10-17 04:18:40] {2442} INFO -  at 3.4s,\testimator rf's best error=0.2784,\tbest estimator lgbm's best error=0.2251\n",
            "[flaml.automl.logger: 10-17 04:18:40] {2258} INFO - iteration 21, current learner rf\n",
            "[flaml.automl.logger: 10-17 04:18:40] {2442} INFO -  at 3.6s,\testimator rf's best error=0.2784,\tbest estimator lgbm's best error=0.2251\n",
            "[flaml.automl.logger: 10-17 04:18:40] {2258} INFO - iteration 22, current learner rf\n",
            "[flaml.automl.logger: 10-17 04:18:41] {2442} INFO -  at 3.9s,\testimator rf's best error=0.2784,\tbest estimator lgbm's best error=0.2251\n",
            "[flaml.automl.logger: 10-17 04:18:41] {2258} INFO - iteration 23, current learner lgbm\n",
            "[flaml.automl.logger: 10-17 04:18:41] {2442} INFO -  at 4.4s,\testimator lgbm's best error=0.2233,\tbest estimator lgbm's best error=0.2233\n",
            "[flaml.automl.logger: 10-17 04:18:41] {2258} INFO - iteration 24, current learner lgbm\n",
            "[flaml.automl.logger: 10-17 04:18:41] {2442} INFO -  at 4.6s,\testimator lgbm's best error=0.2154,\tbest estimator lgbm's best error=0.2154\n",
            "[flaml.automl.logger: 10-17 04:18:41] {2258} INFO - iteration 25, current learner xgboost\n",
            "[flaml.automl.logger: 10-17 04:18:41] {2442} INFO -  at 4.8s,\testimator xgboost's best error=0.2567,\tbest estimator lgbm's best error=0.2154\n",
            "[flaml.automl.logger: 10-17 04:18:41] {2258} INFO - iteration 26, current learner sgd\n",
            "[flaml.automl.logger: 10-17 04:18:42] {2442} INFO -  at 4.9s,\testimator sgd's best error=0.4378,\tbest estimator lgbm's best error=0.2154\n",
            "[flaml.automl.logger: 10-17 04:18:42] {2258} INFO - iteration 27, current learner lgbm\n",
            "[flaml.automl.logger: 10-17 04:18:42] {2442} INFO -  at 5.3s,\testimator lgbm's best error=0.2154,\tbest estimator lgbm's best error=0.2154\n",
            "[flaml.automl.logger: 10-17 04:18:42] {2258} INFO - iteration 28, current learner xgboost\n",
            "[flaml.automl.logger: 10-17 04:18:42] {2442} INFO -  at 5.5s,\testimator xgboost's best error=0.2567,\tbest estimator lgbm's best error=0.2154\n",
            "[flaml.automl.logger: 10-17 04:18:42] {2258} INFO - iteration 29, current learner xgboost\n",
            "[flaml.automl.logger: 10-17 04:18:42] {2442} INFO -  at 5.7s,\testimator xgboost's best error=0.2527,\tbest estimator lgbm's best error=0.2154\n",
            "[flaml.automl.logger: 10-17 04:18:42] {2258} INFO - iteration 30, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:18:43] {2442} INFO -  at 5.9s,\testimator extra_tree's best error=0.3659,\tbest estimator lgbm's best error=0.2154\n",
            "[flaml.automl.logger: 10-17 04:18:43] {2258} INFO - iteration 31, current learner lgbm\n",
            "[flaml.automl.logger: 10-17 04:18:43] {2442} INFO -  at 6.2s,\testimator lgbm's best error=0.2154,\tbest estimator lgbm's best error=0.2154\n",
            "[flaml.automl.logger: 10-17 04:18:43] {2258} INFO - iteration 32, current learner lgbm\n",
            "[flaml.automl.logger: 10-17 04:18:43] {2442} INFO -  at 6.7s,\testimator lgbm's best error=0.2154,\tbest estimator lgbm's best error=0.2154\n",
            "[flaml.automl.logger: 10-17 04:18:43] {2258} INFO - iteration 33, current learner lgbm\n",
            "[flaml.automl.logger: 10-17 04:18:44] {2442} INFO -  at 6.9s,\testimator lgbm's best error=0.2154,\tbest estimator lgbm's best error=0.2154\n",
            "[flaml.automl.logger: 10-17 04:18:44] {2258} INFO - iteration 34, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:18:44] {2442} INFO -  at 7.1s,\testimator extra_tree's best error=0.3659,\tbest estimator lgbm's best error=0.2154\n",
            "[flaml.automl.logger: 10-17 04:18:44] {2258} INFO - iteration 35, current learner lgbm\n",
            "[flaml.automl.logger: 10-17 04:18:45] {2442} INFO -  at 8.6s,\testimator lgbm's best error=0.2154,\tbest estimator lgbm's best error=0.2154\n",
            "[flaml.automl.logger: 10-17 04:18:45] {2258} INFO - iteration 36, current learner rf\n",
            "[flaml.automl.logger: 10-17 04:18:46] {2442} INFO -  at 8.9s,\testimator rf's best error=0.2757,\tbest estimator lgbm's best error=0.2154\n",
            "[flaml.automl.logger: 10-17 04:18:46] {2258} INFO - iteration 37, current learner sgd\n",
            "[flaml.automl.logger: 10-17 04:18:46] {2442} INFO -  at 9.0s,\testimator sgd's best error=0.4325,\tbest estimator lgbm's best error=0.2154\n",
            "[flaml.automl.logger: 10-17 04:18:46] {2258} INFO - iteration 38, current learner rf\n",
            "[flaml.automl.logger: 10-17 04:18:46] {2442} INFO -  at 9.3s,\testimator rf's best error=0.2757,\tbest estimator lgbm's best error=0.2154\n",
            "[flaml.automl.logger: 10-17 04:18:46] {2258} INFO - iteration 39, current learner xgboost\n",
            "[flaml.automl.logger: 10-17 04:18:46] {2442} INFO -  at 9.6s,\testimator xgboost's best error=0.2527,\tbest estimator lgbm's best error=0.2154\n",
            "[flaml.automl.logger: 10-17 04:18:46] {2258} INFO - iteration 40, current learner lgbm\n",
            "[flaml.automl.logger: 10-17 04:18:46] {2442} INFO -  at 9.7s,\testimator lgbm's best error=0.2154,\tbest estimator lgbm's best error=0.2154\n",
            "[flaml.automl.logger: 10-17 04:18:46] {2258} INFO - iteration 41, current learner xgboost\n",
            "[flaml.automl.logger: 10-17 04:18:47] {2442} INFO -  at 10.0s,\testimator xgboost's best error=0.2527,\tbest estimator lgbm's best error=0.2154\n",
            "[flaml.automl.logger: 10-17 04:18:47] {2258} INFO - iteration 42, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:18:47] {2442} INFO -  at 10.1s,\testimator extra_tree's best error=0.3419,\tbest estimator lgbm's best error=0.2154\n",
            "[flaml.automl.logger: 10-17 04:18:47] {2258} INFO - iteration 43, current learner lgbm\n",
            "[flaml.automl.logger: 10-17 04:18:47] {2442} INFO -  at 10.3s,\testimator lgbm's best error=0.2154,\tbest estimator lgbm's best error=0.2154\n",
            "[flaml.automl.logger: 10-17 04:18:47] {2258} INFO - iteration 44, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:18:47] {2442} INFO -  at 10.5s,\testimator extra_tree's best error=0.3384,\tbest estimator lgbm's best error=0.2154\n",
            "[flaml.automl.logger: 10-17 04:18:47] {2258} INFO - iteration 45, current learner sgd\n",
            "[flaml.automl.logger: 10-17 04:18:47] {2442} INFO -  at 10.7s,\testimator sgd's best error=0.4325,\tbest estimator lgbm's best error=0.2154\n",
            "[flaml.automl.logger: 10-17 04:18:47] {2258} INFO - iteration 46, current learner xgboost\n",
            "[flaml.automl.logger: 10-17 04:18:48] {2442} INFO -  at 11.0s,\testimator xgboost's best error=0.2389,\tbest estimator lgbm's best error=0.2154\n",
            "[flaml.automl.logger: 10-17 04:18:48] {2258} INFO - iteration 47, current learner lgbm\n",
            "[flaml.automl.logger: 10-17 04:18:48] {2442} INFO -  at 11.5s,\testimator lgbm's best error=0.2154,\tbest estimator lgbm's best error=0.2154\n",
            "[flaml.automl.logger: 10-17 04:18:48] {2258} INFO - iteration 48, current learner xgboost\n",
            "[flaml.automl.logger: 10-17 04:18:48] {2442} INFO -  at 11.7s,\testimator xgboost's best error=0.2389,\tbest estimator lgbm's best error=0.2154\n",
            "[flaml.automl.logger: 10-17 04:18:48] {2258} INFO - iteration 49, current learner lgbm\n",
            "[flaml.automl.logger: 10-17 04:18:49] {2442} INFO -  at 12.1s,\testimator lgbm's best error=0.2154,\tbest estimator lgbm's best error=0.2154\n",
            "[flaml.automl.logger: 10-17 04:18:49] {2258} INFO - iteration 50, current learner xgboost\n",
            "[flaml.automl.logger: 10-17 04:18:49] {2442} INFO -  at 12.3s,\testimator xgboost's best error=0.2389,\tbest estimator lgbm's best error=0.2154\n",
            "[flaml.automl.logger: 10-17 04:18:49] {2258} INFO - iteration 51, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:18:49] {2442} INFO -  at 12.5s,\testimator extra_tree's best error=0.3366,\tbest estimator lgbm's best error=0.2154\n",
            "[flaml.automl.logger: 10-17 04:18:49] {2258} INFO - iteration 52, current learner lgbm\n",
            "[flaml.automl.logger: 10-17 04:18:49] {2442} INFO -  at 12.7s,\testimator lgbm's best error=0.2154,\tbest estimator lgbm's best error=0.2154\n",
            "[flaml.automl.logger: 10-17 04:18:49] {2258} INFO - iteration 53, current learner lgbm\n",
            "[flaml.automl.logger: 10-17 04:18:50] {2442} INFO -  at 12.9s,\testimator lgbm's best error=0.2154,\tbest estimator lgbm's best error=0.2154\n",
            "[flaml.automl.logger: 10-17 04:18:50] {2258} INFO - iteration 54, current learner lgbm\n",
            "[flaml.automl.logger: 10-17 04:18:50] {2442} INFO -  at 13.2s,\testimator lgbm's best error=0.2154,\tbest estimator lgbm's best error=0.2154\n",
            "[flaml.automl.logger: 10-17 04:18:50] {2258} INFO - iteration 55, current learner lgbm\n",
            "[flaml.automl.logger: 10-17 04:18:51] {2442} INFO -  at 13.9s,\testimator lgbm's best error=0.2154,\tbest estimator lgbm's best error=0.2154\n",
            "[flaml.automl.logger: 10-17 04:18:51] {2258} INFO - iteration 56, current learner xgboost\n",
            "[flaml.automl.logger: 10-17 04:18:51] {2442} INFO -  at 14.3s,\testimator xgboost's best error=0.2353,\tbest estimator lgbm's best error=0.2154\n",
            "[flaml.automl.logger: 10-17 04:18:51] {2258} INFO - iteration 57, current learner lgbm\n",
            "[flaml.automl.logger: 10-17 04:18:51] {2442} INFO -  at 14.5s,\testimator lgbm's best error=0.2154,\tbest estimator lgbm's best error=0.2154\n",
            "[flaml.automl.logger: 10-17 04:18:51] {2258} INFO - iteration 58, current learner lgbm\n",
            "[flaml.automl.logger: 10-17 04:18:52] {2442} INFO -  at 14.9s,\testimator lgbm's best error=0.2154,\tbest estimator lgbm's best error=0.2154\n",
            "[flaml.automl.logger: 10-17 04:18:52] {2258} INFO - iteration 59, current learner rf\n",
            "[flaml.automl.logger: 10-17 04:18:52] {2442} INFO -  at 15.2s,\testimator rf's best error=0.2589,\tbest estimator lgbm's best error=0.2154\n",
            "[flaml.automl.logger: 10-17 04:18:52] {2258} INFO - iteration 60, current learner lgbm\n",
            "[flaml.automl.logger: 10-17 04:18:52] {2442} INFO -  at 15.4s,\testimator lgbm's best error=0.2154,\tbest estimator lgbm's best error=0.2154\n",
            "[flaml.automl.logger: 10-17 04:18:52] {2258} INFO - iteration 61, current learner rf\n",
            "[flaml.automl.logger: 10-17 04:18:52] {2442} INFO -  at 15.7s,\testimator rf's best error=0.2482,\tbest estimator lgbm's best error=0.2154\n",
            "[flaml.automl.logger: 10-17 04:18:52] {2258} INFO - iteration 62, current learner lgbm\n",
            "[flaml.automl.logger: 10-17 04:18:52] {2442} INFO -  at 15.8s,\testimator lgbm's best error=0.2154,\tbest estimator lgbm's best error=0.2154\n",
            "[flaml.automl.logger: 10-17 04:18:52] {2258} INFO - iteration 63, current learner rf\n",
            "[flaml.automl.logger: 10-17 04:18:53] {2442} INFO -  at 16.0s,\testimator rf's best error=0.2482,\tbest estimator lgbm's best error=0.2154\n",
            "[flaml.automl.logger: 10-17 04:18:53] {2258} INFO - iteration 64, current learner rf\n",
            "[flaml.automl.logger: 10-17 04:18:53] {2442} INFO -  at 16.3s,\testimator rf's best error=0.2482,\tbest estimator lgbm's best error=0.2154\n",
            "[flaml.automl.logger: 10-17 04:18:53] {2258} INFO - iteration 65, current learner lgbm\n",
            "[flaml.automl.logger: 10-17 04:18:54] {2442} INFO -  at 17.3s,\testimator lgbm's best error=0.2149,\tbest estimator lgbm's best error=0.2149\n",
            "[flaml.automl.logger: 10-17 04:18:54] {2258} INFO - iteration 66, current learner rf\n",
            "[flaml.automl.logger: 10-17 04:18:54] {2442} INFO -  at 17.6s,\testimator rf's best error=0.2376,\tbest estimator lgbm's best error=0.2149\n",
            "[flaml.automl.logger: 10-17 04:18:54] {2258} INFO - iteration 67, current learner xgboost\n",
            "[flaml.automl.logger: 10-17 04:18:55] {2442} INFO -  at 17.9s,\testimator xgboost's best error=0.2353,\tbest estimator lgbm's best error=0.2149\n",
            "[flaml.automl.logger: 10-17 04:18:55] {2258} INFO - iteration 68, current learner rf\n",
            "[flaml.automl.logger: 10-17 04:18:55] {2442} INFO -  at 18.2s,\testimator rf's best error=0.2376,\tbest estimator lgbm's best error=0.2149\n",
            "[flaml.automl.logger: 10-17 04:18:55] {2258} INFO - iteration 69, current learner lgbm\n",
            "[flaml.automl.logger: 10-17 04:18:55] {2442} INFO -  at 18.8s,\testimator lgbm's best error=0.2069,\tbest estimator lgbm's best error=0.2069\n",
            "[flaml.automl.logger: 10-17 04:18:55] {2258} INFO - iteration 70, current learner lgbm\n",
            "[flaml.automl.logger: 10-17 04:18:56] {2442} INFO -  at 19.7s,\testimator lgbm's best error=0.2069,\tbest estimator lgbm's best error=0.2069\n",
            "[flaml.automl.logger: 10-17 04:18:56] {2258} INFO - iteration 71, current learner lgbm\n",
            "[flaml.automl.logger: 10-17 04:18:58] {2442} INFO -  at 21.3s,\testimator lgbm's best error=0.2069,\tbest estimator lgbm's best error=0.2069\n",
            "[flaml.automl.logger: 10-17 04:18:58] {2258} INFO - iteration 72, current learner lgbm\n",
            "[flaml.automl.logger: 10-17 04:18:59] {2442} INFO -  at 22.5s,\testimator lgbm's best error=0.2069,\tbest estimator lgbm's best error=0.2069\n",
            "[flaml.automl.logger: 10-17 04:18:59] {2258} INFO - iteration 73, current learner sgd\n",
            "[flaml.automl.logger: 10-17 04:18:59] {2442} INFO -  at 22.8s,\testimator sgd's best error=0.4325,\tbest estimator lgbm's best error=0.2069\n",
            "[flaml.automl.logger: 10-17 04:18:59] {2258} INFO - iteration 74, current learner rf\n",
            "[flaml.automl.logger: 10-17 04:19:00] {2442} INFO -  at 23.3s,\testimator rf's best error=0.2251,\tbest estimator lgbm's best error=0.2069\n",
            "[flaml.automl.logger: 10-17 04:19:00] {2258} INFO - iteration 75, current learner xgboost\n",
            "[flaml.automl.logger: 10-17 04:19:00] {2442} INFO -  at 23.7s,\testimator xgboost's best error=0.2336,\tbest estimator lgbm's best error=0.2069\n",
            "[flaml.automl.logger: 10-17 04:19:00] {2258} INFO - iteration 76, current learner lgbm\n",
            "[flaml.automl.logger: 10-17 04:19:02] {2442} INFO -  at 25.3s,\testimator lgbm's best error=0.2069,\tbest estimator lgbm's best error=0.2069\n",
            "[flaml.automl.logger: 10-17 04:19:02] {2258} INFO - iteration 77, current learner lgbm\n",
            "[flaml.automl.logger: 10-17 04:19:03] {2442} INFO -  at 25.9s,\testimator lgbm's best error=0.2069,\tbest estimator lgbm's best error=0.2069\n",
            "[flaml.automl.logger: 10-17 04:19:03] {2258} INFO - iteration 78, current learner rf\n",
            "[flaml.automl.logger: 10-17 04:19:03] {2442} INFO -  at 26.2s,\testimator rf's best error=0.2251,\tbest estimator lgbm's best error=0.2069\n",
            "[flaml.automl.logger: 10-17 04:19:03] {2258} INFO - iteration 79, current learner rf\n",
            "[flaml.automl.logger: 10-17 04:19:04] {2442} INFO -  at 27.0s,\testimator rf's best error=0.2251,\tbest estimator lgbm's best error=0.2069\n",
            "[flaml.automl.logger: 10-17 04:19:04] {2258} INFO - iteration 80, current learner lgbm\n",
            "[flaml.automl.logger: 10-17 04:19:05] {2442} INFO -  at 28.1s,\testimator lgbm's best error=0.2069,\tbest estimator lgbm's best error=0.2069\n",
            "[flaml.automl.logger: 10-17 04:19:05] {2258} INFO - iteration 81, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:19:05] {2442} INFO -  at 28.4s,\testimator extra_tree's best error=0.2993,\tbest estimator lgbm's best error=0.2069\n",
            "[flaml.automl.logger: 10-17 04:19:05] {2258} INFO - iteration 82, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:19:05] {2442} INFO -  at 28.6s,\testimator extra_tree's best error=0.2993,\tbest estimator lgbm's best error=0.2069\n",
            "[flaml.automl.logger: 10-17 04:19:05] {2258} INFO - iteration 83, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:19:06] {2442} INFO -  at 28.9s,\testimator extra_tree's best error=0.2993,\tbest estimator lgbm's best error=0.2069\n",
            "[flaml.automl.logger: 10-17 04:19:06] {2258} INFO - iteration 84, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:19:06] {2442} INFO -  at 29.1s,\testimator extra_tree's best error=0.2789,\tbest estimator lgbm's best error=0.2069\n",
            "[flaml.automl.logger: 10-17 04:19:06] {2258} INFO - iteration 85, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:19:06] {2442} INFO -  at 29.3s,\testimator extra_tree's best error=0.2789,\tbest estimator lgbm's best error=0.2069\n",
            "[flaml.automl.logger: 10-17 04:19:06] {2258} INFO - iteration 86, current learner xgboost\n",
            "[flaml.automl.logger: 10-17 04:19:06] {2442} INFO -  at 29.6s,\testimator xgboost's best error=0.2336,\tbest estimator lgbm's best error=0.2069\n",
            "[flaml.automl.logger: 10-17 04:19:06] {2258} INFO - iteration 87, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:19:07] {2442} INFO -  at 29.9s,\testimator extra_tree's best error=0.2624,\tbest estimator lgbm's best error=0.2069\n",
            "[flaml.automl.logger: 10-17 04:19:07] {2258} INFO - iteration 88, current learner rf\n",
            "[flaml.automl.logger: 10-17 04:19:07] {2442} INFO -  at 30.3s,\testimator rf's best error=0.2251,\tbest estimator lgbm's best error=0.2069\n",
            "[flaml.automl.logger: 10-17 04:19:07] {2258} INFO - iteration 89, current learner rf\n",
            "[flaml.automl.logger: 10-17 04:19:07] {2442} INFO -  at 30.7s,\testimator rf's best error=0.2251,\tbest estimator lgbm's best error=0.2069\n",
            "[flaml.automl.logger: 10-17 04:19:07] {2258} INFO - iteration 90, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:19:08] {2442} INFO -  at 30.9s,\testimator extra_tree's best error=0.2624,\tbest estimator lgbm's best error=0.2069\n",
            "[flaml.automl.logger: 10-17 04:19:08] {2258} INFO - iteration 91, current learner rf\n",
            "[flaml.automl.logger: 10-17 04:19:08] {2442} INFO -  at 31.2s,\testimator rf's best error=0.2251,\tbest estimator lgbm's best error=0.2069\n",
            "[flaml.automl.logger: 10-17 04:19:08] {2258} INFO - iteration 92, current learner sgd\n",
            "[flaml.automl.logger: 10-17 04:19:08] {2442} INFO -  at 31.4s,\testimator sgd's best error=0.4325,\tbest estimator lgbm's best error=0.2069\n",
            "[flaml.automl.logger: 10-17 04:19:08] {2258} INFO - iteration 93, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:19:08] {2442} INFO -  at 31.8s,\testimator extra_tree's best error=0.2598,\tbest estimator lgbm's best error=0.2069\n",
            "[flaml.automl.logger: 10-17 04:19:08] {2258} INFO - iteration 94, current learner rf\n",
            "[flaml.automl.logger: 10-17 04:19:09] {2442} INFO -  at 32.4s,\testimator rf's best error=0.2247,\tbest estimator lgbm's best error=0.2069\n",
            "[flaml.automl.logger: 10-17 04:19:09] {2258} INFO - iteration 95, current learner lgbm\n",
            "[flaml.automl.logger: 10-17 04:19:09] {2442} INFO -  at 32.8s,\testimator lgbm's best error=0.2069,\tbest estimator lgbm's best error=0.2069\n",
            "[flaml.automl.logger: 10-17 04:19:09] {2258} INFO - iteration 96, current learner sgd\n",
            "[flaml.automl.logger: 10-17 04:19:10] {2442} INFO -  at 32.9s,\testimator sgd's best error=0.4325,\tbest estimator lgbm's best error=0.2069\n",
            "[flaml.automl.logger: 10-17 04:19:10] {2258} INFO - iteration 97, current learner lgbm\n",
            "[flaml.automl.logger: 10-17 04:19:13] {2442} INFO -  at 36.2s,\testimator lgbm's best error=0.2069,\tbest estimator lgbm's best error=0.2069\n",
            "[flaml.automl.logger: 10-17 04:19:13] {2258} INFO - iteration 98, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-17 04:19:13] {2442} INFO -  at 36.6s,\testimator xgb_limitdepth's best error=0.2273,\tbest estimator lgbm's best error=0.2069\n",
            "[flaml.automl.logger: 10-17 04:19:13] {2258} INFO - iteration 99, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-17 04:19:14] {2442} INFO -  at 36.9s,\testimator xgb_limitdepth's best error=0.2273,\tbest estimator lgbm's best error=0.2069\n",
            "[flaml.automl.logger: 10-17 04:19:14] {2258} INFO - iteration 100, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-17 04:19:14] {2442} INFO -  at 37.4s,\testimator xgb_limitdepth's best error=0.2273,\tbest estimator lgbm's best error=0.2069\n",
            "[flaml.automl.logger: 10-17 04:19:14] {2258} INFO - iteration 101, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-17 04:19:14] {2442} INFO -  at 37.7s,\testimator xgb_limitdepth's best error=0.2273,\tbest estimator lgbm's best error=0.2069\n",
            "[flaml.automl.logger: 10-17 04:19:14] {2258} INFO - iteration 102, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-17 04:19:15] {2442} INFO -  at 38.4s,\testimator xgb_limitdepth's best error=0.2273,\tbest estimator lgbm's best error=0.2069\n",
            "[flaml.automl.logger: 10-17 04:19:15] {2258} INFO - iteration 103, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-17 04:19:15] {2442} INFO -  at 38.6s,\testimator xgb_limitdepth's best error=0.2273,\tbest estimator lgbm's best error=0.2069\n",
            "[flaml.automl.logger: 10-17 04:19:15] {2258} INFO - iteration 104, current learner lgbm\n",
            "[flaml.automl.logger: 10-17 04:19:15] {2442} INFO -  at 38.8s,\testimator lgbm's best error=0.2069,\tbest estimator lgbm's best error=0.2069\n",
            "[flaml.automl.logger: 10-17 04:19:15] {2258} INFO - iteration 105, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-17 04:19:16] {2442} INFO -  at 39.3s,\testimator xgb_limitdepth's best error=0.2273,\tbest estimator lgbm's best error=0.2069\n",
            "[flaml.automl.logger: 10-17 04:19:16] {2258} INFO - iteration 106, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-17 04:19:16] {2442} INFO -  at 39.7s,\testimator xgb_limitdepth's best error=0.2273,\tbest estimator lgbm's best error=0.2069\n",
            "[flaml.automl.logger: 10-17 04:19:16] {2258} INFO - iteration 107, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-17 04:19:17] {2442} INFO -  at 40.1s,\testimator xgb_limitdepth's best error=0.2273,\tbest estimator lgbm's best error=0.2069\n",
            "[flaml.automl.logger: 10-17 04:19:17] {2258} INFO - iteration 108, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-17 04:19:17] {2442} INFO -  at 40.7s,\testimator xgb_limitdepth's best error=0.2273,\tbest estimator lgbm's best error=0.2069\n",
            "[flaml.automl.logger: 10-17 04:19:17] {2258} INFO - iteration 109, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:19:18] {2442} INFO -  at 41.1s,\testimator extra_tree's best error=0.2300,\tbest estimator lgbm's best error=0.2069\n",
            "[flaml.automl.logger: 10-17 04:19:18] {2258} INFO - iteration 110, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-17 04:19:18] {2442} INFO -  at 41.5s,\testimator xgb_limitdepth's best error=0.2273,\tbest estimator lgbm's best error=0.2069\n",
            "[flaml.automl.logger: 10-17 04:19:18] {2258} INFO - iteration 111, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:19:19] {2442} INFO -  at 41.9s,\testimator extra_tree's best error=0.2300,\tbest estimator lgbm's best error=0.2069\n",
            "[flaml.automl.logger: 10-17 04:19:19] {2258} INFO - iteration 112, current learner lgbm\n",
            "[flaml.automl.logger: 10-17 04:19:19] {2442} INFO -  at 42.1s,\testimator lgbm's best error=0.2069,\tbest estimator lgbm's best error=0.2069\n",
            "[flaml.automl.logger: 10-17 04:19:19] {2258} INFO - iteration 113, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-17 04:19:19] {2442} INFO -  at 42.4s,\testimator xgb_limitdepth's best error=0.2273,\tbest estimator lgbm's best error=0.2069\n",
            "[flaml.automl.logger: 10-17 04:19:19] {2258} INFO - iteration 114, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:19:19] {2442} INFO -  at 42.7s,\testimator extra_tree's best error=0.2300,\tbest estimator lgbm's best error=0.2069\n",
            "[flaml.automl.logger: 10-17 04:19:19] {2258} INFO - iteration 115, current learner sgd\n",
            "[flaml.automl.logger: 10-17 04:19:20] {2442} INFO -  at 42.9s,\testimator sgd's best error=0.4325,\tbest estimator lgbm's best error=0.2069\n",
            "[flaml.automl.logger: 10-17 04:19:20] {2258} INFO - iteration 116, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:19:20] {2442} INFO -  at 43.6s,\testimator extra_tree's best error=0.2300,\tbest estimator lgbm's best error=0.2069\n",
            "[flaml.automl.logger: 10-17 04:19:20] {2258} INFO - iteration 117, current learner xgboost\n",
            "[flaml.automl.logger: 10-17 04:19:21] {2442} INFO -  at 44.2s,\testimator xgboost's best error=0.2278,\tbest estimator lgbm's best error=0.2069\n",
            "[flaml.automl.logger: 10-17 04:19:21] {2258} INFO - iteration 118, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-17 04:19:21] {2442} INFO -  at 44.6s,\testimator xgb_limitdepth's best error=0.2273,\tbest estimator lgbm's best error=0.2069\n",
            "[flaml.automl.logger: 10-17 04:19:21] {2258} INFO - iteration 119, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:19:22] {2442} INFO -  at 45.0s,\testimator extra_tree's best error=0.2176,\tbest estimator lgbm's best error=0.2069\n",
            "[flaml.automl.logger: 10-17 04:19:22] {2258} INFO - iteration 120, current learner lgbm\n",
            "[flaml.automl.logger: 10-17 04:19:26] {2442} INFO -  at 49.5s,\testimator lgbm's best error=0.2069,\tbest estimator lgbm's best error=0.2069\n",
            "[flaml.automl.logger: 10-17 04:19:26] {2258} INFO - iteration 121, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-17 04:19:27] {2442} INFO -  at 49.9s,\testimator xgb_limitdepth's best error=0.2273,\tbest estimator lgbm's best error=0.2069\n",
            "[flaml.automl.logger: 10-17 04:19:27] {2258} INFO - iteration 122, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-17 04:19:27] {2442} INFO -  at 50.4s,\testimator xgb_limitdepth's best error=0.2273,\tbest estimator lgbm's best error=0.2069\n",
            "[flaml.automl.logger: 10-17 04:19:27] {2258} INFO - iteration 123, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-17 04:19:27] {2442} INFO -  at 50.6s,\testimator xgb_limitdepth's best error=0.2273,\tbest estimator lgbm's best error=0.2069\n",
            "[flaml.automl.logger: 10-17 04:19:27] {2258} INFO - iteration 124, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:19:28] {2442} INFO -  at 51.0s,\testimator extra_tree's best error=0.2176,\tbest estimator lgbm's best error=0.2069\n",
            "[flaml.automl.logger: 10-17 04:19:28] {2258} INFO - iteration 125, current learner xgboost\n",
            "[flaml.automl.logger: 10-17 04:19:28] {2442} INFO -  at 51.3s,\testimator xgboost's best error=0.2278,\tbest estimator lgbm's best error=0.2069\n",
            "[flaml.automl.logger: 10-17 04:19:28] {2258} INFO - iteration 126, current learner lgbm\n",
            "[flaml.automl.logger: 10-17 04:19:29] {2442} INFO -  at 52.2s,\testimator lgbm's best error=0.2069,\tbest estimator lgbm's best error=0.2069\n",
            "[flaml.automl.logger: 10-17 04:19:29] {2258} INFO - iteration 127, current learner lgbm\n",
            "[flaml.automl.logger: 10-17 04:19:29] {2442} INFO -  at 52.5s,\testimator lgbm's best error=0.2069,\tbest estimator lgbm's best error=0.2069\n",
            "[flaml.automl.logger: 10-17 04:19:29] {2258} INFO - iteration 128, current learner lgbm\n",
            "[flaml.automl.logger: 10-17 04:19:29] {2442} INFO -  at 52.7s,\testimator lgbm's best error=0.2069,\tbest estimator lgbm's best error=0.2069\n",
            "[flaml.automl.logger: 10-17 04:19:29] {2258} INFO - iteration 129, current learner xgboost\n",
            "[flaml.automl.logger: 10-17 04:19:31] {2442} INFO -  at 53.9s,\testimator xgboost's best error=0.2278,\tbest estimator lgbm's best error=0.2069\n",
            "[flaml.automl.logger: 10-17 04:19:31] {2258} INFO - iteration 130, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-17 04:19:31] {2442} INFO -  at 54.6s,\testimator xgb_limitdepth's best error=0.2273,\tbest estimator lgbm's best error=0.2069\n",
            "[flaml.automl.logger: 10-17 04:19:31] {2258} INFO - iteration 131, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:19:32] {2442} INFO -  at 55.1s,\testimator extra_tree's best error=0.2176,\tbest estimator lgbm's best error=0.2069\n",
            "[flaml.automl.logger: 10-17 04:19:32] {2258} INFO - iteration 132, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:19:32] {2442} INFO -  at 55.4s,\testimator extra_tree's best error=0.2176,\tbest estimator lgbm's best error=0.2069\n",
            "[flaml.automl.logger: 10-17 04:19:32] {2258} INFO - iteration 133, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-17 04:19:32] {2442} INFO -  at 55.7s,\testimator xgb_limitdepth's best error=0.2273,\tbest estimator lgbm's best error=0.2069\n",
            "[flaml.automl.logger: 10-17 04:19:32] {2258} INFO - iteration 134, current learner lgbm\n",
            "[flaml.automl.logger: 10-17 04:19:33] {2442} INFO -  at 56.8s,\testimator lgbm's best error=0.2069,\tbest estimator lgbm's best error=0.2069\n",
            "[flaml.automl.logger: 10-17 04:19:34] {2258} INFO - iteration 135, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:19:34] {2442} INFO -  at 57.5s,\testimator extra_tree's best error=0.2176,\tbest estimator lgbm's best error=0.2069\n",
            "[flaml.automl.logger: 10-17 04:19:34] {2258} INFO - iteration 136, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:19:34] {2442} INFO -  at 57.8s,\testimator extra_tree's best error=0.2176,\tbest estimator lgbm's best error=0.2069\n",
            "[flaml.automl.logger: 10-17 04:19:34] {2258} INFO - iteration 137, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-17 04:19:35] {2442} INFO -  at 58.5s,\testimator xgb_limitdepth's best error=0.2273,\tbest estimator lgbm's best error=0.2069\n",
            "[flaml.automl.logger: 10-17 04:19:35] {2258} INFO - iteration 138, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:19:36] {2442} INFO -  at 58.9s,\testimator extra_tree's best error=0.2176,\tbest estimator lgbm's best error=0.2069\n",
            "[flaml.automl.logger: 10-17 04:19:36] {2258} INFO - iteration 139, current learner lgbm\n",
            "[flaml.automl.logger: 10-17 04:19:36] {2442} INFO -  at 59.1s,\testimator lgbm's best error=0.2069,\tbest estimator lgbm's best error=0.2069\n",
            "[flaml.automl.logger: 10-17 04:19:36] {2258} INFO - iteration 140, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-17 04:19:36] {2442} INFO -  at 59.3s,\testimator xgb_limitdepth's best error=0.2273,\tbest estimator lgbm's best error=0.2069\n",
            "[flaml.automl.logger: 10-17 04:19:36] {2258} INFO - iteration 141, current learner xgboost\n",
            "[flaml.automl.logger: 10-17 04:19:36] {2442} INFO -  at 59.6s,\testimator xgboost's best error=0.2278,\tbest estimator lgbm's best error=0.2069\n",
            "[flaml.automl.logger: 10-17 04:19:36] {2258} INFO - iteration 142, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-17 04:19:37] {2442} INFO -  at 60.6s,\testimator xgb_limitdepth's best error=0.2189,\tbest estimator lgbm's best error=0.2069\n",
            "[flaml.automl.logger: 10-17 04:19:37] {2258} INFO - iteration 143, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:19:38] {2442} INFO -  at 60.9s,\testimator extra_tree's best error=0.2176,\tbest estimator lgbm's best error=0.2069\n",
            "[flaml.automl.logger: 10-17 04:19:38] {2258} INFO - iteration 144, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-17 04:19:38] {2442} INFO -  at 61.6s,\testimator xgb_limitdepth's best error=0.2189,\tbest estimator lgbm's best error=0.2069\n",
            "[flaml.automl.logger: 10-17 04:19:38] {2258} INFO - iteration 145, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:19:39] {2442} INFO -  at 62.1s,\testimator extra_tree's best error=0.2176,\tbest estimator lgbm's best error=0.2069\n",
            "[flaml.automl.logger: 10-17 04:19:39] {2258} INFO - iteration 146, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:19:39] {2442} INFO -  at 62.4s,\testimator extra_tree's best error=0.2176,\tbest estimator lgbm's best error=0.2069\n",
            "[flaml.automl.logger: 10-17 04:19:39] {2258} INFO - iteration 147, current learner lgbm\n",
            "[flaml.automl.logger: 10-17 04:19:41] {2442} INFO -  at 64.5s,\testimator lgbm's best error=0.2069,\tbest estimator lgbm's best error=0.2069\n",
            "[flaml.automl.logger: 10-17 04:19:41] {2258} INFO - iteration 148, current learner lgbm\n",
            "[flaml.automl.logger: 10-17 04:19:41] {2442} INFO -  at 64.6s,\testimator lgbm's best error=0.2069,\tbest estimator lgbm's best error=0.2069\n",
            "[flaml.automl.logger: 10-17 04:19:41] {2258} INFO - iteration 149, current learner lgbm\n",
            "[flaml.automl.logger: 10-17 04:19:43] {2442} INFO -  at 66.6s,\testimator lgbm's best error=0.2069,\tbest estimator lgbm's best error=0.2069\n",
            "[flaml.automl.logger: 10-17 04:19:43] {2258} INFO - iteration 150, current learner lgbm\n",
            "[flaml.automl.logger: 10-17 04:19:45] {2442} INFO -  at 68.7s,\testimator lgbm's best error=0.2069,\tbest estimator lgbm's best error=0.2069\n",
            "[flaml.automl.logger: 10-17 04:19:45] {2258} INFO - iteration 151, current learner lgbm\n",
            "[flaml.automl.logger: 10-17 04:19:46] {2442} INFO -  at 69.0s,\testimator lgbm's best error=0.2069,\tbest estimator lgbm's best error=0.2069\n",
            "[flaml.automl.logger: 10-17 04:19:46] {2258} INFO - iteration 152, current learner xgboost\n",
            "[flaml.automl.logger: 10-17 04:19:48] {2442} INFO -  at 71.1s,\testimator xgboost's best error=0.2065,\tbest estimator xgboost's best error=0.2065\n",
            "[flaml.automl.logger: 10-17 04:19:48] {2258} INFO - iteration 153, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:19:48] {2442} INFO -  at 71.5s,\testimator extra_tree's best error=0.2176,\tbest estimator xgboost's best error=0.2065\n",
            "[flaml.automl.logger: 10-17 04:19:48] {2258} INFO - iteration 154, current learner xgboost\n",
            "[flaml.automl.logger: 10-17 04:19:49] {2442} INFO -  at 72.7s,\testimator xgboost's best error=0.2065,\tbest estimator xgboost's best error=0.2065\n",
            "[flaml.automl.logger: 10-17 04:19:49] {2258} INFO - iteration 155, current learner lgbm\n",
            "[flaml.automl.logger: 10-17 04:19:51] {2442} INFO -  at 74.4s,\testimator lgbm's best error=0.2069,\tbest estimator xgboost's best error=0.2065\n",
            "[flaml.automl.logger: 10-17 04:19:51] {2258} INFO - iteration 156, current learner lgbm\n",
            "[flaml.automl.logger: 10-17 04:19:51] {2442} INFO -  at 74.6s,\testimator lgbm's best error=0.2069,\tbest estimator xgboost's best error=0.2065\n",
            "[flaml.automl.logger: 10-17 04:19:51] {2258} INFO - iteration 157, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-17 04:19:52] {2442} INFO -  at 75.7s,\testimator xgb_limitdepth's best error=0.2189,\tbest estimator xgboost's best error=0.2065\n",
            "[flaml.automl.logger: 10-17 04:19:52] {2258} INFO - iteration 158, current learner xgboost\n",
            "[flaml.automl.logger: 10-17 04:19:56] {2442} INFO -  at 79.1s,\testimator xgboost's best error=0.2065,\tbest estimator xgboost's best error=0.2065\n",
            "[flaml.automl.logger: 10-17 04:19:56] {2258} INFO - iteration 159, current learner xgboost\n",
            "[flaml.automl.logger: 10-17 04:19:59] {2442} INFO -  at 82.2s,\testimator xgboost's best error=0.2065,\tbest estimator xgboost's best error=0.2065\n",
            "[flaml.automl.logger: 10-17 04:19:59] {2258} INFO - iteration 160, current learner xgboost\n",
            "[flaml.automl.logger: 10-17 04:20:00] {2442} INFO -  at 83.7s,\testimator xgboost's best error=0.2047,\tbest estimator xgboost's best error=0.2047\n",
            "[flaml.automl.logger: 10-17 04:20:00] {2258} INFO - iteration 161, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:20:01] {2442} INFO -  at 84.1s,\testimator extra_tree's best error=0.2176,\tbest estimator xgboost's best error=0.2047\n",
            "[flaml.automl.logger: 10-17 04:20:01] {2258} INFO - iteration 162, current learner xgboost\n",
            "[flaml.automl.logger: 10-17 04:20:01] {2442} INFO -  at 84.7s,\testimator xgboost's best error=0.2047,\tbest estimator xgboost's best error=0.2047\n",
            "[flaml.automl.logger: 10-17 04:20:01] {2258} INFO - iteration 163, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:20:02] {2442} INFO -  at 85.2s,\testimator extra_tree's best error=0.2176,\tbest estimator xgboost's best error=0.2047\n",
            "[flaml.automl.logger: 10-17 04:20:02] {2258} INFO - iteration 164, current learner sgd\n",
            "[flaml.automl.logger: 10-17 04:20:02] {2442} INFO -  at 85.4s,\testimator sgd's best error=0.4325,\tbest estimator xgboost's best error=0.2047\n",
            "[flaml.automl.logger: 10-17 04:20:02] {2258} INFO - iteration 165, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:20:02] {2442} INFO -  at 85.8s,\testimator extra_tree's best error=0.2176,\tbest estimator xgboost's best error=0.2047\n",
            "[flaml.automl.logger: 10-17 04:20:02] {2258} INFO - iteration 166, current learner xgboost\n",
            "[flaml.automl.logger: 10-17 04:20:05] {2442} INFO -  at 88.4s,\testimator xgboost's best error=0.2047,\tbest estimator xgboost's best error=0.2047\n",
            "[flaml.automl.logger: 10-17 04:20:05] {2258} INFO - iteration 167, current learner xgboost\n",
            "[flaml.automl.logger: 10-17 04:20:06] {2442} INFO -  at 89.4s,\testimator xgboost's best error=0.2047,\tbest estimator xgboost's best error=0.2047\n",
            "[flaml.automl.logger: 10-17 04:20:06] {2258} INFO - iteration 168, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:20:06] {2442} INFO -  at 89.8s,\testimator extra_tree's best error=0.2176,\tbest estimator xgboost's best error=0.2047\n",
            "[flaml.automl.logger: 10-17 04:20:06] {2258} INFO - iteration 169, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:20:07] {2442} INFO -  at 90.2s,\testimator extra_tree's best error=0.2171,\tbest estimator xgboost's best error=0.2047\n",
            "[flaml.automl.logger: 10-17 04:20:07] {2258} INFO - iteration 170, current learner lgbm\n",
            "[flaml.automl.logger: 10-17 04:20:07] {2442} INFO -  at 90.7s,\testimator lgbm's best error=0.2069,\tbest estimator xgboost's best error=0.2047\n",
            "[flaml.automl.logger: 10-17 04:20:07] {2258} INFO - iteration 171, current learner lgbm\n",
            "[flaml.automl.logger: 10-17 04:20:08] {2442} INFO -  at 91.4s,\testimator lgbm's best error=0.2069,\tbest estimator xgboost's best error=0.2047\n",
            "[flaml.automl.logger: 10-17 04:20:08] {2258} INFO - iteration 172, current learner lgbm\n",
            "[flaml.automl.logger: 10-17 04:20:09] {2442} INFO -  at 91.9s,\testimator lgbm's best error=0.2069,\tbest estimator xgboost's best error=0.2047\n",
            "[flaml.automl.logger: 10-17 04:20:09] {2258} INFO - iteration 173, current learner xgboost\n",
            "[flaml.automl.logger: 10-17 04:20:10] {2442} INFO -  at 93.1s,\testimator xgboost's best error=0.2047,\tbest estimator xgboost's best error=0.2047\n",
            "[flaml.automl.logger: 10-17 04:20:10] {2258} INFO - iteration 174, current learner xgboost\n",
            "[flaml.automl.logger: 10-17 04:20:10] {2442} INFO -  at 93.7s,\testimator xgboost's best error=0.2047,\tbest estimator xgboost's best error=0.2047\n",
            "[flaml.automl.logger: 10-17 04:20:10] {2258} INFO - iteration 175, current learner xgboost\n",
            "[flaml.automl.logger: 10-17 04:20:14] {2442} INFO -  at 97.7s,\testimator xgboost's best error=0.2047,\tbest estimator xgboost's best error=0.2047\n",
            "[flaml.automl.logger: 10-17 04:20:14] {2258} INFO - iteration 176, current learner xgboost\n",
            "[flaml.automl.logger: 10-17 04:20:16] {2442} INFO -  at 99.1s,\testimator xgboost's best error=0.2047,\tbest estimator xgboost's best error=0.2047\n",
            "[flaml.automl.logger: 10-17 04:20:16] {2258} INFO - iteration 177, current learner sgd\n",
            "[flaml.automl.logger: 10-17 04:20:16] {2442} INFO -  at 99.2s,\testimator sgd's best error=0.4325,\tbest estimator xgboost's best error=0.2047\n",
            "[flaml.automl.logger: 10-17 04:20:16] {2258} INFO - iteration 178, current learner xgboost\n",
            "[flaml.automl.logger: 10-17 04:20:17] {2442} INFO -  at 100.6s,\testimator xgboost's best error=0.2047,\tbest estimator xgboost's best error=0.2047\n",
            "[flaml.automl.logger: 10-17 04:20:17] {2258} INFO - iteration 179, current learner xgboost\n",
            "[flaml.automl.logger: 10-17 04:20:19] {2442} INFO -  at 102.3s,\testimator xgboost's best error=0.2047,\tbest estimator xgboost's best error=0.2047\n",
            "[flaml.automl.logger: 10-17 04:20:19] {2258} INFO - iteration 180, current learner xgboost\n",
            "[flaml.automl.logger: 10-17 04:20:20] {2442} INFO -  at 103.5s,\testimator xgboost's best error=0.2047,\tbest estimator xgboost's best error=0.2047\n",
            "[flaml.automl.logger: 10-17 04:20:20] {2258} INFO - iteration 181, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:20:21] {2442} INFO -  at 104.7s,\testimator extra_tree's best error=0.2171,\tbest estimator xgboost's best error=0.2047\n",
            "[flaml.automl.logger: 10-17 04:20:21] {2258} INFO - iteration 182, current learner xgboost\n",
            "[flaml.automl.logger: 10-17 04:20:24] {2442} INFO -  at 107.2s,\testimator xgboost's best error=0.2047,\tbest estimator xgboost's best error=0.2047\n",
            "[flaml.automl.logger: 10-17 04:20:24] {2258} INFO - iteration 183, current learner lgbm\n",
            "[flaml.automl.logger: 10-17 04:20:25] {2442} INFO -  at 107.9s,\testimator lgbm's best error=0.2069,\tbest estimator xgboost's best error=0.2047\n",
            "[flaml.automl.logger: 10-17 04:20:25] {2258} INFO - iteration 184, current learner lgbm\n",
            "[flaml.automl.logger: 10-17 04:20:25] {2442} INFO -  at 108.2s,\testimator lgbm's best error=0.2069,\tbest estimator xgboost's best error=0.2047\n",
            "[flaml.automl.logger: 10-17 04:20:25] {2258} INFO - iteration 185, current learner xgboost\n",
            "[flaml.automl.logger: 10-17 04:20:25] {2442} INFO -  at 108.8s,\testimator xgboost's best error=0.2047,\tbest estimator xgboost's best error=0.2047\n",
            "[flaml.automl.logger: 10-17 04:20:25] {2258} INFO - iteration 186, current learner xgboost\n",
            "[flaml.automl.logger: 10-17 04:20:28] {2442} INFO -  at 111.1s,\testimator xgboost's best error=0.2047,\tbest estimator xgboost's best error=0.2047\n",
            "[flaml.automl.logger: 10-17 04:20:28] {2258} INFO - iteration 187, current learner lrl1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:flaml.tune.searcher.blendsearch:No low-cost partial config given to the search algorithm. For cost-frugal search, consider providing low-cost values for cost-related hps via 'low_cost_partial_config'. More info can be found at https://microsoft.github.io/FLAML/docs/FAQ#about-low_cost_partial_config-in-tune\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[flaml.automl.logger: 10-17 04:20:29] {2442} INFO -  at 112.0s,\testimator lrl1's best error=0.3543,\tbest estimator xgboost's best error=0.2047\n",
            "[flaml.automl.logger: 10-17 04:20:29] {2258} INFO - iteration 188, current learner lrl1\n",
            "[flaml.automl.logger: 10-17 04:20:29] {2442} INFO -  at 112.4s,\testimator lrl1's best error=0.3543,\tbest estimator xgboost's best error=0.2047\n",
            "[flaml.automl.logger: 10-17 04:20:29] {2258} INFO - iteration 189, current learner lrl1\n",
            "[flaml.automl.logger: 10-17 04:20:30] {2442} INFO -  at 113.4s,\testimator lrl1's best error=0.3543,\tbest estimator xgboost's best error=0.2047\n",
            "[flaml.automl.logger: 10-17 04:20:30] {2258} INFO - iteration 190, current learner xgboost\n",
            "[flaml.automl.logger: 10-17 04:20:31] {2442} INFO -  at 114.6s,\testimator xgboost's best error=0.2047,\tbest estimator xgboost's best error=0.2047\n",
            "[flaml.automl.logger: 10-17 04:20:31] {2258} INFO - iteration 191, current learner lrl1\n",
            "[flaml.automl.logger: 10-17 04:20:32] {2442} INFO -  at 115.5s,\testimator lrl1's best error=0.3526,\tbest estimator xgboost's best error=0.2047\n",
            "[flaml.automl.logger: 10-17 04:20:32] {2258} INFO - iteration 192, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-17 04:20:33] {2442} INFO -  at 116.5s,\testimator xgb_limitdepth's best error=0.2189,\tbest estimator xgboost's best error=0.2047\n",
            "[flaml.automl.logger: 10-17 04:20:33] {2258} INFO - iteration 193, current learner lgbm\n",
            "[flaml.automl.logger: 10-17 04:20:34] {2442} INFO -  at 117.3s,\testimator lgbm's best error=0.2069,\tbest estimator xgboost's best error=0.2047\n",
            "[flaml.automl.logger: 10-17 04:20:34] {2258} INFO - iteration 194, current learner xgboost\n",
            "[flaml.automl.logger: 10-17 04:20:36] {2442} INFO -  at 119.4s,\testimator xgboost's best error=0.2047,\tbest estimator xgboost's best error=0.2047\n",
            "[flaml.automl.logger: 10-17 04:20:36] {2258} INFO - iteration 195, current learner xgboost\n",
            "[flaml.automl.logger: 10-17 04:20:37] {2442} INFO -  at 120.2s,\testimator xgboost's best error=0.2047,\tbest estimator xgboost's best error=0.2047\n",
            "[flaml.automl.logger: 10-17 04:20:37] {2258} INFO - iteration 196, current learner sgd\n",
            "[flaml.automl.logger: 10-17 04:20:37] {2442} INFO -  at 120.3s,\testimator sgd's best error=0.4325,\tbest estimator xgboost's best error=0.2047\n",
            "[flaml.automl.logger: 10-17 04:20:37] {2258} INFO - iteration 197, current learner lgbm\n",
            "[flaml.automl.logger: 10-17 04:20:39] {2442} INFO -  at 122.0s,\testimator lgbm's best error=0.2069,\tbest estimator xgboost's best error=0.2047\n",
            "[flaml.automl.logger: 10-17 04:20:39] {2258} INFO - iteration 198, current learner lgbm\n",
            "[flaml.automl.logger: 10-17 04:20:39] {2442} INFO -  at 122.2s,\testimator lgbm's best error=0.2069,\tbest estimator xgboost's best error=0.2047\n",
            "[flaml.automl.logger: 10-17 04:20:39] {2258} INFO - iteration 199, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-17 04:20:40] {2442} INFO -  at 123.0s,\testimator xgb_limitdepth's best error=0.2189,\tbest estimator xgboost's best error=0.2047\n",
            "[flaml.automl.logger: 10-17 04:20:40] {2258} INFO - iteration 200, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-17 04:20:40] {2442} INFO -  at 123.4s,\testimator xgb_limitdepth's best error=0.2189,\tbest estimator xgboost's best error=0.2047\n",
            "[flaml.automl.logger: 10-17 04:20:40] {2258} INFO - iteration 201, current learner sgd\n",
            "[flaml.automl.logger: 10-17 04:20:40] {2442} INFO -  at 123.5s,\testimator sgd's best error=0.4325,\tbest estimator xgboost's best error=0.2047\n",
            "[flaml.automl.logger: 10-17 04:20:40] {2258} INFO - iteration 202, current learner sgd\n",
            "[flaml.automl.logger: 10-17 04:20:40] {2442} INFO -  at 123.6s,\testimator sgd's best error=0.4294,\tbest estimator xgboost's best error=0.2047\n",
            "[flaml.automl.logger: 10-17 04:20:40] {2258} INFO - iteration 203, current learner lgbm\n",
            "[flaml.automl.logger: 10-17 04:20:42] {2442} INFO -  at 125.3s,\testimator lgbm's best error=0.2069,\tbest estimator xgboost's best error=0.2047\n",
            "[flaml.automl.logger: 10-17 04:20:42] {2258} INFO - iteration 204, current learner lgbm\n",
            "[flaml.automl.logger: 10-17 04:20:42] {2442} INFO -  at 125.5s,\testimator lgbm's best error=0.2069,\tbest estimator xgboost's best error=0.2047\n",
            "[flaml.automl.logger: 10-17 04:20:42] {2258} INFO - iteration 205, current learner xgboost\n",
            "[flaml.automl.logger: 10-17 04:20:43] {2442} INFO -  at 126.3s,\testimator xgboost's best error=0.2047,\tbest estimator xgboost's best error=0.2047\n",
            "[flaml.automl.logger: 10-17 04:20:43] {2258} INFO - iteration 206, current learner sgd\n",
            "[flaml.automl.logger: 10-17 04:20:43] {2442} INFO -  at 126.4s,\testimator sgd's best error=0.4294,\tbest estimator xgboost's best error=0.2047\n",
            "[flaml.automl.logger: 10-17 04:20:43] {2258} INFO - iteration 207, current learner sgd\n",
            "[flaml.automl.logger: 10-17 04:20:43] {2442} INFO -  at 126.6s,\testimator sgd's best error=0.4294,\tbest estimator xgboost's best error=0.2047\n",
            "[flaml.automl.logger: 10-17 04:20:43] {2258} INFO - iteration 208, current learner xgboost\n",
            "[flaml.automl.logger: 10-17 04:20:47] {2442} INFO -  at 129.9s,\testimator xgboost's best error=0.2047,\tbest estimator xgboost's best error=0.2047\n",
            "[flaml.automl.logger: 10-17 04:20:47] {2258} INFO - iteration 209, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-17 04:20:48] {2442} INFO -  at 131.5s,\testimator xgb_limitdepth's best error=0.2189,\tbest estimator xgboost's best error=0.2047\n",
            "[flaml.automl.logger: 10-17 04:20:48] {2258} INFO - iteration 210, current learner xgboost\n",
            "[flaml.automl.logger: 10-17 04:20:50] {2442} INFO -  at 132.9s,\testimator xgboost's best error=0.2047,\tbest estimator xgboost's best error=0.2047\n",
            "[flaml.automl.logger: 10-17 04:20:50] {2258} INFO - iteration 211, current learner xgboost\n",
            "[flaml.automl.logger: 10-17 04:20:51] {2442} INFO -  at 134.0s,\testimator xgboost's best error=0.2047,\tbest estimator xgboost's best error=0.2047\n",
            "[flaml.automl.logger: 10-17 04:20:51] {2258} INFO - iteration 212, current learner xgboost\n",
            "[flaml.automl.logger: 10-17 04:20:52] {2442} INFO -  at 135.1s,\testimator xgboost's best error=0.2047,\tbest estimator xgboost's best error=0.2047\n",
            "[flaml.automl.logger: 10-17 04:20:52] {2258} INFO - iteration 213, current learner xgboost\n",
            "[flaml.automl.logger: 10-17 04:20:53] {2442} INFO -  at 136.3s,\testimator xgboost's best error=0.2047,\tbest estimator xgboost's best error=0.2047\n",
            "[flaml.automl.logger: 10-17 04:20:53] {2258} INFO - iteration 214, current learner xgboost\n",
            "[flaml.automl.logger: 10-17 04:20:54] {2442} INFO -  at 137.3s,\testimator xgboost's best error=0.2047,\tbest estimator xgboost's best error=0.2047\n",
            "[flaml.automl.logger: 10-17 04:20:54] {2258} INFO - iteration 215, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-17 04:20:55] {2442} INFO -  at 138.2s,\testimator xgb_limitdepth's best error=0.2189,\tbest estimator xgboost's best error=0.2047\n",
            "[flaml.automl.logger: 10-17 04:20:55] {2258} INFO - iteration 216, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-17 04:20:56] {2442} INFO -  at 139.0s,\testimator xgb_limitdepth's best error=0.2189,\tbest estimator xgboost's best error=0.2047\n",
            "[flaml.automl.logger: 10-17 04:20:56] {2258} INFO - iteration 217, current learner xgboost\n",
            "[flaml.automl.logger: 10-17 04:20:57] {2442} INFO -  at 140.6s,\testimator xgboost's best error=0.2047,\tbest estimator xgboost's best error=0.2047\n",
            "[flaml.automl.logger: 10-17 04:20:57] {2258} INFO - iteration 218, current learner sgd\n",
            "[flaml.automl.logger: 10-17 04:20:57] {2442} INFO -  at 140.7s,\testimator sgd's best error=0.4294,\tbest estimator xgboost's best error=0.2047\n",
            "[flaml.automl.logger: 10-17 04:20:57] {2258} INFO - iteration 219, current learner lgbm\n",
            "[flaml.automl.logger: 10-17 04:20:59] {2442} INFO -  at 142.0s,\testimator lgbm's best error=0.2069,\tbest estimator xgboost's best error=0.2047\n",
            "[flaml.automl.logger: 10-17 04:20:59] {2258} INFO - iteration 220, current learner lgbm\n",
            "[flaml.automl.logger: 10-17 04:21:01] {2442} INFO -  at 144.4s,\testimator lgbm's best error=0.2069,\tbest estimator xgboost's best error=0.2047\n",
            "[flaml.automl.logger: 10-17 04:21:01] {2258} INFO - iteration 221, current learner lgbm\n",
            "[flaml.automl.logger: 10-17 04:21:01] {2442} INFO -  at 144.7s,\testimator lgbm's best error=0.2069,\tbest estimator xgboost's best error=0.2047\n",
            "[flaml.automl.logger: 10-17 04:21:01] {2258} INFO - iteration 222, current learner xgboost\n",
            "[flaml.automl.logger: 10-17 04:21:03] {2442} INFO -  at 146.5s,\testimator xgboost's best error=0.2047,\tbest estimator xgboost's best error=0.2047\n",
            "[flaml.automl.logger: 10-17 04:21:03] {2258} INFO - iteration 223, current learner lgbm\n",
            "[flaml.automl.logger: 10-17 04:21:04] {2442} INFO -  at 147.3s,\testimator lgbm's best error=0.2069,\tbest estimator xgboost's best error=0.2047\n",
            "[flaml.automl.logger: 10-17 04:21:04] {2258} INFO - iteration 224, current learner sgd\n",
            "[flaml.automl.logger: 10-17 04:21:04] {2442} INFO -  at 147.4s,\testimator sgd's best error=0.4294,\tbest estimator xgboost's best error=0.2047\n",
            "[flaml.automl.logger: 10-17 04:21:04] {2258} INFO - iteration 225, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-17 04:21:05] {2442} INFO -  at 147.9s,\testimator xgb_limitdepth's best error=0.2189,\tbest estimator xgboost's best error=0.2047\n",
            "[flaml.automl.logger: 10-17 04:21:05] {2258} INFO - iteration 226, current learner lgbm\n",
            "[flaml.automl.logger: 10-17 04:21:06] {2442} INFO -  at 149.4s,\testimator lgbm's best error=0.2065,\tbest estimator xgboost's best error=0.2047\n",
            "[flaml.automl.logger: 10-17 04:21:06] {2258} INFO - iteration 227, current learner xgboost\n",
            "[flaml.automl.logger: 10-17 04:21:07] {2442} INFO -  at 150.5s,\testimator xgboost's best error=0.2047,\tbest estimator xgboost's best error=0.2047\n",
            "[flaml.automl.logger: 10-17 04:21:07] {2258} INFO - iteration 228, current learner xgboost\n",
            "[flaml.automl.logger: 10-17 04:21:09] {2442} INFO -  at 152.4s,\testimator xgboost's best error=0.2047,\tbest estimator xgboost's best error=0.2047\n",
            "[flaml.automl.logger: 10-17 04:21:09] {2258} INFO - iteration 229, current learner xgboost\n",
            "[flaml.automl.logger: 10-17 04:21:10] {2442} INFO -  at 153.4s,\testimator xgboost's best error=0.2047,\tbest estimator xgboost's best error=0.2047\n",
            "[flaml.automl.logger: 10-17 04:21:10] {2258} INFO - iteration 230, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-17 04:21:12] {2442} INFO -  at 155.5s,\testimator xgb_limitdepth's best error=0.2189,\tbest estimator xgboost's best error=0.2047\n",
            "[flaml.automl.logger: 10-17 04:21:12] {2258} INFO - iteration 231, current learner xgboost\n",
            "[flaml.automl.logger: 10-17 04:21:14] {2442} INFO -  at 157.1s,\testimator xgboost's best error=0.2047,\tbest estimator xgboost's best error=0.2047\n",
            "[flaml.automl.logger: 10-17 04:21:14] {2258} INFO - iteration 232, current learner sgd\n",
            "[flaml.automl.logger: 10-17 04:21:14] {2442} INFO -  at 157.2s,\testimator sgd's best error=0.4294,\tbest estimator xgboost's best error=0.2047\n",
            "[flaml.automl.logger: 10-17 04:21:14] {2258} INFO - iteration 233, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:21:14] {2442} INFO -  at 157.6s,\testimator extra_tree's best error=0.2171,\tbest estimator xgboost's best error=0.2047\n",
            "[flaml.automl.logger: 10-17 04:21:14] {2258} INFO - iteration 234, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-17 04:21:15] {2442} INFO -  at 158.4s,\testimator xgb_limitdepth's best error=0.2189,\tbest estimator xgboost's best error=0.2047\n",
            "[flaml.automl.logger: 10-17 04:21:15] {2258} INFO - iteration 235, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-17 04:21:16] {2442} INFO -  at 159.3s,\testimator xgb_limitdepth's best error=0.2154,\tbest estimator xgboost's best error=0.2047\n",
            "[flaml.automl.logger: 10-17 04:21:16] {2258} INFO - iteration 236, current learner sgd\n",
            "[flaml.automl.logger: 10-17 04:21:16] {2442} INFO -  at 159.4s,\testimator sgd's best error=0.4294,\tbest estimator xgboost's best error=0.2047\n",
            "[flaml.automl.logger: 10-17 04:21:16] {2258} INFO - iteration 237, current learner xgboost\n",
            "[flaml.automl.logger: 10-17 04:21:18] {2442} INFO -  at 160.9s,\testimator xgboost's best error=0.2047,\tbest estimator xgboost's best error=0.2047\n",
            "[flaml.automl.logger: 10-17 04:21:18] {2258} INFO - iteration 238, current learner xgboost\n",
            "[flaml.automl.logger: 10-17 04:21:19] {2442} INFO -  at 162.6s,\testimator xgboost's best error=0.2047,\tbest estimator xgboost's best error=0.2047\n",
            "[flaml.automl.logger: 10-17 04:21:19] {2258} INFO - iteration 239, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-17 04:21:20] {2442} INFO -  at 163.4s,\testimator xgb_limitdepth's best error=0.2154,\tbest estimator xgboost's best error=0.2047\n",
            "[flaml.automl.logger: 10-17 04:21:20] {2258} INFO - iteration 240, current learner xgboost\n",
            "[flaml.automl.logger: 10-17 04:21:21] {2442} INFO -  at 164.7s,\testimator xgboost's best error=0.2047,\tbest estimator xgboost's best error=0.2047\n",
            "[flaml.automl.logger: 10-17 04:21:21] {2258} INFO - iteration 241, current learner xgboost\n",
            "[flaml.automl.logger: 10-17 04:21:25] {2442} INFO -  at 167.9s,\testimator xgboost's best error=0.2047,\tbest estimator xgboost's best error=0.2047\n",
            "[flaml.automl.logger: 10-17 04:21:25] {2258} INFO - iteration 242, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-17 04:21:25] {2442} INFO -  at 168.6s,\testimator xgb_limitdepth's best error=0.2154,\tbest estimator xgboost's best error=0.2047\n",
            "[flaml.automl.logger: 10-17 04:21:25] {2258} INFO - iteration 243, current learner lgbm\n",
            "[flaml.automl.logger: 10-17 04:21:26] {2442} INFO -  at 169.2s,\testimator lgbm's best error=0.2065,\tbest estimator xgboost's best error=0.2047\n",
            "[flaml.automl.logger: 10-17 04:21:26] {2258} INFO - iteration 244, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:21:26] {2442} INFO -  at 169.5s,\testimator extra_tree's best error=0.2171,\tbest estimator xgboost's best error=0.2047\n",
            "[flaml.automl.logger: 10-17 04:21:26] {2258} INFO - iteration 245, current learner xgboost\n",
            "[flaml.automl.logger: 10-17 04:21:27] {2442} INFO -  at 170.1s,\testimator xgboost's best error=0.2047,\tbest estimator xgboost's best error=0.2047\n",
            "[flaml.automl.logger: 10-17 04:21:27] {2258} INFO - iteration 246, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-17 04:21:28] {2442} INFO -  at 171.8s,\testimator xgb_limitdepth's best error=0.2154,\tbest estimator xgboost's best error=0.2047\n",
            "[flaml.automl.logger: 10-17 04:21:28] {2258} INFO - iteration 247, current learner xgboost\n",
            "[flaml.automl.logger: 10-17 04:21:29] {2442} INFO -  at 172.8s,\testimator xgboost's best error=0.2047,\tbest estimator xgboost's best error=0.2047\n",
            "[flaml.automl.logger: 10-17 04:21:29] {2258} INFO - iteration 248, current learner sgd\n",
            "[flaml.automl.logger: 10-17 04:21:30] {2442} INFO -  at 172.9s,\testimator sgd's best error=0.4294,\tbest estimator xgboost's best error=0.2047\n",
            "[flaml.automl.logger: 10-17 04:21:30] {2258} INFO - iteration 249, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:21:30] {2442} INFO -  at 173.7s,\testimator extra_tree's best error=0.2171,\tbest estimator xgboost's best error=0.2047\n",
            "[flaml.automl.logger: 10-17 04:21:30] {2258} INFO - iteration 250, current learner xgboost\n",
            "[flaml.automl.logger: 10-17 04:21:32] {2442} INFO -  at 175.7s,\testimator xgboost's best error=0.2047,\tbest estimator xgboost's best error=0.2047\n",
            "[flaml.automl.logger: 10-17 04:21:32] {2258} INFO - iteration 251, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-17 04:21:33] {2442} INFO -  at 176.0s,\testimator xgb_limitdepth's best error=0.2154,\tbest estimator xgboost's best error=0.2047\n",
            "[flaml.automl.logger: 10-17 04:21:33] {2258} INFO - iteration 252, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:21:34] {2442} INFO -  at 177.0s,\testimator extra_tree's best error=0.2136,\tbest estimator xgboost's best error=0.2047\n",
            "[flaml.automl.logger: 10-17 04:21:34] {2258} INFO - iteration 253, current learner rf\n",
            "[flaml.automl.logger: 10-17 04:21:35] {2442} INFO -  at 178.0s,\testimator rf's best error=0.2198,\tbest estimator xgboost's best error=0.2047\n",
            "[flaml.automl.logger: 10-17 04:21:35] {2258} INFO - iteration 254, current learner rf\n",
            "[flaml.automl.logger: 10-17 04:21:36] {2442} INFO -  at 178.9s,\testimator rf's best error=0.2198,\tbest estimator xgboost's best error=0.2047\n",
            "[flaml.automl.logger: 10-17 04:21:36] {2258} INFO - iteration 255, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:21:36] {2442} INFO -  at 179.3s,\testimator extra_tree's best error=0.2136,\tbest estimator xgboost's best error=0.2047\n",
            "[flaml.automl.logger: 10-17 04:21:36] {2258} INFO - iteration 256, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-17 04:21:37] {2442} INFO -  at 180.3s,\testimator xgb_limitdepth's best error=0.2154,\tbest estimator xgboost's best error=0.2047\n",
            "[flaml.automl.logger: 10-17 04:21:37] {2258} INFO - iteration 257, current learner lgbm\n",
            "[flaml.automl.logger: 10-17 04:21:39] {2442} INFO -  at 182.2s,\testimator lgbm's best error=0.2065,\tbest estimator xgboost's best error=0.2047\n",
            "[flaml.automl.logger: 10-17 04:21:39] {2258} INFO - iteration 258, current learner sgd\n",
            "[flaml.automl.logger: 10-17 04:21:39] {2442} INFO -  at 182.3s,\testimator sgd's best error=0.4294,\tbest estimator xgboost's best error=0.2047\n",
            "[flaml.automl.logger: 10-17 04:21:39] {2258} INFO - iteration 259, current learner rf\n",
            "[flaml.automl.logger: 10-17 04:21:40] {2442} INFO -  at 183.3s,\testimator rf's best error=0.2198,\tbest estimator xgboost's best error=0.2047\n",
            "[flaml.automl.logger: 10-17 04:21:40] {2258} INFO - iteration 260, current learner sgd\n",
            "[flaml.automl.logger: 10-17 04:21:40] {2442} INFO -  at 183.5s,\testimator sgd's best error=0.4294,\tbest estimator xgboost's best error=0.2047\n",
            "[flaml.automl.logger: 10-17 04:21:40] {2258} INFO - iteration 261, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:21:41] {2442} INFO -  at 184.8s,\testimator extra_tree's best error=0.2136,\tbest estimator xgboost's best error=0.2047\n",
            "[flaml.automl.logger: 10-17 04:21:41] {2258} INFO - iteration 262, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:21:42] {2442} INFO -  at 185.5s,\testimator extra_tree's best error=0.1954,\tbest estimator extra_tree's best error=0.1954\n",
            "[flaml.automl.logger: 10-17 04:21:42] {2258} INFO - iteration 263, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:21:43] {2442} INFO -  at 186.8s,\testimator extra_tree's best error=0.1954,\tbest estimator extra_tree's best error=0.1954\n",
            "[flaml.automl.logger: 10-17 04:21:43] {2258} INFO - iteration 264, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:21:44] {2442} INFO -  at 187.2s,\testimator extra_tree's best error=0.1954,\tbest estimator extra_tree's best error=0.1954\n",
            "[flaml.automl.logger: 10-17 04:21:44] {2258} INFO - iteration 265, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:21:45] {2442} INFO -  at 188.0s,\testimator extra_tree's best error=0.1954,\tbest estimator extra_tree's best error=0.1954\n",
            "[flaml.automl.logger: 10-17 04:21:45] {2258} INFO - iteration 266, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:21:45] {2442} INFO -  at 188.6s,\testimator extra_tree's best error=0.1954,\tbest estimator extra_tree's best error=0.1954\n",
            "[flaml.automl.logger: 10-17 04:21:45] {2258} INFO - iteration 267, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:21:46] {2442} INFO -  at 189.3s,\testimator extra_tree's best error=0.1954,\tbest estimator extra_tree's best error=0.1954\n",
            "[flaml.automl.logger: 10-17 04:21:46] {2258} INFO - iteration 268, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:21:47] {2442} INFO -  at 190.1s,\testimator extra_tree's best error=0.1954,\tbest estimator extra_tree's best error=0.1954\n",
            "[flaml.automl.logger: 10-17 04:21:47] {2258} INFO - iteration 269, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:21:48] {2442} INFO -  at 190.8s,\testimator extra_tree's best error=0.1954,\tbest estimator extra_tree's best error=0.1954\n",
            "[flaml.automl.logger: 10-17 04:21:48] {2258} INFO - iteration 270, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:21:48] {2442} INFO -  at 191.7s,\testimator extra_tree's best error=0.1954,\tbest estimator extra_tree's best error=0.1954\n",
            "[flaml.automl.logger: 10-17 04:21:48] {2258} INFO - iteration 271, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:21:50] {2442} INFO -  at 192.9s,\testimator extra_tree's best error=0.1954,\tbest estimator extra_tree's best error=0.1954\n",
            "[flaml.automl.logger: 10-17 04:21:50] {2258} INFO - iteration 272, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:21:50] {2442} INFO -  at 193.4s,\testimator extra_tree's best error=0.1954,\tbest estimator extra_tree's best error=0.1954\n",
            "[flaml.automl.logger: 10-17 04:21:50] {2258} INFO - iteration 273, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:21:51] {2442} INFO -  at 194.6s,\testimator extra_tree's best error=0.1954,\tbest estimator extra_tree's best error=0.1954\n",
            "[flaml.automl.logger: 10-17 04:21:51] {2258} INFO - iteration 274, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:21:52] {2442} INFO -  at 195.0s,\testimator extra_tree's best error=0.1954,\tbest estimator extra_tree's best error=0.1954\n",
            "[flaml.automl.logger: 10-17 04:21:52] {2258} INFO - iteration 275, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:21:52] {2442} INFO -  at 195.4s,\testimator extra_tree's best error=0.1954,\tbest estimator extra_tree's best error=0.1954\n",
            "[flaml.automl.logger: 10-17 04:21:52] {2258} INFO - iteration 276, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:21:54] {2442} INFO -  at 197.0s,\testimator extra_tree's best error=0.1954,\tbest estimator extra_tree's best error=0.1954\n",
            "[flaml.automl.logger: 10-17 04:21:54] {2258} INFO - iteration 277, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:21:54] {2442} INFO -  at 197.5s,\testimator extra_tree's best error=0.1954,\tbest estimator extra_tree's best error=0.1954\n",
            "[flaml.automl.logger: 10-17 04:21:54] {2258} INFO - iteration 278, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:21:55] {2442} INFO -  at 198.5s,\testimator extra_tree's best error=0.1954,\tbest estimator extra_tree's best error=0.1954\n",
            "[flaml.automl.logger: 10-17 04:21:55] {2258} INFO - iteration 279, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:21:56] {2442} INFO -  at 199.0s,\testimator extra_tree's best error=0.1954,\tbest estimator extra_tree's best error=0.1954\n",
            "[flaml.automl.logger: 10-17 04:21:56] {2258} INFO - iteration 280, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:21:57] {2442} INFO -  at 200.0s,\testimator extra_tree's best error=0.1954,\tbest estimator extra_tree's best error=0.1954\n",
            "[flaml.automl.logger: 10-17 04:21:57] {2258} INFO - iteration 281, current learner sgd\n",
            "[flaml.automl.logger: 10-17 04:21:57] {2442} INFO -  at 200.2s,\testimator sgd's best error=0.4294,\tbest estimator extra_tree's best error=0.1954\n",
            "[flaml.automl.logger: 10-17 04:21:57] {2258} INFO - iteration 282, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:21:57] {2442} INFO -  at 200.7s,\testimator extra_tree's best error=0.1954,\tbest estimator extra_tree's best error=0.1954\n",
            "[flaml.automl.logger: 10-17 04:21:57] {2258} INFO - iteration 283, current learner rf\n",
            "[flaml.automl.logger: 10-17 04:21:58] {2442} INFO -  at 201.6s,\testimator rf's best error=0.2198,\tbest estimator extra_tree's best error=0.1954\n",
            "[flaml.automl.logger: 10-17 04:21:58] {2258} INFO - iteration 284, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:21:59] {2442} INFO -  at 202.8s,\testimator extra_tree's best error=0.1954,\tbest estimator extra_tree's best error=0.1954\n",
            "[flaml.automl.logger: 10-17 04:21:59] {2258} INFO - iteration 285, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:22:00] {2442} INFO -  at 203.3s,\testimator extra_tree's best error=0.1954,\tbest estimator extra_tree's best error=0.1954\n",
            "[flaml.automl.logger: 10-17 04:22:00] {2258} INFO - iteration 286, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:22:01] {2442} INFO -  at 204.3s,\testimator extra_tree's best error=0.1954,\tbest estimator extra_tree's best error=0.1954\n",
            "[flaml.automl.logger: 10-17 04:22:01] {2258} INFO - iteration 287, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:22:02] {2442} INFO -  at 204.9s,\testimator extra_tree's best error=0.1954,\tbest estimator extra_tree's best error=0.1954\n",
            "[flaml.automl.logger: 10-17 04:22:02] {2258} INFO - iteration 288, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-17 04:22:02] {2442} INFO -  at 205.5s,\testimator xgb_limitdepth's best error=0.2154,\tbest estimator extra_tree's best error=0.1954\n",
            "[flaml.automl.logger: 10-17 04:22:02] {2258} INFO - iteration 289, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:22:03] {2442} INFO -  at 206.4s,\testimator extra_tree's best error=0.1954,\tbest estimator extra_tree's best error=0.1954\n",
            "[flaml.automl.logger: 10-17 04:22:03] {2258} INFO - iteration 290, current learner rf\n",
            "[flaml.automl.logger: 10-17 04:22:05] {2442} INFO -  at 207.9s,\testimator rf's best error=0.2149,\tbest estimator extra_tree's best error=0.1954\n",
            "[flaml.automl.logger: 10-17 04:22:05] {2258} INFO - iteration 291, current learner rf\n",
            "[flaml.automl.logger: 10-17 04:22:06] {2442} INFO -  at 208.9s,\testimator rf's best error=0.2149,\tbest estimator extra_tree's best error=0.1954\n",
            "[flaml.automl.logger: 10-17 04:22:06] {2258} INFO - iteration 292, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:22:06] {2442} INFO -  at 209.3s,\testimator extra_tree's best error=0.1949,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:22:06] {2258} INFO - iteration 293, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:22:07] {2442} INFO -  at 210.1s,\testimator extra_tree's best error=0.1949,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:22:07] {2258} INFO - iteration 294, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:22:08] {2442} INFO -  at 211.0s,\testimator extra_tree's best error=0.1949,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:22:08] {2258} INFO - iteration 295, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:22:08] {2442} INFO -  at 211.3s,\testimator extra_tree's best error=0.1949,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:22:08] {2258} INFO - iteration 296, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:22:08] {2442} INFO -  at 211.6s,\testimator extra_tree's best error=0.1949,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:22:08] {2258} INFO - iteration 297, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:22:09] {2442} INFO -  at 212.3s,\testimator extra_tree's best error=0.1949,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:22:09] {2258} INFO - iteration 298, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:22:10] {2442} INFO -  at 212.9s,\testimator extra_tree's best error=0.1949,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:22:10] {2258} INFO - iteration 299, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:22:10] {2442} INFO -  at 213.3s,\testimator extra_tree's best error=0.1949,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:22:10] {2258} INFO - iteration 300, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:22:11] {2442} INFO -  at 213.9s,\testimator extra_tree's best error=0.1949,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:22:11] {2258} INFO - iteration 301, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:22:11] {2442} INFO -  at 214.3s,\testimator extra_tree's best error=0.1949,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:22:11] {2258} INFO - iteration 302, current learner rf\n",
            "[flaml.automl.logger: 10-17 04:22:13] {2442} INFO -  at 215.9s,\testimator rf's best error=0.2149,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:22:13] {2258} INFO - iteration 303, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:22:13] {2442} INFO -  at 216.6s,\testimator extra_tree's best error=0.1949,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:22:13] {2258} INFO - iteration 304, current learner rf\n",
            "[flaml.automl.logger: 10-17 04:22:14] {2442} INFO -  at 217.8s,\testimator rf's best error=0.2149,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:22:14] {2258} INFO - iteration 305, current learner lrl1\n",
            "[flaml.automl.logger: 10-17 04:22:15] {2442} INFO -  at 218.7s,\testimator lrl1's best error=0.3526,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:22:15] {2258} INFO - iteration 306, current learner rf\n",
            "[flaml.automl.logger: 10-17 04:22:18] {2442} INFO -  at 221.0s,\testimator rf's best error=0.2149,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:22:18] {2258} INFO - iteration 307, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:22:18] {2442} INFO -  at 221.3s,\testimator extra_tree's best error=0.1949,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:22:18] {2258} INFO - iteration 308, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-17 04:22:19] {2442} INFO -  at 222.3s,\testimator xgb_limitdepth's best error=0.2154,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:22:19] {2258} INFO - iteration 309, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:22:20] {2442} INFO -  at 223.0s,\testimator extra_tree's best error=0.1949,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:22:20] {2258} INFO - iteration 310, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:22:20] {2442} INFO -  at 223.4s,\testimator extra_tree's best error=0.1949,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:22:20] {2258} INFO - iteration 311, current learner rf\n",
            "[flaml.automl.logger: 10-17 04:22:21] {2442} INFO -  at 224.3s,\testimator rf's best error=0.2140,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:22:21] {2258} INFO - iteration 312, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:22:21] {2442} INFO -  at 224.6s,\testimator extra_tree's best error=0.1949,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:22:21] {2258} INFO - iteration 313, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:22:22] {2442} INFO -  at 225.4s,\testimator extra_tree's best error=0.1949,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:22:22] {2258} INFO - iteration 314, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:22:22] {2442} INFO -  at 225.7s,\testimator extra_tree's best error=0.1949,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:22:22] {2258} INFO - iteration 315, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:22:23] {2442} INFO -  at 226.7s,\testimator extra_tree's best error=0.1949,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:22:23] {2258} INFO - iteration 316, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:22:24] {2442} INFO -  at 227.3s,\testimator extra_tree's best error=0.1949,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:22:24] {2258} INFO - iteration 317, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-17 04:22:24] {2442} INFO -  at 227.8s,\testimator xgb_limitdepth's best error=0.2154,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:22:24] {2258} INFO - iteration 318, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-17 04:22:25] {2442} INFO -  at 228.2s,\testimator xgb_limitdepth's best error=0.2154,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:22:25] {2258} INFO - iteration 319, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:22:25] {2442} INFO -  at 228.6s,\testimator extra_tree's best error=0.1949,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:22:25] {2258} INFO - iteration 320, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:22:26] {2442} INFO -  at 229.0s,\testimator extra_tree's best error=0.1949,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:22:26] {2258} INFO - iteration 321, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:22:26] {2442} INFO -  at 229.4s,\testimator extra_tree's best error=0.1949,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:22:26] {2258} INFO - iteration 322, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:22:26] {2442} INFO -  at 229.8s,\testimator extra_tree's best error=0.1949,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:22:26] {2258} INFO - iteration 323, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:22:27] {2442} INFO -  at 230.6s,\testimator extra_tree's best error=0.1949,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:22:27] {2258} INFO - iteration 324, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:22:28] {2442} INFO -  at 231.1s,\testimator extra_tree's best error=0.1949,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:22:28] {2258} INFO - iteration 325, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:22:28] {2442} INFO -  at 231.7s,\testimator extra_tree's best error=0.1949,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:22:28] {2258} INFO - iteration 326, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:22:29] {2442} INFO -  at 232.0s,\testimator extra_tree's best error=0.1949,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:22:29] {2258} INFO - iteration 327, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:22:29] {2442} INFO -  at 232.8s,\testimator extra_tree's best error=0.1949,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:22:29] {2258} INFO - iteration 328, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:22:30] {2442} INFO -  at 233.2s,\testimator extra_tree's best error=0.1949,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:22:30] {2258} INFO - iteration 329, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:22:30] {2442} INFO -  at 233.8s,\testimator extra_tree's best error=0.1949,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:22:30] {2258} INFO - iteration 330, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:22:31] {2442} INFO -  at 234.1s,\testimator extra_tree's best error=0.1949,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:22:31] {2258} INFO - iteration 331, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:22:32] {2442} INFO -  at 234.8s,\testimator extra_tree's best error=0.1949,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:22:32] {2258} INFO - iteration 332, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:22:32] {2442} INFO -  at 235.4s,\testimator extra_tree's best error=0.1949,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:22:32] {2258} INFO - iteration 333, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:22:32] {2442} INFO -  at 235.8s,\testimator extra_tree's best error=0.1949,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:22:32] {2258} INFO - iteration 334, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:22:33] {2442} INFO -  at 236.5s,\testimator extra_tree's best error=0.1949,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:22:33] {2258} INFO - iteration 335, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:22:33] {2442} INFO -  at 236.8s,\testimator extra_tree's best error=0.1949,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:22:33] {2258} INFO - iteration 336, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:22:34] {2442} INFO -  at 237.4s,\testimator extra_tree's best error=0.1949,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:22:34] {2258} INFO - iteration 337, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:22:34] {2442} INFO -  at 237.8s,\testimator extra_tree's best error=0.1949,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:22:34] {2258} INFO - iteration 338, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:22:35] {2442} INFO -  at 238.5s,\testimator extra_tree's best error=0.1949,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:22:35] {2258} INFO - iteration 339, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:22:36] {2442} INFO -  at 238.9s,\testimator extra_tree's best error=0.1949,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:22:36] {2258} INFO - iteration 340, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:22:36] {2442} INFO -  at 239.4s,\testimator extra_tree's best error=0.1949,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:22:36] {2258} INFO - iteration 341, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:22:36] {2442} INFO -  at 239.8s,\testimator extra_tree's best error=0.1949,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:22:36] {2258} INFO - iteration 342, current learner rf\n",
            "[flaml.automl.logger: 10-17 04:22:37] {2442} INFO -  at 240.8s,\testimator rf's best error=0.2078,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:22:37] {2258} INFO - iteration 343, current learner rf\n",
            "[flaml.automl.logger: 10-17 04:22:38] {2442} INFO -  at 241.8s,\testimator rf's best error=0.2038,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:22:38] {2258} INFO - iteration 344, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:22:39] {2442} INFO -  at 242.4s,\testimator extra_tree's best error=0.1949,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:22:39] {2258} INFO - iteration 345, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:22:39] {2442} INFO -  at 242.7s,\testimator extra_tree's best error=0.1949,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:22:39] {2258} INFO - iteration 346, current learner rf\n",
            "[flaml.automl.logger: 10-17 04:22:41] {2442} INFO -  at 244.3s,\testimator rf's best error=0.2038,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:22:41] {2258} INFO - iteration 347, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:22:41] {2442} INFO -  at 244.7s,\testimator extra_tree's best error=0.1949,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:22:41] {2258} INFO - iteration 348, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-17 04:22:43] {2442} INFO -  at 246.3s,\testimator xgb_limitdepth's best error=0.2154,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:22:43] {2258} INFO - iteration 349, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:22:43] {2442} INFO -  at 246.8s,\testimator extra_tree's best error=0.1949,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:22:43] {2258} INFO - iteration 350, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:22:44] {2442} INFO -  at 247.2s,\testimator extra_tree's best error=0.1949,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:22:44] {2258} INFO - iteration 351, current learner rf\n",
            "[flaml.automl.logger: 10-17 04:22:44] {2442} INFO -  at 247.8s,\testimator rf's best error=0.2038,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:22:44] {2258} INFO - iteration 352, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:22:45] {2442} INFO -  at 248.3s,\testimator extra_tree's best error=0.1949,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:22:45] {2258} INFO - iteration 353, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:22:45] {2442} INFO -  at 248.8s,\testimator extra_tree's best error=0.1949,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:22:45] {2258} INFO - iteration 354, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:22:46] {2442} INFO -  at 249.3s,\testimator extra_tree's best error=0.1949,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:22:46] {2258} INFO - iteration 355, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:22:46] {2442} INFO -  at 249.7s,\testimator extra_tree's best error=0.1949,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:22:46] {2258} INFO - iteration 356, current learner rf\n",
            "[flaml.automl.logger: 10-17 04:22:47] {2442} INFO -  at 250.5s,\testimator rf's best error=0.2038,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:22:47] {2258} INFO - iteration 357, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:22:48] {2442} INFO -  at 251.0s,\testimator extra_tree's best error=0.1949,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:22:48] {2258} INFO - iteration 358, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:22:48] {2442} INFO -  at 251.7s,\testimator extra_tree's best error=0.1949,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:22:48] {2258} INFO - iteration 359, current learner rf\n",
            "[flaml.automl.logger: 10-17 04:22:49] {2442} INFO -  at 252.8s,\testimator rf's best error=0.2038,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:22:49] {2258} INFO - iteration 360, current learner rf\n",
            "[flaml.automl.logger: 10-17 04:22:52] {2442} INFO -  at 255.6s,\testimator rf's best error=0.2038,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:22:52] {2258} INFO - iteration 361, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:22:53] {2442} INFO -  at 256.0s,\testimator extra_tree's best error=0.1949,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:22:53] {2258} INFO - iteration 362, current learner rf\n",
            "[flaml.automl.logger: 10-17 04:22:53] {2442} INFO -  at 256.4s,\testimator rf's best error=0.2038,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:22:53] {2258} INFO - iteration 363, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:22:54] {2442} INFO -  at 257.2s,\testimator extra_tree's best error=0.1949,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:22:54] {2258} INFO - iteration 364, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:22:54] {2442} INFO -  at 257.5s,\testimator extra_tree's best error=0.1949,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:22:54] {2258} INFO - iteration 365, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:22:55] {2442} INFO -  at 258.0s,\testimator extra_tree's best error=0.1949,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:22:55] {2258} INFO - iteration 366, current learner lrl1\n",
            "[flaml.automl.logger: 10-17 04:22:55] {2442} INFO -  at 258.8s,\testimator lrl1's best error=0.3526,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:22:55] {2258} INFO - iteration 367, current learner rf\n",
            "[flaml.automl.logger: 10-17 04:22:56] {2442} INFO -  at 259.5s,\testimator rf's best error=0.2038,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:22:56] {2258} INFO - iteration 368, current learner rf\n",
            "[flaml.automl.logger: 10-17 04:22:58] {2442} INFO -  at 261.0s,\testimator rf's best error=0.2038,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:22:58] {2258} INFO - iteration 369, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-17 04:22:58] {2442} INFO -  at 261.7s,\testimator xgb_limitdepth's best error=0.2154,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:22:58] {2258} INFO - iteration 370, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:22:59] {2442} INFO -  at 262.1s,\testimator extra_tree's best error=0.1949,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:22:59] {2258} INFO - iteration 371, current learner sgd\n",
            "[flaml.automl.logger: 10-17 04:22:59] {2442} INFO -  at 262.4s,\testimator sgd's best error=0.4294,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:22:59] {2258} INFO - iteration 372, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:23:00] {2442} INFO -  at 262.9s,\testimator extra_tree's best error=0.1949,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:23:00] {2258} INFO - iteration 373, current learner lrl1\n",
            "[flaml.automl.logger: 10-17 04:23:00] {2442} INFO -  at 263.2s,\testimator lrl1's best error=0.3526,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:23:00] {2258} INFO - iteration 374, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:23:00] {2442} INFO -  at 263.7s,\testimator extra_tree's best error=0.1949,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:23:00] {2258} INFO - iteration 375, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:23:01] {2442} INFO -  at 264.2s,\testimator extra_tree's best error=0.1949,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:23:01] {2258} INFO - iteration 376, current learner rf\n",
            "[flaml.automl.logger: 10-17 04:23:03] {2442} INFO -  at 266.3s,\testimator rf's best error=0.2038,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:23:03] {2258} INFO - iteration 377, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:23:03] {2442} INFO -  at 266.7s,\testimator extra_tree's best error=0.1949,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:23:03] {2258} INFO - iteration 378, current learner rf\n",
            "[flaml.automl.logger: 10-17 04:23:04] {2442} INFO -  at 267.2s,\testimator rf's best error=0.2038,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:23:04] {2258} INFO - iteration 379, current learner rf\n",
            "[flaml.automl.logger: 10-17 04:23:05] {2442} INFO -  at 268.4s,\testimator rf's best error=0.2038,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:23:05] {2258} INFO - iteration 380, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:23:06] {2442} INFO -  at 268.9s,\testimator extra_tree's best error=0.1949,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:23:06] {2258} INFO - iteration 381, current learner rf\n",
            "[flaml.automl.logger: 10-17 04:23:06] {2442} INFO -  at 269.6s,\testimator rf's best error=0.2038,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:23:06] {2258} INFO - iteration 382, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:23:07] {2442} INFO -  at 270.0s,\testimator extra_tree's best error=0.1949,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:23:07] {2258} INFO - iteration 383, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:23:07] {2442} INFO -  at 270.3s,\testimator extra_tree's best error=0.1949,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:23:07] {2258} INFO - iteration 384, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:23:08] {2442} INFO -  at 271.1s,\testimator extra_tree's best error=0.1949,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:23:08] {2258} INFO - iteration 385, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:23:08] {2442} INFO -  at 271.5s,\testimator extra_tree's best error=0.1949,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:23:08] {2258} INFO - iteration 386, current learner rf\n",
            "[flaml.automl.logger: 10-17 04:23:10] {2442} INFO -  at 273.4s,\testimator rf's best error=0.2038,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:23:10] {2258} INFO - iteration 387, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:23:11] {2442} INFO -  at 273.9s,\testimator extra_tree's best error=0.1949,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:23:11] {2258} INFO - iteration 388, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:23:11] {2442} INFO -  at 274.4s,\testimator extra_tree's best error=0.1949,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:23:11] {2258} INFO - iteration 389, current learner lrl1\n",
            "[flaml.automl.logger: 10-17 04:23:11] {2442} INFO -  at 274.8s,\testimator lrl1's best error=0.3526,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:23:11] {2258} INFO - iteration 390, current learner rf\n",
            "[flaml.automl.logger: 10-17 04:23:12] {2442} INFO -  at 275.4s,\testimator rf's best error=0.2038,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:23:12] {2258} INFO - iteration 391, current learner rf\n",
            "[flaml.automl.logger: 10-17 04:23:13] {2442} INFO -  at 276.3s,\testimator rf's best error=0.2038,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:23:13] {2258} INFO - iteration 392, current learner xgboost\n",
            "[flaml.automl.logger: 10-17 04:23:15] {2442} INFO -  at 278.0s,\testimator xgboost's best error=0.2047,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:23:15] {2258} INFO - iteration 393, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:23:15] {2442} INFO -  at 278.4s,\testimator extra_tree's best error=0.1949,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:23:15] {2258} INFO - iteration 394, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:23:16] {2442} INFO -  at 279.1s,\testimator extra_tree's best error=0.1949,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:23:16] {2258} INFO - iteration 395, current learner rf\n",
            "[flaml.automl.logger: 10-17 04:23:17] {2442} INFO -  at 280.1s,\testimator rf's best error=0.2038,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:23:17] {2258} INFO - iteration 396, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:23:17] {2442} INFO -  at 280.5s,\testimator extra_tree's best error=0.1949,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:23:17] {2258} INFO - iteration 397, current learner rf\n",
            "[flaml.automl.logger: 10-17 04:23:18] {2442} INFO -  at 281.6s,\testimator rf's best error=0.2038,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:23:18] {2258} INFO - iteration 398, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:23:19] {2442} INFO -  at 282.1s,\testimator extra_tree's best error=0.1949,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:23:19] {2258} INFO - iteration 399, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:23:19] {2442} INFO -  at 282.5s,\testimator extra_tree's best error=0.1949,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:23:19] {2258} INFO - iteration 400, current learner rf\n",
            "[flaml.automl.logger: 10-17 04:23:20] {2442} INFO -  at 283.3s,\testimator rf's best error=0.2038,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:23:20] {2258} INFO - iteration 401, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:23:20] {2442} INFO -  at 283.8s,\testimator extra_tree's best error=0.1949,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:23:20] {2258} INFO - iteration 402, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-17 04:23:21] {2442} INFO -  at 284.6s,\testimator xgb_limitdepth's best error=0.2154,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:23:21] {2258} INFO - iteration 403, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:23:22] {2442} INFO -  at 285.3s,\testimator extra_tree's best error=0.1949,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:23:22] {2258} INFO - iteration 404, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:23:22] {2442} INFO -  at 285.8s,\testimator extra_tree's best error=0.1949,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:23:22] {2258} INFO - iteration 405, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:23:23] {2442} INFO -  at 286.3s,\testimator extra_tree's best error=0.1949,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:23:23] {2258} INFO - iteration 406, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:23:23] {2442} INFO -  at 286.6s,\testimator extra_tree's best error=0.1949,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:23:23] {2258} INFO - iteration 407, current learner sgd\n",
            "[flaml.automl.logger: 10-17 04:23:23] {2442} INFO -  at 286.8s,\testimator sgd's best error=0.4294,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:23:23] {2258} INFO - iteration 408, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:23:24] {2442} INFO -  at 287.5s,\testimator extra_tree's best error=0.1949,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:23:24] {2258} INFO - iteration 409, current learner rf\n",
            "[flaml.automl.logger: 10-17 04:23:25] {2442} INFO -  at 288.3s,\testimator rf's best error=0.2038,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:23:25] {2258} INFO - iteration 410, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:23:26] {2442} INFO -  at 288.9s,\testimator extra_tree's best error=0.1949,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:23:26] {2258} INFO - iteration 411, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:23:26] {2442} INFO -  at 289.3s,\testimator extra_tree's best error=0.1949,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:23:26] {2258} INFO - iteration 412, current learner sgd\n",
            "[flaml.automl.logger: 10-17 04:23:26] {2442} INFO -  at 289.5s,\testimator sgd's best error=0.4294,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:23:26] {2258} INFO - iteration 413, current learner rf\n",
            "[flaml.automl.logger: 10-17 04:23:27] {2442} INFO -  at 290.6s,\testimator rf's best error=0.2038,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:23:27] {2258} INFO - iteration 414, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:23:28] {2442} INFO -  at 291.3s,\testimator extra_tree's best error=0.1949,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:23:28] {2258} INFO - iteration 415, current learner rf\n",
            "[flaml.automl.logger: 10-17 04:23:29] {2442} INFO -  at 292.7s,\testimator rf's best error=0.2038,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:23:29] {2258} INFO - iteration 416, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:23:30] {2442} INFO -  at 293.1s,\testimator extra_tree's best error=0.1949,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:23:30] {2258} INFO - iteration 417, current learner rf\n",
            "[flaml.automl.logger: 10-17 04:23:30] {2442} INFO -  at 293.7s,\testimator rf's best error=0.2038,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:23:30] {2258} INFO - iteration 418, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:23:31] {2442} INFO -  at 294.1s,\testimator extra_tree's best error=0.1949,\tbest estimator extra_tree's best error=0.1949\n",
            "[flaml.automl.logger: 10-17 04:23:31] {2258} INFO - iteration 419, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:23:31] {2442} INFO -  at 294.7s,\testimator extra_tree's best error=0.1905,\tbest estimator extra_tree's best error=0.1905\n",
            "[flaml.automl.logger: 10-17 04:23:31] {2258} INFO - iteration 420, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:23:32] {2442} INFO -  at 295.1s,\testimator extra_tree's best error=0.1905,\tbest estimator extra_tree's best error=0.1905\n",
            "[flaml.automl.logger: 10-17 04:23:32] {2258} INFO - iteration 421, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:23:33] {2442} INFO -  at 296.0s,\testimator extra_tree's best error=0.1905,\tbest estimator extra_tree's best error=0.1905\n",
            "[flaml.automl.logger: 10-17 04:23:33] {2258} INFO - iteration 422, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:23:33] {2442} INFO -  at 296.4s,\testimator extra_tree's best error=0.1905,\tbest estimator extra_tree's best error=0.1905\n",
            "[flaml.automl.logger: 10-17 04:23:33] {2258} INFO - iteration 423, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-17 04:23:34] {2442} INFO -  at 297.1s,\testimator xgb_limitdepth's best error=0.2154,\tbest estimator extra_tree's best error=0.1905\n",
            "[flaml.automl.logger: 10-17 04:23:34] {2258} INFO - iteration 424, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:23:35] {2442} INFO -  at 298.0s,\testimator extra_tree's best error=0.1905,\tbest estimator extra_tree's best error=0.1905\n",
            "[flaml.automl.logger: 10-17 04:23:35] {2258} INFO - iteration 425, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:23:36] {2442} INFO -  at 298.8s,\testimator extra_tree's best error=0.1905,\tbest estimator extra_tree's best error=0.1905\n",
            "[flaml.automl.logger: 10-17 04:23:36] {2258} INFO - iteration 426, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:23:36] {2442} INFO -  at 299.3s,\testimator extra_tree's best error=0.1905,\tbest estimator extra_tree's best error=0.1905\n",
            "[flaml.automl.logger: 10-17 04:23:36] {2258} INFO - iteration 427, current learner rf\n",
            "[flaml.automl.logger: 10-17 04:23:38] {2442} INFO -  at 301.0s,\testimator rf's best error=0.2038,\tbest estimator extra_tree's best error=0.1905\n",
            "[flaml.automl.logger: 10-17 04:23:38] {2258} INFO - iteration 428, current learner rf\n",
            "[flaml.automl.logger: 10-17 04:23:38] {2442} INFO -  at 301.6s,\testimator rf's best error=0.2038,\tbest estimator extra_tree's best error=0.1905\n",
            "[flaml.automl.logger: 10-17 04:23:38] {2258} INFO - iteration 429, current learner rf\n",
            "[flaml.automl.logger: 10-17 04:23:39] {2442} INFO -  at 302.2s,\testimator rf's best error=0.2038,\tbest estimator extra_tree's best error=0.1905\n",
            "[flaml.automl.logger: 10-17 04:23:39] {2258} INFO - iteration 430, current learner rf\n",
            "[flaml.automl.logger: 10-17 04:23:40] {2442} INFO -  at 303.8s,\testimator rf's best error=0.2038,\tbest estimator extra_tree's best error=0.1905\n",
            "[flaml.automl.logger: 10-17 04:23:40] {2258} INFO - iteration 431, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:23:41] {2442} INFO -  at 304.4s,\testimator extra_tree's best error=0.1905,\tbest estimator extra_tree's best error=0.1905\n",
            "[flaml.automl.logger: 10-17 04:23:41] {2258} INFO - iteration 432, current learner rf\n",
            "[flaml.automl.logger: 10-17 04:23:42] {2442} INFO -  at 305.1s,\testimator rf's best error=0.2038,\tbest estimator extra_tree's best error=0.1905\n",
            "[flaml.automl.logger: 10-17 04:23:42] {2258} INFO - iteration 433, current learner rf\n",
            "[flaml.automl.logger: 10-17 04:23:43] {2442} INFO -  at 306.5s,\testimator rf's best error=0.2038,\tbest estimator extra_tree's best error=0.1905\n",
            "[flaml.automl.logger: 10-17 04:23:43] {2258} INFO - iteration 434, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:23:44] {2442} INFO -  at 307.1s,\testimator extra_tree's best error=0.1905,\tbest estimator extra_tree's best error=0.1905\n",
            "[flaml.automl.logger: 10-17 04:23:44] {2258} INFO - iteration 435, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:23:45] {2442} INFO -  at 308.1s,\testimator extra_tree's best error=0.1905,\tbest estimator extra_tree's best error=0.1905\n",
            "[flaml.automl.logger: 10-17 04:23:45] {2258} INFO - iteration 436, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:23:45] {2442} INFO -  at 308.5s,\testimator extra_tree's best error=0.1905,\tbest estimator extra_tree's best error=0.1905\n",
            "[flaml.automl.logger: 10-17 04:23:45] {2258} INFO - iteration 437, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:23:46] {2442} INFO -  at 309.2s,\testimator extra_tree's best error=0.1905,\tbest estimator extra_tree's best error=0.1905\n",
            "[flaml.automl.logger: 10-17 04:23:46] {2258} INFO - iteration 438, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:23:46] {2442} INFO -  at 309.8s,\testimator extra_tree's best error=0.1905,\tbest estimator extra_tree's best error=0.1905\n",
            "[flaml.automl.logger: 10-17 04:23:46] {2258} INFO - iteration 439, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:23:47] {2442} INFO -  at 310.3s,\testimator extra_tree's best error=0.1905,\tbest estimator extra_tree's best error=0.1905\n",
            "[flaml.automl.logger: 10-17 04:23:47] {2258} INFO - iteration 440, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:23:48] {2442} INFO -  at 311.0s,\testimator extra_tree's best error=0.1905,\tbest estimator extra_tree's best error=0.1905\n",
            "[flaml.automl.logger: 10-17 04:23:48] {2258} INFO - iteration 441, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:23:49] {2442} INFO -  at 311.9s,\testimator extra_tree's best error=0.1905,\tbest estimator extra_tree's best error=0.1905\n",
            "[flaml.automl.logger: 10-17 04:23:49] {2258} INFO - iteration 442, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:23:49] {2442} INFO -  at 312.3s,\testimator extra_tree's best error=0.1905,\tbest estimator extra_tree's best error=0.1905\n",
            "[flaml.automl.logger: 10-17 04:23:49] {2258} INFO - iteration 443, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-17 04:23:50] {2442} INFO -  at 313.0s,\testimator xgb_limitdepth's best error=0.2154,\tbest estimator extra_tree's best error=0.1905\n",
            "[flaml.automl.logger: 10-17 04:23:50] {2258} INFO - iteration 444, current learner rf\n",
            "[flaml.automl.logger: 10-17 04:23:50] {2442} INFO -  at 313.6s,\testimator rf's best error=0.2038,\tbest estimator extra_tree's best error=0.1905\n",
            "[flaml.automl.logger: 10-17 04:23:50] {2258} INFO - iteration 445, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:23:51] {2442} INFO -  at 314.1s,\testimator extra_tree's best error=0.1905,\tbest estimator extra_tree's best error=0.1905\n",
            "[flaml.automl.logger: 10-17 04:23:51] {2258} INFO - iteration 446, current learner rf\n",
            "[flaml.automl.logger: 10-17 04:23:52] {2442} INFO -  at 315.6s,\testimator rf's best error=0.2038,\tbest estimator extra_tree's best error=0.1905\n",
            "[flaml.automl.logger: 10-17 04:23:52] {2258} INFO - iteration 447, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:23:53] {2442} INFO -  at 316.4s,\testimator extra_tree's best error=0.1905,\tbest estimator extra_tree's best error=0.1905\n",
            "[flaml.automl.logger: 10-17 04:23:53] {2258} INFO - iteration 448, current learner rf\n",
            "[flaml.automl.logger: 10-17 04:23:54] {2442} INFO -  at 317.1s,\testimator rf's best error=0.2038,\tbest estimator extra_tree's best error=0.1905\n",
            "[flaml.automl.logger: 10-17 04:23:54] {2258} INFO - iteration 449, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:23:54] {2442} INFO -  at 317.8s,\testimator extra_tree's best error=0.1905,\tbest estimator extra_tree's best error=0.1905\n",
            "[flaml.automl.logger: 10-17 04:23:54] {2258} INFO - iteration 450, current learner lgbm\n",
            "[flaml.automl.logger: 10-17 04:23:55] {2442} INFO -  at 318.6s,\testimator lgbm's best error=0.2065,\tbest estimator extra_tree's best error=0.1905\n",
            "[flaml.automl.logger: 10-17 04:23:55] {2258} INFO - iteration 451, current learner sgd\n",
            "[flaml.automl.logger: 10-17 04:23:55] {2442} INFO -  at 318.7s,\testimator sgd's best error=0.4294,\tbest estimator extra_tree's best error=0.1905\n",
            "[flaml.automl.logger: 10-17 04:23:55] {2258} INFO - iteration 452, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-17 04:23:56] {2442} INFO -  at 319.5s,\testimator xgb_limitdepth's best error=0.2154,\tbest estimator extra_tree's best error=0.1905\n",
            "[flaml.automl.logger: 10-17 04:23:56] {2258} INFO - iteration 453, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:23:57] {2442} INFO -  at 320.1s,\testimator extra_tree's best error=0.1905,\tbest estimator extra_tree's best error=0.1905\n",
            "[flaml.automl.logger: 10-17 04:23:57] {2258} INFO - iteration 454, current learner sgd\n",
            "[flaml.automl.logger: 10-17 04:23:57] {2442} INFO -  at 320.2s,\testimator sgd's best error=0.4294,\tbest estimator extra_tree's best error=0.1905\n",
            "[flaml.automl.logger: 10-17 04:23:57] {2258} INFO - iteration 455, current learner xgboost\n",
            "[flaml.automl.logger: 10-17 04:23:58] {2442} INFO -  at 321.8s,\testimator xgboost's best error=0.2047,\tbest estimator extra_tree's best error=0.1905\n",
            "[flaml.automl.logger: 10-17 04:23:58] {2258} INFO - iteration 456, current learner xgboost\n",
            "[flaml.automl.logger: 10-17 04:24:00] {2442} INFO -  at 323.1s,\testimator xgboost's best error=0.2047,\tbest estimator extra_tree's best error=0.1905\n",
            "[flaml.automl.logger: 10-17 04:24:00] {2258} INFO - iteration 457, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:24:00] {2442} INFO -  at 323.6s,\testimator extra_tree's best error=0.1905,\tbest estimator extra_tree's best error=0.1905\n",
            "[flaml.automl.logger: 10-17 04:24:00] {2258} INFO - iteration 458, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:24:01] {2442} INFO -  at 324.3s,\testimator extra_tree's best error=0.1905,\tbest estimator extra_tree's best error=0.1905\n",
            "[flaml.automl.logger: 10-17 04:24:01] {2258} INFO - iteration 459, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-17 04:24:02] {2442} INFO -  at 325.0s,\testimator xgb_limitdepth's best error=0.2154,\tbest estimator extra_tree's best error=0.1905\n",
            "[flaml.automl.logger: 10-17 04:24:02] {2258} INFO - iteration 460, current learner lrl1\n",
            "[flaml.automl.logger: 10-17 04:24:03] {2442} INFO -  at 325.9s,\testimator lrl1's best error=0.3526,\tbest estimator extra_tree's best error=0.1905\n",
            "[flaml.automl.logger: 10-17 04:24:03] {2258} INFO - iteration 461, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:24:03] {2442} INFO -  at 326.7s,\testimator extra_tree's best error=0.1905,\tbest estimator extra_tree's best error=0.1905\n",
            "[flaml.automl.logger: 10-17 04:24:03] {2258} INFO - iteration 462, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:24:04] {2442} INFO -  at 327.2s,\testimator extra_tree's best error=0.1905,\tbest estimator extra_tree's best error=0.1905\n",
            "[flaml.automl.logger: 10-17 04:24:04] {2258} INFO - iteration 463, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-17 04:24:05] {2442} INFO -  at 328.0s,\testimator xgb_limitdepth's best error=0.2154,\tbest estimator extra_tree's best error=0.1905\n",
            "[flaml.automl.logger: 10-17 04:24:05] {2258} INFO - iteration 464, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:24:05] {2442} INFO -  at 328.6s,\testimator extra_tree's best error=0.1905,\tbest estimator extra_tree's best error=0.1905\n",
            "[flaml.automl.logger: 10-17 04:24:05] {2258} INFO - iteration 465, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:24:06] {2442} INFO -  at 329.2s,\testimator extra_tree's best error=0.1905,\tbest estimator extra_tree's best error=0.1905\n",
            "[flaml.automl.logger: 10-17 04:24:06] {2258} INFO - iteration 466, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:24:06] {2442} INFO -  at 329.7s,\testimator extra_tree's best error=0.1905,\tbest estimator extra_tree's best error=0.1905\n",
            "[flaml.automl.logger: 10-17 04:24:06] {2258} INFO - iteration 467, current learner rf\n",
            "[flaml.automl.logger: 10-17 04:24:08] {2442} INFO -  at 330.9s,\testimator rf's best error=0.2038,\tbest estimator extra_tree's best error=0.1905\n",
            "[flaml.automl.logger: 10-17 04:24:08] {2258} INFO - iteration 468, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:24:08] {2442} INFO -  at 331.6s,\testimator extra_tree's best error=0.1905,\tbest estimator extra_tree's best error=0.1905\n",
            "[flaml.automl.logger: 10-17 04:24:08] {2258} INFO - iteration 469, current learner xgboost\n",
            "[flaml.automl.logger: 10-17 04:24:10] {2442} INFO -  at 333.4s,\testimator xgboost's best error=0.2047,\tbest estimator extra_tree's best error=0.1905\n",
            "[flaml.automl.logger: 10-17 04:24:10] {2258} INFO - iteration 470, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:24:10] {2442} INFO -  at 333.8s,\testimator extra_tree's best error=0.1905,\tbest estimator extra_tree's best error=0.1905\n",
            "[flaml.automl.logger: 10-17 04:24:10] {2258} INFO - iteration 471, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:24:11] {2442} INFO -  at 334.6s,\testimator extra_tree's best error=0.1905,\tbest estimator extra_tree's best error=0.1905\n",
            "[flaml.automl.logger: 10-17 04:24:11] {2258} INFO - iteration 472, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:24:12] {2442} INFO -  at 335.2s,\testimator extra_tree's best error=0.1905,\tbest estimator extra_tree's best error=0.1905\n",
            "[flaml.automl.logger: 10-17 04:24:12] {2258} INFO - iteration 473, current learner lrl1\n",
            "[flaml.automl.logger: 10-17 04:24:13] {2442} INFO -  at 336.1s,\testimator lrl1's best error=0.3526,\tbest estimator extra_tree's best error=0.1905\n",
            "[flaml.automl.logger: 10-17 04:24:13] {2258} INFO - iteration 474, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:24:13] {2442} INFO -  at 336.7s,\testimator extra_tree's best error=0.1905,\tbest estimator extra_tree's best error=0.1905\n",
            "[flaml.automl.logger: 10-17 04:24:13] {2258} INFO - iteration 475, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:24:14] {2442} INFO -  at 337.2s,\testimator extra_tree's best error=0.1905,\tbest estimator extra_tree's best error=0.1905\n",
            "[flaml.automl.logger: 10-17 04:24:14] {2258} INFO - iteration 476, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:24:15] {2442} INFO -  at 338.0s,\testimator extra_tree's best error=0.1905,\tbest estimator extra_tree's best error=0.1905\n",
            "[flaml.automl.logger: 10-17 04:24:15] {2258} INFO - iteration 477, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-17 04:24:15] {2442} INFO -  at 338.6s,\testimator xgb_limitdepth's best error=0.2154,\tbest estimator extra_tree's best error=0.1905\n",
            "[flaml.automl.logger: 10-17 04:24:15] {2258} INFO - iteration 478, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:24:16] {2442} INFO -  at 339.1s,\testimator extra_tree's best error=0.1905,\tbest estimator extra_tree's best error=0.1905\n",
            "[flaml.automl.logger: 10-17 04:24:16] {2258} INFO - iteration 479, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:24:17] {2442} INFO -  at 339.9s,\testimator extra_tree's best error=0.1905,\tbest estimator extra_tree's best error=0.1905\n",
            "[flaml.automl.logger: 10-17 04:24:17] {2258} INFO - iteration 480, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:24:17] {2442} INFO -  at 340.6s,\testimator extra_tree's best error=0.1905,\tbest estimator extra_tree's best error=0.1905\n",
            "[flaml.automl.logger: 10-17 04:24:17] {2258} INFO - iteration 481, current learner sgd\n",
            "[flaml.automl.logger: 10-17 04:24:17] {2442} INFO -  at 340.7s,\testimator sgd's best error=0.4294,\tbest estimator extra_tree's best error=0.1905\n",
            "[flaml.automl.logger: 10-17 04:24:17] {2258} INFO - iteration 482, current learner rf\n",
            "[flaml.automl.logger: 10-17 04:24:18] {2442} INFO -  at 341.3s,\testimator rf's best error=0.2038,\tbest estimator extra_tree's best error=0.1905\n",
            "[flaml.automl.logger: 10-17 04:24:18] {2258} INFO - iteration 483, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:24:18] {2442} INFO -  at 341.8s,\testimator extra_tree's best error=0.1905,\tbest estimator extra_tree's best error=0.1905\n",
            "[flaml.automl.logger: 10-17 04:24:18] {2258} INFO - iteration 484, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-17 04:24:20] {2442} INFO -  at 343.3s,\testimator xgb_limitdepth's best error=0.2154,\tbest estimator extra_tree's best error=0.1905\n",
            "[flaml.automl.logger: 10-17 04:24:20] {2258} INFO - iteration 485, current learner rf\n",
            "[flaml.automl.logger: 10-17 04:24:22] {2442} INFO -  at 344.9s,\testimator rf's best error=0.2038,\tbest estimator extra_tree's best error=0.1905\n",
            "[flaml.automl.logger: 10-17 04:24:22] {2258} INFO - iteration 486, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:24:22] {2442} INFO -  at 345.6s,\testimator extra_tree's best error=0.1905,\tbest estimator extra_tree's best error=0.1905\n",
            "[flaml.automl.logger: 10-17 04:24:22] {2258} INFO - iteration 487, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:24:23] {2442} INFO -  at 346.1s,\testimator extra_tree's best error=0.1905,\tbest estimator extra_tree's best error=0.1905\n",
            "[flaml.automl.logger: 10-17 04:24:23] {2258} INFO - iteration 488, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-17 04:24:23] {2442} INFO -  at 346.6s,\testimator xgb_limitdepth's best error=0.2154,\tbest estimator extra_tree's best error=0.1905\n",
            "[flaml.automl.logger: 10-17 04:24:23] {2258} INFO - iteration 489, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:24:24] {2442} INFO -  at 347.1s,\testimator extra_tree's best error=0.1905,\tbest estimator extra_tree's best error=0.1905\n",
            "[flaml.automl.logger: 10-17 04:24:24] {2258} INFO - iteration 490, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:24:24] {2442} INFO -  at 347.7s,\testimator extra_tree's best error=0.1905,\tbest estimator extra_tree's best error=0.1905\n",
            "[flaml.automl.logger: 10-17 04:24:24] {2258} INFO - iteration 491, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:24:25] {2442} INFO -  at 348.3s,\testimator extra_tree's best error=0.1905,\tbest estimator extra_tree's best error=0.1905\n",
            "[flaml.automl.logger: 10-17 04:24:25] {2258} INFO - iteration 492, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:24:26] {2442} INFO -  at 348.9s,\testimator extra_tree's best error=0.1905,\tbest estimator extra_tree's best error=0.1905\n",
            "[flaml.automl.logger: 10-17 04:24:26] {2258} INFO - iteration 493, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:24:26] {2442} INFO -  at 349.5s,\testimator extra_tree's best error=0.1905,\tbest estimator extra_tree's best error=0.1905\n",
            "[flaml.automl.logger: 10-17 04:24:26] {2258} INFO - iteration 494, current learner lgbm\n",
            "[flaml.automl.logger: 10-17 04:24:27] {2442} INFO -  at 350.2s,\testimator lgbm's best error=0.2065,\tbest estimator extra_tree's best error=0.1905\n",
            "[flaml.automl.logger: 10-17 04:24:27] {2258} INFO - iteration 495, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:24:27] {2442} INFO -  at 350.8s,\testimator extra_tree's best error=0.1905,\tbest estimator extra_tree's best error=0.1905\n",
            "[flaml.automl.logger: 10-17 04:24:27] {2258} INFO - iteration 496, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:24:28] {2442} INFO -  at 351.6s,\testimator extra_tree's best error=0.1905,\tbest estimator extra_tree's best error=0.1905\n",
            "[flaml.automl.logger: 10-17 04:24:28] {2258} INFO - iteration 497, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:24:29] {2442} INFO -  at 352.1s,\testimator extra_tree's best error=0.1905,\tbest estimator extra_tree's best error=0.1905\n",
            "[flaml.automl.logger: 10-17 04:24:29] {2258} INFO - iteration 498, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-17 04:24:29] {2442} INFO -  at 352.8s,\testimator xgb_limitdepth's best error=0.2154,\tbest estimator extra_tree's best error=0.1905\n",
            "[flaml.automl.logger: 10-17 04:24:29] {2258} INFO - iteration 499, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:24:30] {2442} INFO -  at 353.6s,\testimator extra_tree's best error=0.1905,\tbest estimator extra_tree's best error=0.1905\n",
            "[flaml.automl.logger: 10-17 04:24:30] {2258} INFO - iteration 500, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:24:31] {2442} INFO -  at 354.1s,\testimator extra_tree's best error=0.1905,\tbest estimator extra_tree's best error=0.1905\n",
            "[flaml.automl.logger: 10-17 04:24:31] {2258} INFO - iteration 501, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:24:31] {2442} INFO -  at 354.5s,\testimator extra_tree's best error=0.1905,\tbest estimator extra_tree's best error=0.1905\n",
            "[flaml.automl.logger: 10-17 04:24:31] {2258} INFO - iteration 502, current learner sgd\n",
            "[flaml.automl.logger: 10-17 04:24:31] {2442} INFO -  at 354.6s,\testimator sgd's best error=0.4294,\tbest estimator extra_tree's best error=0.1905\n",
            "[flaml.automl.logger: 10-17 04:24:31] {2258} INFO - iteration 503, current learner sgd\n",
            "[flaml.automl.logger: 10-17 04:24:31] {2442} INFO -  at 354.8s,\testimator sgd's best error=0.4294,\tbest estimator extra_tree's best error=0.1905\n",
            "[flaml.automl.logger: 10-17 04:24:31] {2258} INFO - iteration 504, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:24:33] {2442} INFO -  at 355.9s,\testimator extra_tree's best error=0.1905,\tbest estimator extra_tree's best error=0.1905\n",
            "[flaml.automl.logger: 10-17 04:24:33] {2258} INFO - iteration 505, current learner xgb_limitdepth\n",
            "[flaml.automl.logger: 10-17 04:24:33] {2442} INFO -  at 356.6s,\testimator xgb_limitdepth's best error=0.2154,\tbest estimator extra_tree's best error=0.1905\n",
            "[flaml.automl.logger: 10-17 04:24:33] {2258} INFO - iteration 506, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:24:34] {2442} INFO -  at 357.5s,\testimator extra_tree's best error=0.1905,\tbest estimator extra_tree's best error=0.1905\n",
            "[flaml.automl.logger: 10-17 04:24:34] {2258} INFO - iteration 507, current learner rf\n",
            "[flaml.automl.logger: 10-17 04:24:35] {2442} INFO -  at 358.3s,\testimator rf's best error=0.2038,\tbest estimator extra_tree's best error=0.1905\n",
            "[flaml.automl.logger: 10-17 04:24:35] {2258} INFO - iteration 508, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:24:35] {2442} INFO -  at 358.8s,\testimator extra_tree's best error=0.1905,\tbest estimator extra_tree's best error=0.1905\n",
            "[flaml.automl.logger: 10-17 04:24:35] {2258} INFO - iteration 509, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:24:36] {2442} INFO -  at 359.2s,\testimator extra_tree's best error=0.1905,\tbest estimator extra_tree's best error=0.1905\n",
            "[flaml.automl.logger: 10-17 04:24:36] {2258} INFO - iteration 510, current learner extra_tree\n",
            "[flaml.automl.logger: 10-17 04:24:37] {2442} INFO -  at 360.1s,\testimator extra_tree's best error=0.1905,\tbest estimator extra_tree's best error=0.1905\n",
            "[flaml.automl.logger: 10-17 04:24:37] {2685} INFO - retrain extra_tree for 0.1s\n",
            "[flaml.automl.logger: 10-17 04:24:37] {2688} INFO - retrained model: ExtraTreesClassifier(criterion='entropy', max_features=0.643370958753101,\n",
            "                     max_leaf_nodes=533, n_estimators=45, n_jobs=-1,\n",
            "                     random_state=12032022)\n",
            "[flaml.automl.logger: 10-17 04:24:37] {1985} INFO - fit succeeded\n",
            "[flaml.automl.logger: 10-17 04:24:37] {1986} INFO - Time taken to find the best model: 294.66832876205444\n",
            "Estimator: extra_tree\n",
            "Config: {'n_estimators': 45, 'max_features': 0.643370958753101, 'max_leaves': 533, 'criterion': 'entropy'}\n"
          ]
        }
      ],
      "source": [
        "model = AutoML()\n",
        "\n",
        "model.fit(X_train, y_train, task='classification', metric='accuracy', time_budget=360) #train classifier for 6 minutes optimizing for accuracy\n",
        "\n",
        "\n",
        "print(f\"Estimator: {model.best_estimator}\")\n",
        "print(f\"Config: {model.best_config}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IT6O8oGnvIsZ"
      },
      "source": [
        "- Print Accuracy and Classification Report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-srfhwGrxPL",
        "outputId": "9561d421-2045-446b-cb8b-d0997251941c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.817\n",
            "Classification:               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.77      0.81       282\n",
            "           1       0.79      0.86      0.83       282\n",
            "\n",
            "    accuracy                           0.82       564\n",
            "   macro avg       0.82      0.82      0.82       564\n",
            "weighted avg       0.82      0.82      0.82       564\n",
            "\n"
          ]
        }
      ],
      "source": [
        "y_test_predict = model.predict(X_test)\n",
        "test_accuracy = accuracy_score(y_test, y_test_predict)\n",
        "print(f\"Test Accuracy: {test_accuracy:.3f}\")\n",
        "print(f\"Classification: {classification_report(y_test, y_test_predict)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GINx6brPrxPM"
      },
      "source": [
        "## Process Example Video to test for OKD Predictions\n",
        "\n",
        "### Creates overall function for processing and predicting\n",
        "\n",
        "- Import libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "JO2k9t1iv4vZ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", message=r\".*X does not have valid feature names.*\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DmXNhn7TvzHx"
      },
      "source": [
        "- Define processing function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "POP9gZHCwBTp"
      },
      "outputs": [],
      "source": [
        "# create function to process individual video for OKD given models\n",
        "def process_okd_video(video_path, pose_model, phc_model, model, output_path=None, batch_size=4) -> list[int]:\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "    if output_path: # save video with predictions if output path is specified\n",
        "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "        out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
        "\n",
        "    okd_predictions = []\n",
        "    frames = []\n",
        "\n",
        "    for _ in tqdm(range(0, total_frames, batch_size), desc=\"Processing batches\"): # process video in batches of frames for quicker processing\n",
        "        batch_frames = []\n",
        "        for _ in range(batch_size):\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "            batch_frames.append(frame)\n",
        "\n",
        "        if not batch_frames:\n",
        "            break\n",
        "\n",
        "        # perform detections on batch\n",
        "        phc_results = phc_model(batch_frames, device='mps', verbose=False)\n",
        "\n",
        "        for i, frame in enumerate(batch_frames):\n",
        "            catcher_box = None\n",
        "            for box in phc_results[i].boxes:\n",
        "                cls = int(box.cls)\n",
        "                if cls == 2:\n",
        "                    catcher_box = box.xyxy[0].cpu().numpy() # extract catcher box coordinates\n",
        "                    break\n",
        "\n",
        "            if catcher_box is None:\n",
        "                okd_predictions.append(0)\n",
        "                frames.append(frame)\n",
        "                continue\n",
        "\n",
        "             # predict pose within catcher's box\n",
        "            x1, y1, x2, y2 = map(int, catcher_box)\n",
        "            catcher_frame = frame[y1:y2, x1:x2]\n",
        "            pose_results = pose_model(catcher_frame, device='mps', verbose=False, conf=0.5)[0]\n",
        "\n",
        "            pose_points = []\n",
        "            for keypoints in pose_results.keypoints:\n",
        "                for point in keypoints.xyn[0].cpu().numpy():\n",
        "                    pose_points.extend(point)\n",
        "\n",
        "\n",
        "            # pad pose points for expected length\n",
        "            pose_points = pose_points[:34] + [0] * (34 - len(pose_points))\n",
        "\n",
        "            okd_pred = model.predict(np.array(pose_points).reshape(1, -1))[0] # predict with classifier model\n",
        "            okd_predictions.append(okd_pred)\n",
        "\n",
        "            if output_path:\n",
        "                cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
        "                cv2.putText(frame, \"Catcher\", (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 1)\n",
        "                cv2.putText(frame, f\"OKD: {'Yes' if okd_pred == 1 else 'No'}\", (10, 30),\n",
        "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0) if okd_pred == 1 else (0, 0, 255), 2)\n",
        "\n",
        "            frames.append(frame)\n",
        "\n",
        "    if output_path:\n",
        "        for frame in frames:\n",
        "            out.write(frame)\n",
        "\n",
        "    cap.release()\n",
        "    if output_path:\n",
        "        out.release()\n",
        "\n",
        "    return okd_predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ozq0R_InviYS"
      },
      "source": [
        "- Load Pose, PHC, and Classifier models\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-lUPa05ZwEcQ",
        "outputId": "a677f698-1900-4870-d051-c3a65a08e29d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading pitcher_hitter_catcher_detector_v4.pt: 100%|██████████| 87.6M/87.6M [00:02<00:00, 42.2MiB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model downloaded to models/pitcher_hitter_catcher_detector/model_weights/pitcher_hitter_catcher_detector_v4.pt\n"
          ]
        }
      ],
      "source": [
        "pose_model = YOLO(\"yolov8l-pose.pt\")\n",
        "phc_model = YOLO(load_tools.load_model(\"phc_detector\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVgKYvQsvkDa"
      },
      "source": [
        "- Process video in frame batches for quicker processing\n",
        "- Predict OKD for a given frame (futue iterations need to identify where pitch starts)\n",
        "- Save video with predictions (if given an output path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2PhfR05IwRaA",
        "outputId": "08661027-6db4-4dc5-a2da-5980456b979e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rProcessing batches:   0%|          | 0/98 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING ⚠️ Apple MPS known Pose bug. Recommend 'device=cpu' for Pose models. See https://github.com/ultralytics/ultralytics/issues/4031.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing batches: 100%|██████████| 98/98 [07:55<00:00,  4.85s/it]\n"
          ]
        }
      ],
      "source": [
        "video_path = \"assets/example_broadcast_video.mp4\"\n",
        "output_path = \"test_okd.mp4\"\n",
        "\n",
        "okd_predictions = process_okd_video(video_path, pose_model, phc_model, model, output_path, batch_size=4)\n",
        "\n",
        "okd_count = sum(okd_predictions)\n",
        "total_frames = len(okd_predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQ7JN74WvoxR"
      },
      "source": [
        "- Print percentage of frames for video predicted as OKD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHrXMkIZrxPM",
        "outputId": "d19685fc-0008-4931-d407-29515c46b1ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted OKD in 75.3% of 392 frames.\n"
          ]
        }
      ],
      "source": [
        "print(f\"Predicted OKD in {okd_count/total_frames:.1%} of {total_frames} frames.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8MxdQEVlrxPN"
      },
      "source": [
        "##**CONGRATS!** You utilized the OKD / NOKD datase and pose estimation to train a classifier to predict if a catcher is in a one-knee down position!\n",
        "\n",
        "### The classifier model and it's relavent information can be found in the models/okd_nokd_classifier folder."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
